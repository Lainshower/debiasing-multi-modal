{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data/Model settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinsu/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jinsu/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/jinsu/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/jinsu/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/jinsu/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "from visualizer import *\n",
    "from visualizer_supcon import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = parse_option()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.dataset = 'waterbirds'\n",
    "# opt.tl_method = \"linear_probing\" # For zeroshot\n",
    "opt.tl_method = \"contrastive_adapter\"\n",
    "opt.train_target = \"class\"\n",
    "non_target = \"spurious\"\n",
    "\n",
    "opt.text_embedding_dir = f\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/{opt.dataset}/clip_{opt.train_target}.json\"\n",
    "opt.text_spurious_embedding_dir = f\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/{opt.dataset}/clip_{non_target}.json\"\n",
    "opt.text_group_embedding_dir = f\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/{opt.dataset}/clip_group.json\"\n",
    "opt.image_embedding_dir = f\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/RN50/clip.json\"\n",
    "opt.data_dir=\"/home/jinsu/workstation/project/debiasing-multi-modal/data/waterbirds/waterbird_complete95_forest2water2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Start Transfer Learning using [contrastive_adapter]\n",
      "========================================================================\n",
      "Load image embedding of Waterbirds: /home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/RN50/clip.json\n",
      "/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/RN50/clip.json\n",
      "ㄴ Corresponding text embedding of Waterbirds: /home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/clip_class.json\n",
      "Load Data Loader (train, validation, test)\n",
      "/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/RN50/clip.json\n",
      "/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/RN50/clip.json\n",
      "/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/RN50/clip.json\n",
      "Training target : class (Land bird(0) / Water bird(1))\n",
      "Off-the-shelf classifier : Contrastive Adapter\n"
     ]
    }
   ],
   "source": [
    "(trainset, train_loader, val_loader, test_loader, \n",
    " get_yp_func, train_group_ratio, classifier, criterion) = initialize_for_vis(opt)\n",
    "\n",
    "ce_loss = criterion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training & Visualize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Training Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.balance_by_zs_pred = False  # Anchor' class 밸런스.\n",
    "opt.re_shuffle_ca_loader = True # 매 에폭마다 Contrastive Batch 셔플\n",
    "opt.maintain_alternative_ordering = True # Anchor 배치를 클래스끼리 번갈아가면서 할당. (opt.balance_by_zs_pred와 동시에 사용)\n",
    "\n",
    "opt.correct_class_bias = False # CA paper 내 CE-loader-psampling 방식으로 인해 심해지는 class imbalance 교정.\n",
    "opt.reweighting_by_class = False # CE-loader에서 class balance를 1:1로 할당.\n",
    "\n",
    "## \n",
    "opt.epochs = 5\n",
    "opt.learning_rate = 1e-3\n",
    "opt.batch_size = 128\n",
    "opt.num_anchor = 1\n",
    "opt.num_positive = 2048\n",
    "opt.num_negative = 2048\n",
    "\n",
    "opt.print_freq_ca = 1\n",
    "opt.print_freq = 1\n",
    "opt.batch_factor = 32 # CA Loader 내 배치팩터. (1 update per 32 anchor)\n",
    "opt.contrastive_weight = 1.0\n",
    "\n",
    "opt.ca_update = 10000 # ca update 멈추는 배치 개수 (1~50)\n",
    "opt.ce_update = 10000 # ce update 멈추는 배치 개수 (1~12)\n",
    "opt.ca_pre_norm = True # CLIP -> \"Normalized CLIP\" -> Adapter -> ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Visualization Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "opt.ca_update = 1 # CA 업데이트 횟수\n",
    "opt.ce_update = 0 # CE 업데이트 횟수\n",
    "\n",
    "# 임베딩 누적시킬 에폭 길이. \n",
    "opt.max_length_ebd_queue = 4 # (e.g., at 20 epoch, we are having following embeddings: 18-after-CA, 18-after-CE, 19-after-CA, 19-after-CE)\n",
    "\n",
    "vis_handler = VisHandler(opt)\n",
    "\n",
    "vis_handler.SaveTextEmbeddings(opt.text_embedding_dir) # class 임베딩 경로 (unnormalized!) (c.f. clip_inference_including_group_with_unnorm.py)\n",
    "vis_handler.SaveTextEmbeddings(opt.text_spurious_embedding_dir) # spurious 임베딩 경로 (unnormalized!) (c.f. clip_inference_including_group_with_unnorm.py)\n",
    "# vis_handler.SaveTextEmbeddings(opt.text_group_embedding_dir) # group 임베딩 경로 (unnormalized!) (c.f. clip_inference_including_group_with_unnorm.py)\n",
    "\n",
    "num_nn_text_ebd = 10 # 각각의 Text embedding에서 제일 가까운 [num_nn_text_ebd] 개수의 이미지 임베딩을 뽑아, 평균낸 임베딩을 해당 Text embedding의 visualization에 사용함. \n",
    "set_bbox=False # True: 가독성 그나마 좋아지나, 가끔 가릴 때 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_like_queue(array, new_instance, max_length):\n",
    "    while (len(array) >= max_length):\n",
    "        del array[0]\n",
    "    \n",
    "    array.append(new_instance)\n",
    "    \n",
    "# 길이 N인 인 큐 생성\n",
    "train_ebd_q = []\n",
    "val_ebd_q = []\n",
    "test_ebd_q = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisHandler():\n",
    "    \"\"\"\n",
    "    - 1) Embedding 기반 Loader 받아서 Zero-shot prediction, Embeddings reduction 등 수행.\n",
    "      - 1.1) Adapter 학습 하고 난 다음의 pth도 저장해놨으니, 불러와서 임베딩 똑같이 뽑을 수 있음.\n",
    "      - 1.2) Linear probing / Adapter 등 학습 시 results/...에 결과 저장됨. \n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        \"\"\"\n",
    "        Initialized by arguments for \"single run\"\n",
    "        \"\"\"\n",
    "        self.args = args\n",
    "        self.device = (torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "    \n",
    "        # self.train_results = EasyDict(read_pickle_file(os.path.join(self.run_path, 'full_dict.pickle')))\n",
    "        self.final_results = {} # Best Train / Val / Text\n",
    "        \n",
    "        if self.args.dataset == \"waterbirds\" :\n",
    "            self.legend_labels_dict = {\"target\": {0: \"Landbird\", 1: \"Waterbird\"}, \"spurious\": {0: \"Land-background\", 1:\"Water-background\"}, \n",
    "                            \"group\": {0: \"Landbird on Land-background\", 1: \"Landbird on Water-background\",\n",
    "                                        2: \"Waterbird on Land-background\", 3: \"Waterbird on Water-background\"},\n",
    "                            \"prediction\": {0: \"Pred. to Landbird\",\n",
    "                                            1: \"Pred. to Waterbird\"}}\n",
    "\n",
    "        self.model = None\n",
    "        self.text_embeddings = []\n",
    "        self.group_wise_stat_ebd = {}\n",
    "        self.group_wise_stat_conf = {}\n",
    "        \n",
    "        self.epoch = 0\n",
    "    \n",
    "    def SaveWaterbirdsDatasets(self, trainset):\n",
    "        self.train_set = trainset\n",
    "    \n",
    "    def SaveWaterbirdsLoaders(self, train_loader, val_loader, test_loader):\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "\n",
    "    def SaveTextEmbeddings(self, embedding_dir):\n",
    "        self.text_embeddings.extend(get_text_embedding(embedding_dir, return_key=True))\n",
    "    \n",
    "    def SaveModel(self, classifier):\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def SaveUtils(self, criterion, get_yp_func, train_group_ratio):\n",
    "        self.criterion = criterion\n",
    "        self.get_yp_func = get_yp_func\n",
    "        self.train_group_ratio = train_group_ratio\n",
    "        \n",
    "    def SaveZeroShotResults(self, train_loader, val_loader, test_loader):\n",
    "        self.zs_results = {}\n",
    "        _, _, train_group_acc = validate_zs(self.args, train_loader, self.classifier, self.criterion, self.get_yp_func, self.train_group_ratio, target=\"class\", print_label='Get ZS Acc. of train (class)')    \n",
    "        _, _, val_group_acc = validate_zs(self.args, val_loader, self.classifier, self.criterion, self.get_yp_func, self.train_group_ratio, target=\"class\", print_label='Get ZS Acc. of val (class)')    \n",
    "        _, _, test_group_acc = validate_zs(self.args, test_loader, self.classifier, self.criterion, self.get_yp_func, self.train_group_ratio, target=\"class\", print_label='Get ZS Acc. of test (class)')    \n",
    "        self.zs_results['train'] = train_group_acc\n",
    "        self.zs_results['val'] = val_group_acc\n",
    "        self.zs_results['test'] = test_group_acc\n",
    "    \n",
    "    def GetEmbeddings(self, dataloader):\n",
    "        # # NOTE Adapter 학습 이후 모델 받아서 추출하는 라인 추가해야함.\n",
    "        \n",
    "        total_embeddings = []\n",
    "\n",
    "        total_labels = []\n",
    "        total_spuriouss = []\n",
    "        total_groups = []\n",
    "        # total_confidences = []\n",
    "        total_predictions = [] # Zero-shot\n",
    "\n",
    "        print('> Saving activations')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(tqdm(dataloader, desc='Running inference')):\n",
    "                embeddings, labels_dict, _= data\n",
    "                labels = labels_dict[\"class\"]\n",
    "                groups = labels_dict[\"group\"]\n",
    "                places = labels_dict[\"spurious\"]\n",
    "                predicted = labels_dict[\"ebd_y_pred\"]\n",
    "\n",
    "                total_labels.extend(labels.numpy())\n",
    "                total_groups.extend(groups.numpy())\n",
    "                total_spuriouss.extend(places.numpy())\n",
    "                total_predictions.extend(predicted.numpy())\n",
    "                total_embeddings.extend(embeddings.numpy())\n",
    "                \n",
    "                del embeddings; del labels; del groups; del places; del predicted\n",
    "\n",
    "        total_embeddings = np.array(total_embeddings) # (# of full data, feat_dim)\n",
    "\n",
    "        total_meta_results = {\"targets\" : total_labels, \"spuriouss\": total_spuriouss, \"groups\" : total_groups, \n",
    "                             \"predictions\": total_predictions}\n",
    "        \n",
    "        return total_embeddings, total_meta_results\n",
    "        \n",
    "    def VisRep(self, model, dataloader, vis_on, label_types=['group', 'target', 'spurious', 'prediction'], num_data=None, reduced_dim=2,\n",
    "                          figsize=(8, 6), save=True, ftype='.png', title_suffix=None, save_id_suffix=None,\n",
    "                          annotate_points=None, plot_mds=False, seed=42):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            model (_type_): nn.Module\n",
    "            dataloader (_type_): Dataset for visualization \n",
    "            vis_on (_type_): choice <- [\"train\", \"val\", \"test\", \"val_fg\", \"test_fg\"] (correspond to dataloader)\n",
    "            label_types (_type_): ['confidence', 'target', 'spurious', 'group', 'prediction']\n",
    "            num_data (_type_, optional): for Random sampling(No..) Defaults to None=Full..\n",
    "            reduced_dim (int, optional): _description_. Defaults to 2.\n",
    "        \"\"\"\n",
    "        \n",
    "        total_embeddings, total_meta_results = self.GetEmbeddings(model, dataloader)\n",
    "        \n",
    "        if self.args.tl_method == \"linear_probing\":\n",
    "            model_title = \"CLIP ZS\"\n",
    "            title_suffix= f'([{model_title}] Rep. on [{vis_on}])'\n",
    "        else:\n",
    "            title_suffix= f'([{self.args.tl_method}] Rep. on [{vis_on}] (Epoch {self.model_epoch}))'\n",
    "            \n",
    "             \n",
    "\n",
    "        print(f'total_embeddings.shape: {total_embeddings.shape}')\n",
    "        n_mult = 1\n",
    "        pbar = tqdm(total=n_mult * len(label_types))\n",
    "        for label_type in label_types:\n",
    "            # For now just save both classifier ReLU activation layers (for MLP, BaseCNN)\n",
    "            if save_id_suffix is not None:\n",
    "                save_id = f'{reduced_dim}d_{label_type}_{vis_on}_{save_id_suffix}'\n",
    "            else:\n",
    "                save_id = f'{reduced_dim}d_{label_type}_{vis_on}'\n",
    "                \n",
    "            plot_umap(total_embeddings, total_meta_results, label_type, self.legend_labels_dict, reduced_dim, num_data, method='umap',\n",
    "                        offset=0, figsize=figsize, save_id=save_id, save=save,\n",
    "                        ftype=ftype, title_suffix=title_suffix, annotate_points=annotate_points,\n",
    "                        seed=seed, display_image = True)\n",
    "            # Add MDS\n",
    "            if plot_mds:\n",
    "                plot_umap(total_embeddings, total_meta_results, label_type, self.legend_labels_dict,  reduced_dim, num_data, method='mds',\n",
    "                            offset=0, figsize=figsize, save_id=save_id, save=save,\n",
    "                            ftype=ftype, title_suffix=title_suffix, annotate_points=annotate_points,\n",
    "                            seed=seed, display_image = True)\n",
    "            pbar.update(1)\n",
    "    \n",
    "    def VisRepAll(self, train_loader, val_loader, test_loader, label_types=['group', 'target', 'spurious', 'prediction'], num_data=None, reduced_dim=2,\n",
    "                          figsize=(24, 6), save=True, ftype='.png', title_suffix=None, save_id_suffix=None,\n",
    "                          annotate_points=None, plot_mds=False, seed=42, text_ebd=None, group_mean_ebd=None, num_nn_text_ebd=10, set_bbox=False):\n",
    "        \"\"\"\n",
    "        - Projection all train/val/test sets to same sub-space. (thus same umap-structure)\n",
    "        \"\"\"\n",
    "        \n",
    "        # self.embeddings_df = pd.read_json(self.embedding_dir) # key : image_filename\n",
    "        indices_to_convert = ['y', 'place', 'group', 'y_pred', 'split'] # str -> int\n",
    "        # self.embeddings_df.loc[indices_to_convert] = self.embeddings_df.loc[indices_to_convert].astype('int64')\n",
    "        \n",
    "        total_embeddings_train, total_meta_results_train = self.GetEmbeddings(train_loader)\n",
    "        total_embeddings_val, total_meta_results_val = self.GetEmbeddings(val_loader)\n",
    "        total_embeddings_test, total_meta_results_test = self.GetEmbeddings(test_loader)\n",
    "        \n",
    "        # Save Group-wise Statistics -> [(norm of mean_vector, mean-vector) / compactness] for [train/val/test]\n",
    "        \n",
    "        print(\"> Calculating [Group-wise] Statistics...\")\n",
    "        self.group_wise_stat_ebd['train'] = GetGroupWiseStatEbd(total_embeddings_train, np.array(total_meta_results_train[\"groups\"]))\n",
    "        self.group_wise_stat_ebd['val'] = GetGroupWiseStatEbd(total_embeddings_val, np.array(total_meta_results_val[\"groups\"]))\n",
    "        self.group_wise_stat_ebd['test'] = GetGroupWiseStatEbd(total_embeddings_test, np.array(total_meta_results_test[\"groups\"]))\n",
    "            \n",
    "        group_wise_indexes = [\"Acc.\", \"Div.\", \"Centr. Norm.\"]\n",
    "        columns = [\"Avg.\",\"Worst\", \"group0\", \"group1\", \"group2\", \"group3\"]\n",
    "        \n",
    "        dfs =[]\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            if split==\"train\":\n",
    "                values = [list(self.zs_results[f\"{split}\"].values())[:-1], \n",
    "                        [list(self.group_wise_stat_ebd[split][\"pairwise_distance\"].values())[0]] + [0] + list(self.group_wise_stat_ebd[split][\"pairwise_distance\"].values())[1:],\n",
    "                        [list(self.group_wise_stat_ebd[split][\"mean_vector_norm\"].values())[0]] + [0] + list(self.group_wise_stat_ebd[split][\"mean_vector_norm\"].values())[1:]]\n",
    "                df = pd.DataFrame(values, index=group_wise_indexes, columns = columns)\n",
    "                df = df.round(3)\n",
    "                dfs.append(df)\n",
    "            else:\n",
    "                values = [list(self.zs_results[f\"{split}\"].values())[:-1], \n",
    "                        [list(self.group_wise_stat_ebd[split][\"pairwise_distance\"].values())[0]] + [0] + list(self.group_wise_stat_ebd[split][\"pairwise_distance\"].values())[1:],\n",
    "                        [list(self.group_wise_stat_ebd[split][\"mean_vector_norm\"].values())[0]] + [0] + list(self.group_wise_stat_ebd[split][\"mean_vector_norm\"].values())[1:]]\n",
    "                df = pd.DataFrame(values, index=group_wise_indexes, columns = columns)\n",
    "                df = df.round(3)\n",
    "                dfs.append(df)\n",
    "        \n",
    "        if group_mean_ebd is not None:  # group label : (4, 2024) X 3\n",
    "            add_group_labels_train = [group for group in self.group_wise_stat_ebd['train'][\"mean_vector\"].keys()] # Waterbird\n",
    "            add_group_mean_ebds_train = [ebd for ebd in self.group_wise_stat_ebd['train'][\"mean_vector\"].values()]\n",
    "            add_group_labels_val = [group for group in self.group_wise_stat_ebd['val'][\"mean_vector\"].keys()] # Waterbird\n",
    "            add_group_mean_ebds_val = [ebd for ebd in self.group_wise_stat_ebd['val'][\"mean_vector\"].values()]\n",
    "            add_group_labels_test = [group for group in self.group_wise_stat_ebd['test'][\"mean_vector\"].keys()] # Waterbird\n",
    "            add_group_mean_ebds_test = [ebd for ebd in self.group_wise_stat_ebd['test'][\"mean_vector\"].values()]\n",
    "\n",
    "            group_mean_ebd = (add_group_mean_ebds_train, add_group_mean_ebds_val, add_group_mean_ebds_test,\n",
    "                              add_group_labels_train, add_group_labels_val, add_group_labels_test)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.args.tl_method == \"linear_probing\":\n",
    "            title_suffix= f'([CLIP ZS] Representation ({num_nn_text_ebd} near.)'\n",
    "        else:\n",
    "            title_suffix= f'([{self.args.tl_method}] Representation ({num_nn_text_ebd} near.) (Epoch {self.model_epoch}))'\n",
    "        \n",
    "        n_mult = 1\n",
    "        pbar = tqdm(total=n_mult * len(label_types))\n",
    "        for label_type in label_types:\n",
    "            # For now just save both classifier ReLU activation layers (for MLP, BaseCNN)\n",
    "            if save_id_suffix is not None:\n",
    "                save_id = f'{reduced_dim}d_{label_type}_{save_id_suffix}'\n",
    "            else:\n",
    "                save_id = f'{reduced_dim}d_{label_type}'\n",
    "            \n",
    "            # print(\"save_id\", save_id)\n",
    "            \n",
    "            plot_umap_all(total_embeddings_train, total_embeddings_val, total_embeddings_test, total_meta_results_train, total_meta_results_val, total_meta_results_test,\n",
    "                  label_type, self.legend_labels_dict, dfs, reduced_dim, method='umap', figsize=figsize, save_id=save_id, save=save, ftype=ftype, title_suffix=title_suffix,\n",
    "              annotate_points=annotate_points, seed=seed, display_image=True, text_ebd = text_ebd, group_mean_ebd = group_mean_ebd, num_nn_text_ebd = num_nn_text_ebd, set_bbox=set_bbox)\n",
    "            \n",
    "            if plot_mds:\n",
    "                plot_umap_all(total_embeddings_train, total_embeddings_val, total_embeddings_test, total_meta_results_train, total_meta_results_val, total_meta_results_test,\n",
    "                  label_type, self.legend_labels_dict, dfs, reduced_dim, method='mds', figsize=figsize, save_id=save_id, save=save, ftype=ftype, title_suffix=title_suffix,\n",
    "              annotate_points=annotate_points, seed=seed, display_image=True, text_ebd = text_ebd, group_mean_ebd = group_mean_ebd, num_nn_text_ebd = num_nn_text_ebd, set_bbox=set_bbox)\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "            \n",
    "    def plot_umap_for_ca(self, ebd_queue_train, ebd_queue_val, ebd_queue_test, label_type, save_root, save_id, legend_labels_dict, reduced_dim=2, method='umap', figsize=(24, 6), save=True,\n",
    "              ftype='.png', title_suffix=None, seed=42, display_image=True, text_ebd = True, group_mean_ebd = True, num_nn_text_ebd = 10, remove_prefix=True, set_bbox=False):\n",
    "        \"\"\"\n",
    "        Visualize embeddings with U-MAP\n",
    "        \"\"\"\n",
    "        \n",
    "        # Final Embedding' Statistics\n",
    "        total_embeddings_train, total_meta_results_train = ebd_queue_train[-1]\n",
    "        total_embeddings_val, total_meta_results_val = ebd_queue_val[-1]\n",
    "        total_embeddings_test, total_meta_results_test = ebd_queue_test[-1]\n",
    "        \n",
    "        group_wise_stat_ebd = {}\n",
    "        print(\"> Calculating [Group-wise] Statistics...\")\n",
    "        group_wise_stat_ebd['train'] = GetGroupWiseStatEbd(total_embeddings_train, np.array(total_meta_results_train[\"groups\"]), return_dist = False)\n",
    "        group_wise_stat_ebd['val'] = GetGroupWiseStatEbd(total_embeddings_val, np.array(total_meta_results_val[\"groups\"]), return_dist = False)\n",
    "        group_wise_stat_ebd['test'] = GetGroupWiseStatEbd(total_embeddings_test, np.array(total_meta_results_test[\"groups\"]), return_dist = False)\n",
    "            \n",
    "        group_wise_indexes = [\"Acc.\", \"Centr. Norm.\"]\n",
    "        columns = [\"Avg.\",\"Worst\", \"group0\", \"group1\", \"group2\", \"group3\"]\n",
    "        \n",
    "        dfs =[]\n",
    "   \n",
    "        values = [list(total_meta_results_train[\"group_accs\"].values())[:-1], \n",
    "                [list(group_wise_stat_ebd[\"train\"][\"mean_vector_norm\"].values())[0]] + [0] + list(group_wise_stat_ebd[\"train\"][\"mean_vector_norm\"].values())[1:]]\n",
    "        df = pd.DataFrame(values, index=group_wise_indexes, columns = columns).round(3)\n",
    "        dfs.append(df)\n",
    "        values = [list(total_meta_results_val[\"group_accs\"].values())[:-1], \n",
    "                [list(group_wise_stat_ebd[\"val\"][\"mean_vector_norm\"].values())[0]] + [0] + list(group_wise_stat_ebd[\"test\"][\"mean_vector_norm\"].values())[1:]]\n",
    "        df = pd.DataFrame(values, index=group_wise_indexes, columns = columns).round(3)\n",
    "        dfs.append(df)\n",
    "        values = [list(total_meta_results_test[\"group_accs\"].values())[:-1], \n",
    "                [list(group_wise_stat_ebd[\"test\"][\"mean_vector_norm\"].values())[0]] + [0] + list(group_wise_stat_ebd[\"val\"][\"mean_vector_norm\"].values())[1:]]\n",
    "        df = pd.DataFrame(values, index=group_wise_indexes, columns = columns).round(3)\n",
    "        dfs.append(df)\n",
    "        \n",
    "        if group_mean_ebd is not None:  # group label : (4, 2024) X 3\n",
    "            add_group_labels_train = [group for group in group_wise_stat_ebd['train'][\"mean_vector\"].keys()] # Waterbird\n",
    "            add_group_mean_ebds_train = [ebd for ebd in group_wise_stat_ebd['train'][\"mean_vector\"].values()]\n",
    "            add_group_labels_val = [group for group in group_wise_stat_ebd['val'][\"mean_vector\"].keys()] # Waterbird\n",
    "            add_group_mean_ebds_val = [ebd for ebd in group_wise_stat_ebd['val'][\"mean_vector\"].values()]\n",
    "            add_group_labels_test = [group for group in group_wise_stat_ebd['test'][\"mean_vector\"].keys()] # Waterbird\n",
    "            add_group_mean_ebds_test = [ebd for ebd in group_wise_stat_ebd['test'][\"mean_vector\"].values()]\n",
    "\n",
    "            group_mean_ebd = (add_group_mean_ebds_train, add_group_mean_ebds_val, add_group_mean_ebds_test,\n",
    "                              add_group_labels_train, add_group_labels_val, add_group_labels_test)\n",
    "        \n",
    "        \n",
    "        labels_train_all = [] # [2, [N_tr]] \n",
    "        labels_val_all = [] # [2, [N_val]]\n",
    "        labels_test_all = [] # [2, [N_test]]\n",
    "        \n",
    "        embeddings_train_all = [] # [2, [N_tr]] \n",
    "        embeddings_val_all = [] # [2, [N_val]]\n",
    "        embeddings_test_all = [] # [2, [N_test]]\n",
    "        \n",
    "        for idx in [-2, -1]:    \n",
    "            # Before\n",
    "            labels_train_all.append(np.array(train_ebd_q[idx][1][label_type+'s']))\n",
    "            labels_val_all.append(np.array(val_ebd_q[idx][1][label_type+'s']))\n",
    "            labels_test_all.append(np.array(test_ebd_q[idx][1][label_type+'s']))\n",
    "            \n",
    "            embeddings_train_all.append(train_ebd_q[idx][0])\n",
    "            embeddings_val_all.append(val_ebd_q[idx][0])\n",
    "            embeddings_test_all.append(test_ebd_q[idx][0])\n",
    "        \n",
    "        labels_train_all = np.array(labels_train_all); labels_val_all = np.array(labels_val_all); labels_test_all = np.array(labels_test_all)\n",
    "        embeddings_train_all = np.array(embeddings_train_all); embeddings_val_all = np.array(embeddings_val_all); embeddings_test_all = np.array(embeddings_test_all)\n",
    "        \n",
    "        # return labels_train_all, labels_val_all, labels_test_all, embeddings_train_all, embeddings_val_all, embeddings_test_all\n",
    "        n_train = len(labels_train_all[-2]) + len(labels_train_all[-1])\n",
    "        n_val = len(labels_val_all[-2]) + len(labels_val_all[-1])\n",
    "        n_test = len(labels_test_all[-2]) + len(labels_test_all[-1])\n",
    "        \n",
    "        print(f\"Number of samples for Visualization : tr : [{n_train}], val : [{n_val}], test : [{n_test}]\")\n",
    "        total_labels = np.concatenate([labels_train_all, labels_val_all, labels_test_all], axis=0) # [6]\n",
    "        total_embeddings = np.concatenate([embeddings_train, embeddings_val, embeddings_test], axis=0)\n",
    "        print(\"ㄴ total embedddings  : \", total_embeddings.shape)\n",
    "\n",
    "        if text_ebd is not None: # (# of templates, 2048) add to embedding pool\n",
    "            print(\"Add [text] embedding to umap-pool\")\n",
    "            text_templates = [list(temp_feat_pair.keys())[0] for temp_feat_pair in text_ebd]\n",
    "            text_features = [list(temp_feat_pair.values())[0] for temp_feat_pair in text_ebd]\n",
    "            \n",
    "            print(f\"> Calculate {num_nn_text_ebd} Nearest samples for visualization of [text prompts]\")\n",
    "            nearest_averaged_text_features = []\n",
    "            for i in range(len(text_features)):\n",
    "                nearest_indices = find_closest_sample(total_embeddings, text_features[i], top_k=num_nn_text_ebd)\n",
    "                nearest_averaged_embedding = total_embeddings[nearest_indices].mean(axis=0)\n",
    "                nearest_averaged_text_features.append(nearest_averaged_embedding)\n",
    "            \n",
    "            # # Scale text-embeddings(12.xx) to image-scale (2.xx)\n",
    "            # [print(compute_vector_norm(feat)) for feat in text_features]\n",
    "            # norm_full_image = compute_vector_norm(total_embeddings.mean(axis=0))\n",
    "            # text_features = [(text_feat / compute_vector_norm(text_feat))*norm_full_image for text_feat in text_features]\n",
    "            # [print(compute_vector_norm(feat)) for feat in text_features]\n",
    "            \n",
    "            total_embeddings = np.concatenate([total_embeddings, np.array(nearest_averaged_text_features)], axis=0)\n",
    "            print(\"ㄴ total embedddings  : \", total_embeddings.shape)\n",
    "            # Label : 0, 1\n",
    "        \n",
    "        if  group_mean_ebd is not None:\n",
    "            # 각각 (4, 2024), (4, 2024), (4, 2024)\n",
    "            # label : 0, 1 ,2, 3\n",
    "            print(\"Add [group] (mean) embedding to umap-pool\")\n",
    "            (add_group_mean_ebds_train, add_group_mean_ebds_val, add_group_mean_ebds_test,\n",
    "                                add_group_labels_train, add_group_labels_val, add_group_labels_test) = group_mean_ebd \n",
    "            \n",
    "            add_group_mean_ebds = np.concatenate([add_group_mean_ebds_train, add_group_mean_ebds_val, add_group_mean_ebds_test], axis=0)\n",
    "            total_embeddings = np.concatenate([total_embeddings, add_group_mean_ebds])\n",
    "            \n",
    "            print(\"ㄴ total embedddings  : \", total_embeddings.shape)\n",
    "        \n",
    "        print(\"> Projection all the embeddings to [1024d l2-norm sphere]\")\n",
    "        total_embeddings = total_embeddings / np.linalg.norm(total_embeddings, axis=1, keepdims=True)\n",
    "        print(f\"> Start Umap fitting.... (# of samples {total_embeddings.shape[0]})(dim {total_embeddings.shape[1]})\")\n",
    "        if method == 'umap':\n",
    "            standard_embedding = umap.UMAP(random_state=42, n_components=reduced_dim).fit_transform(total_embeddings)\n",
    "        else:  # method == 'mds'\n",
    "            standard_embedding = MDS(n_components=reduced_dim,\n",
    "                                    random_state=42).fit_transform(total_embeddings)\n",
    "        \n",
    "        standard_embedding_train = standard_embedding[: n_train]\n",
    "        standard_embedding_val = standard_embedding[n_train: n_train + n_val]\n",
    "        standard_embedding_test = standard_embedding[n_train+n_val : n_train+n_val+n_test]\n",
    "        \n",
    "        offset_for_add = n_train+n_val+n_test\n",
    "        # if (text_ebd is not None) or (group_mean_ebd is not None):\n",
    "        #     standard_zero_ebd = standard_embedding[offset_for_add]\n",
    "        #     offset_for_add = offset_for_add + 1 \n",
    "        #     print(\"standard [zero] ebd' shape:\", standard_zero_ebd.shape)\n",
    "            \n",
    "        if text_ebd is not None:\n",
    "            offset_for_text_ebd = len(text_templates)\n",
    "            standard_text_ebd = standard_embedding[offset_for_add: offset_for_add + offset_for_text_ebd]\n",
    "            # print(\"standard [text]] ebd' shape:\", standard_text_ebd.shape)\n",
    "            offset_for_add = offset_for_add + offset_for_text_ebd\n",
    "        \n",
    "        if group_mean_ebd is not None:\n",
    "            standard_group_mean_ebd_train = standard_embedding[offset_for_add: offset_for_add + 5] # Mean + Group 4\n",
    "            standard_group_mean_ebd_val = standard_embedding[offset_for_add + 5: offset_for_add + 10]\n",
    "            standard_group_mean_ebd_test = standard_embedding[offset_for_add + 10: offset_for_add + 15]\n",
    "            # print(\"standard [group] ebd' shape:\", standard_group_mean_ebd_test.shape)\n",
    "                        \n",
    "        fig = plt.figure(figsize=figsize)\n",
    "\n",
    "        # Zero -> Text Prompt (원점 보정) -> CLIP에서는 안 되네.. 너무 Outlier인듯.\n",
    "        standard_origin_ebd = standard_embedding.mean(axis=0)\n",
    "        \n",
    "        # standard_zero_ebd : all the ploting\n",
    "        # standard_text_ebd : all the ploting \n",
    "        \n",
    "        \n",
    "        fig, axs =plt.subplots(2,3, figsize=figsize,  gridspec_kw={'height_ratios': [2.5, 1]})\n",
    "\n",
    "        for idx, (each_standard_embedding, labels, each_standard_group_mean_ebd, each_df, sub_title) in enumerate(zip([standard_embedding_train, standard_embedding_val, standard_embedding_test],\n",
    "                                                                            [labels_train, labels_val, labels_test],\n",
    "                                                                            [standard_group_mean_ebd_train, standard_group_mean_ebd_val, standard_group_mean_ebd_test],\n",
    "                                                                            passed_dfs,\n",
    "                                                                            [\"Train set\", \"Val set\", \"Test set\"])):\n",
    "            # Group : train/val/test\n",
    "            if label_type == 'confidence':\n",
    "                colors = np.array(labels)\n",
    "            else:    \n",
    "                colors = np.array(labels).astype(int)\n",
    "                num_colors = len(np.unique(colors))\n",
    "                if num_colors==2:\n",
    "                    colors_template = ['midnightblue', 'red']\n",
    "                elif num_colors==4: # Group\n",
    "                    colors_template = ['midnightblue', 'darkorange', 'red', 'royalblue']\n",
    "                colors = [colors_template[val] for val in np.array(labels)] \n",
    "            \n",
    "            if reduced_dim==2:\n",
    "                # ax = fig.add_subplot(2, 3, idx+1)\n",
    "                # Continuous\n",
    "                if label_type == 'confidence':\n",
    "                    scatter = axs[0][idx].scatter(each_standard_embedding[:, 0], each_standard_embedding[:, 1],\n",
    "                            c=colors, s=1.0, alpha=1,\n",
    "                            cmap=plt.cm.get_cmap('coolwarm'))\n",
    "                # Discrete\n",
    "                else:\n",
    "                    axs[0][idx].scatter(each_standard_embedding[:, 0], each_standard_embedding[:, 1], c=colors, s=1.0, alpha=1)\n",
    "                \n",
    "                # print(\"X:\", each_standard_embedding[0, 0])\n",
    "                # print(\"Y:\", each_standard_embedding[0, 1])\n",
    "                # axs[0][0].annotate(\"Test~~\", xytext=each_standard_embedding[0], xy=standard_origin_ebd, arrowprops=dict(arrowstyle=\"<-\"), size=30)\n",
    "                if text_ebd is not None:\n",
    "                    for idx_, ebd in enumerate(standard_text_ebd):\n",
    "                        if remove_prefix:\n",
    "                            if set_bbox:\n",
    "                                axs[0][idx].annotate(f'\"{text_templates[idx_].split(\"a photo of \")[-1]}\"', xytext=ebd, xy=standard_origin_ebd, arrowprops=dict(arrowstyle=\"<|-\"), bbox=dict(boxstyle=\"round4\", fc=\"w\"))\n",
    "                            else:\n",
    "                                axs[0][idx].annotate(f'\"{text_templates[idx_].split(\"a photo of \")[-1]}\"', xytext=ebd, xy=standard_origin_ebd, arrowprops=dict(arrowstyle=\"<|-\") ) # bbox=dict(boxstyle=\"round4\", fc=\"w\")\n",
    "                        else:\n",
    "                            if set_bbox:\n",
    "                                axs[0][idx].annotate(f'\"{text_templates[idx_]}\"', xytext=ebd, xy=standard_origin_ebd, arrowprops=dict(arrowstyle=\"<|-\"), bbox=dict(boxstyle=\"round4\", fc=\"w\"))\n",
    "                            else:\n",
    "                                axs[0][idx].annotate(f'\"{text_templates[idx_]}\"', xytext=ebd, xy=standard_origin_ebd, arrowprops=dict(arrowstyle=\"<|-\")) # bbox=dict(boxstyle=\"round4\", fc=\"w\")\n",
    "                if group_mean_ebd is not None:\n",
    "                    for idx_, ebd in enumerate(each_standard_group_mean_ebd):\n",
    "                        if idx_ ==0:\n",
    "                            continue # Pass the average vector.\n",
    "                        axs[0][idx].annotate(f\"Group {idx_-1}\", xytext=ebd, xy=standard_origin_ebd, arrowprops=dict(arrowstyle=\"<-\"))\n",
    "                # ax = fig.add_subplot(2, 3, idx+4)\n",
    "                axs[1][idx].axis('tight')\n",
    "                axs[1][idx].axis('off')\n",
    "                table = axs[1][idx].table(cellText=each_df.values, colLabels=each_df.columns, rowLabels=each_df.index, loc='center')\n",
    "                # ax.set_box_aspect(1)\n",
    "\n",
    "                \n",
    "            table.scale(1, 2)  # Adjust the scale factors to control the size of the table (매커니즘 몰라ㅏ)\n",
    "            \n",
    "                \n",
    "            legend_elements = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10) for color in colors_template]\n",
    "            legend_labels = [legend_labels_dict[label_type][label] for label in range(len(np.unique(labels)))]\n",
    "            axs[0][idx].legend(legend_elements, legend_labels)\n",
    "                \n",
    "            axs[0][idx].set_title(sub_title)\n",
    "                    \n",
    "        suffix = '' if title_suffix is None else f' {title_suffix}'\n",
    "        plt.suptitle(f'Color by [{label_type}] labels{suffix}', size=20)\n",
    "        # plt.tight_layout(rect=[0, 0, 1, 0.95]) \n",
    "            \n",
    "        if save:\n",
    "            fpath = f'{save_id}{ftype}'\n",
    "            if not os.path.exists(fig_save_root):\n",
    "                os.mkdir(fig_save_root)\n",
    "            \n",
    "            fpath = os.path.join(fig_save_root, fpath)\n",
    "            plt.savefig(fname=fpath, dpi=300, bbox_inches=\"tight\")\n",
    "            print(f'Saved {method} to {fpath}!')\n",
    "            \n",
    "        if display_image:\n",
    "            plt.show()\n",
    "        plt.close('all')\n",
    "        del standard_embedding\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ebd_q = train_ebd_q[:4]\n",
    "val_ebd_q = val_ebd_q[:4]\n",
    "test_ebd_q = test_ebd_q[:4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_handler = VisHandler(opt)\n",
    "\n",
    "vis_handler.SaveTextEmbeddings(opt.text_embedding_dir) # class 임베딩 경로 (unnormalized!) (c.f. clip_inference_including_group_with_unnorm.py)\n",
    "vis_handler.SaveTextEmbeddings(opt.text_spurious_embedding_dir) # spurious 임베딩 경로 (unnormalized!) (c.f. clip_inference_including_group_with_unnorm.py)\n",
    "# vis_handler.SaveTextEmbeddings(opt.text_group_embedding_dir) # group 임베딩 경로 (unnormalized!) (c.f. clip_inference_including_group_with_unnorm.py)\n",
    "\n",
    "num_nn_text_ebd = 10 # 각각의 Text embedding에서 제일 가까운 [num_nn_text_ebd] 개수의 이미지 임베딩을 뽑아, 평균낸 임베딩을 해당 Text embedding의 visualization에 사용함. \n",
    "set_bbox=False # True: 가독성 그나마 좋아지나, 가끔 가릴 때 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Calculating [Group-wise] Statistics...\n"
     ]
    }
   ],
   "source": [
    "run_name = \"임의\"\n",
    "fig_save_root = os.path.join(\"figure\", run_name)\n",
    "\n",
    "fig_save_root    \n",
    "save_id = f\"class_{epoch}ep_ca\"\n",
    "title_suffix = f\"After [Contrastive] (Epoch: {epoch})\"\n",
    "train_l, val_l, test_l, train_ebd, val_ebd, test_ebd = vis_handler.plot_umap_for_ca(train_ebd_q, val_ebd_q, test_ebd_q, 'target', fig_save_root, save_id, \n",
    "                             vis_handler.legend_labels_dict, title_suffix = title_suffix,\n",
    "                             text_ebd = True, num_nn_text_ebd = num_nn_text_ebd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9590,)\n",
      "(2398,)\n",
      "(11588,)\n",
      "(9590, 1024)\n",
      "(2398, 1024)\n",
      "(11588, 1024)\n",
      "(23576,)\n",
      "(23576, 1024)\n"
     ]
    }
   ],
   "source": [
    "train_l = train_l.flatten()\n",
    "val_l = val_l.flatten()\n",
    "test_l = test_l.flatten()\n",
    "\n",
    "train_ebd = train_ebd.reshape(-1, train_ebd.shape[-1])\n",
    "val_ebd = val_ebd.reshape(-1, val_ebd.shape[-1])\n",
    "test_ebd = test_ebd.reshape(-1, test_ebd.shape[-1])\n",
    "\n",
    "print(train_l.shape)\n",
    "print(val_l.shape)\n",
    "print(test_l.shape)\n",
    "print(train_ebd.shape)\n",
    "print(val_ebd.shape)\n",
    "print(test_ebd.shape)\n",
    "\n",
    "total_labels = np.concatenate([train_l, val_l, test_l])\n",
    "print(total_labels.shape)\n",
    "total_embeddings = np.concatenate([train_ebd, val_ebd, test_ebd])\n",
    "print(total_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetGroupWiseStatEbd(embeddings, group_labels, return_dist = True):\n",
    "    # in Each group\n",
    "    statistics = {\n",
    "        'mean_vector' : {},\n",
    "        'mean_vector_norm' : {},\n",
    "        'pairwise_distance' : {},\n",
    "    }\n",
    "    \n",
    "    # Full datasets\n",
    "    mean_vector = compute_mean_vector(embeddings, axis=0)\n",
    "    vector_norm = compute_vector_norm(mean_vector)\n",
    "    if return_dist:\n",
    "        pairwise_distance = compute_averaged_pairwise_distance(embeddings)\n",
    "    \n",
    "    statistics['mean_vector']['full'] = mean_vector\n",
    "    statistics['mean_vector_norm']['full'] = vector_norm\n",
    "    if return_dist:\n",
    "        statistics['pairwise_distance']['full'] = pairwise_distance\n",
    "\n",
    "    for group in np.unique(group_labels): # 0, 1, 2, 3\n",
    "        group_indices = np.where(group_labels == group)[0]\n",
    "        group_embeddings = embeddings[group_indices]\n",
    "        \n",
    "        mean_vector = compute_mean_vector(group_embeddings, axis=0)\n",
    "        vector_norm = compute_vector_norm(mean_vector)\n",
    "        if return_dist:\n",
    "            pairwise_distance = compute_averaged_pairwise_distance(group_embeddings)\n",
    "        \n",
    "        statistics['mean_vector'][group] = mean_vector\n",
    "        statistics['mean_vector_norm'][group] = vector_norm\n",
    "        if return_dist:\n",
    "            statistics['pairwise_distance'][group] = pairwise_distance\n",
    "    \n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_adapter_with_return(opt, val_loader, classifier, criterion, get_yp_func, train_group_ratio, target, print_label='Test'):\n",
    "    \"\"\"\n",
    "    For adapter.\n",
    "    - Validation\n",
    "    - Return data (Adapted embeddings, labels, group-labels, ....)\n",
    "    \"\"\"\n",
    "    \n",
    "    total_embeddings = []\n",
    "    total_labels = []\n",
    "    total_spuriouss = []\n",
    "    total_groups = []\n",
    "    # total_confidences = []\n",
    "    total_predictions = [] # Zero-shot\n",
    "    \n",
    "    \n",
    "    classifier.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(val_loader.dataset.n_groups)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            embeddings, all_labels, img_filenames = data # all_labels.keys() : ['class', 'group', 'spurious', 'ebd_pred'(CLIP-zeroshot)] \n",
    "            labels = all_labels[target] # target : one of [class, spurious, group]\n",
    "            \n",
    "            groups = all_labels['group'] # For evaluating group accuracy (and further developing group-information-aware approaches)\n",
    "            places = all_labels[\"spurious\"]\n",
    "            \n",
    "            \n",
    "            embeddings = embeddings.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "            bsz = labels.shape[0]\n",
    "            \n",
    "            # NOTE Embedding 추가\n",
    "            # embeddings = embeddings / embeddings.norm(dim=-1, keepdim=True)\n",
    "            \n",
    "            # forward\n",
    "            assert \"adapter\" in opt.tl_method\n",
    "            \n",
    "            image_features = classifier.adapter(embeddings)\n",
    "            \n",
    "            image_features_normalized = image_features / image_features.norm(dim=-1, keepdim=True) # Normalized (B, 1024)\n",
    "            text_features_normalized = classifier.text_features / classifier.text_features.norm(dim=0, keepdim=True) # Normalized # (1024, 2)\n",
    "            logits = image_features_normalized @ text_features_normalized / classifier.temperature # (B, 1024) X (1024, 2) = # (B, 2)\n",
    "        \n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            \n",
    "            predicted = logits.argmax(axis=1)\n",
    "        \n",
    "            # save\n",
    "            total_labels.extend(labels.cpu().numpy())\n",
    "            total_groups.extend(groups.numpy())\n",
    "            total_spuriouss.extend(places.numpy())\n",
    "            total_predictions.extend(predicted.cpu().numpy())\n",
    "            total_embeddings.extend(image_features.cpu().numpy())\n",
    "    \n",
    "            \n",
    "            # update metric\n",
    "            losses.update(loss.item(), bsz)\n",
    "            acc1 = accuracy(logits, labels, bsz)\n",
    "            acc.update(acc1, bsz)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            # Update acc dict\n",
    "            update_dict(acc_groups, labels, groups, logits)\n",
    "        \n",
    "            if opt.watch_batch_results:\n",
    "                if (idx+1) % opt.print_freq == 0:\n",
    "                    print(f'{print_label}: [{0}/{1}]\\t'\n",
    "                        'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                        'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                        'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                        idx, len(val_loader), batch_time=batch_time,\n",
    "                        loss=losses, acc=acc))\n",
    "    \n",
    "    total_embeddings = np.array(total_embeddings) # (# of full data, feat_dim)\n",
    "\n",
    "    # 딱히 List로 반환해도 되는 친구들이라 List로 해놨었나.. \n",
    "    total_meta_results = {\"targets\" : total_labels, \"spuriouss\": total_spuriouss, \"groups\" : total_groups, \n",
    "                             \"predictions\": total_predictions}\n",
    "                    \n",
    "    group_acc = get_results(acc_groups, get_yp_func)\n",
    "\n",
    "    # NOTE Add Weighted mean acc.\n",
    "    groups = range(val_loader.dataset.n_groups) # 0, 1, 2, 3\n",
    "    group_acc_indiv =  [group_acc[f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\"] for g in groups]\n",
    "    weighted_mean_acc = (np.array(group_acc_indiv) * np.array(train_group_ratio)).sum() # Weighted Sum \\\n",
    "    \n",
    "    group_acc[\"weighted_mean_acc\"] = weighted_mean_acc\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print}\n",
    "    group_acc = {key: np.round(value, 4) for key, value in group_acc.items()}\n",
    "    print(f\"{print_label}:\", str(group_acc))\n",
    "\n",
    "    return (losses.avg, acc.avg, group_acc), (total_embeddings, total_meta_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinsu/workstation/project/debiasing-multi-modal/visualizer_supcon.py:1113: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sliced_data_incorrect = np.array(sliced_data_incorrect)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> set and load Contrastive data-handler\n",
      "========================================================================\n",
      ">> Slice 0, target: 0, counts: 3588\n",
      ">> Slice 0, target: 1, counts: 254\n",
      "Slice 0 % incorrect: 6.6111 %\n",
      "ix class counts [1] [254]\n",
      "nix class counts [0] [3588]\n",
      "Slice 0 # negative (correct): 3588\n",
      "Slice 0 % negative (correct): 93.3889 %\n",
      "Unique negative targets: (array([0]), array([3588]))\n",
      "nix class counts(for positive) [0] [3588]\n",
      "Slice 0 # Positive: (for 'other' slice) 3588\n",
      ">> Slice 1, target: 0, counts: 94\n",
      ">> Slice 1, target: 1, counts: 859\n",
      "Slice 1 % incorrect: 9.8636 %\n",
      "ix class counts [0] [94]\n",
      "nix class counts [1] [859]\n",
      "Slice 1 # negative (correct): 859\n",
      "Slice 1 % negative (correct): 90.1364 %\n",
      "Unique negative targets: (array([1]), array([859]))\n",
      "nix class counts(for positive) [1] [859]\n",
      "Slice 1 # Positive: (for 'other' slice) 859\n",
      "> Add Easy Negatives samples (0523)\n",
      ">> % Negatives for Anoter Slice 1): 6.6111 %\n",
      "859 -> 1113\n",
      "> Add Easy Negatives samples (0523)\n",
      ">> % Negatives for Anoter Slice 0): 9.8636 %\n",
      "3588 -> 3682\n",
      "given args: number of anchors: 1\n",
      "given args: number of positives: 859\n",
      "given args: number of negatives: 1113\n",
      "given samples: number of positives: 859\n",
      "given samples: number of negatives: 1113\n",
      "Adjusted number of anchors:   1\n",
      "Adjusted number of positives: 859\n",
      "Adjusted number of negatives: 1113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data from slice 0: 100%|██████████| 254/254 [00:00<00:00, 9795.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_samples_per_slice.shape (254, 1973)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data from slice 1: 100%|██████████| 94/94 [00:00<00:00, 9503.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_samples_per_slice.shape (94, 1973)\n",
      "No balancing contrastive samples (Focusing on class with more prediction errors)\n",
      "Shuffle for concatenated-contrastive-batch\n",
      "First 10 Anchor indices:  [  97    4 4594 2419 3506  177  152 1510 1262 2317]\n",
      "Shape of Contrastive Batch Samples :  (348, 1973)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(resampled_set.targets) 686604\n",
      "> batchsize of contrastive data loader : 63136\n",
      "> len of contrastive dataset : 686604\n",
      "> Class 0\n",
      "# of samples : 3682\n",
      "# of positives :  3588\n",
      "# of negatives :  94\n",
      "> Class 1\n",
      "# of samples : 1113\n",
      "# of positives :  859\n",
      "# of negatives :  254\n",
      "Re-sampling for [Cross Entropy Loader]\n",
      "> Class 0 Weight: 38.170\n",
      "> Class 1 Weight: 3.382\n",
      "> Final sampling weights set : [ 1.          3.38188976 38.17021277]\n",
      ">> Corresponding Counts : [4447  254   94] / 4795\n",
      "Distribution of some mini batch \n",
      "[70, 33, 25]\n",
      "[75, 25, 3, 25]\n",
      "[73, 32, 2, 21]\n",
      "[73, 26, 4, 25]\n",
      "[85, 18, 2, 23]\n",
      "[85, 18, 2, 23]\n",
      "[85, 20, 2, 21]\n",
      "[80, 23, 1, 24]\n",
      "[77, 29, 22]\n",
      "[85, 21, 2, 20]\n",
      "[72, 25, 1, 30]\n",
      "========================================================================\n",
      "Set Optimizer: SGD (default)\n",
      "========================================================================\n",
      "Train(Initial Adapter): {'weighted_mean_acc': 0.9449, 'worst_acc': 0.3929, 'acc_0_0': 0.9917, 'acc_0_1': 0.9076, 'acc_1_0': 0.3929, 'acc_1_1': 0.8259, 'mean_acc': 0.9449}\n",
      "--- Epoch 1 ---\n",
      ">>CA Optimzer.step\n",
      "Loss in Train(Contrastive Learning): 0.252 Pos:0.0706, Neg: 0.0713\n",
      "Train(After CA): {'weighted_mean_acc': 0.9072, 'worst_acc': 0.0893, 'acc_0_0': 0.9997, 'acc_0_1': 0.9891, 'acc_1_0': 0.0893, 'acc_1_1': 0.6301, 'mean_acc': 0.9072}\n",
      "Val(After CA): {'weighted_mean_acc': 0.9165, 'worst_acc': 0.1955, 'acc_0_0': 0.9979, 'acc_0_1': 0.9678, 'acc_1_0': 0.1955, 'acc_1_1': 0.6767, 'mean_acc': 0.8616}\n",
      "Test(After CA): {'weighted_mean_acc': 0.9047, 'worst_acc': 0.1667, 'acc_0_0': 0.9991, 'acc_0_1': 0.953, 'acc_1_0': 0.1667, 'acc_1_1': 0.6231, 'mean_acc': 0.8473}\n",
      "Train(Cross entropy)(for all training set): {'worst_acc': 0.4706, 'acc_0_0': 0.9931, 'acc_0_1': 0.9665, 'acc_1_0': 0.4706, 'acc_1_1': 0.8173, 'mean_acc': 0.9474}\n",
      "Train(After CE): {'weighted_mean_acc': 0.9618, 'worst_acc': 0.6786, 'acc_0_0': 0.9891, 'acc_0_1': 0.8533, 'acc_1_0': 0.6786, 'acc_1_1': 0.9054, 'mean_acc': 0.9618}\n",
      "Val(After CE): {'weighted_mean_acc': 0.9596, 'worst_acc': 0.5639, 'acc_0_0': 0.9914, 'acc_0_1': 0.8047, 'acc_1_0': 0.5639, 'acc_1_1': 0.9023, 'mean_acc': 0.8616}\n",
      "Test(After CE): {'weighted_mean_acc': 0.9525, 'worst_acc': 0.5841, 'acc_0_0': 0.9867, 'acc_0_1': 0.7583, 'acc_1_0': 0.5841, 'acc_1_1': 0.8925, 'mean_acc': 0.8428}\n",
      "No balancing contrastive samples (Focusing on class with more prediction errors)\n",
      "Shuffle for concatenated-contrastive-batch\n",
      "First 10 Anchor indices:  [2455  683 1065  154 1052 2124 1467 2447 2399 3398]\n",
      "Shape of Contrastive Batch Samples :  (348, 1973)\n",
      "len(resampled_set.targets) 686604\n",
      "> batchsize of contrastive data loader : 63136\n",
      "> len of contrastive dataset : 686604\n",
      "--- Epoch 2 ---\n",
      ">>CA Optimzer.step\n",
      "Loss in Train(Contrastive Learning): 0.251 Pos:0.0642, Neg: 0.0569\n",
      "Train(After CA): {'weighted_mean_acc': 0.9333, 'worst_acc': 0.2321, 'acc_0_0': 0.9994, 'acc_0_1': 0.9728, 'acc_1_0': 0.2321, 'acc_1_1': 0.7446, 'mean_acc': 0.9333}\n",
      "Val(After CA): {'weighted_mean_acc': 0.943, 'worst_acc': 0.2857, 'acc_0_0': 0.9979, 'acc_0_1': 0.9378, 'acc_1_0': 0.2857, 'acc_1_1': 0.797, 'mean_acc': 0.8732}\n",
      "Test(After CA): {'weighted_mean_acc': 0.9289, 'worst_acc': 0.271, 'acc_0_0': 0.9982, 'acc_0_1': 0.9228, 'acc_1_0': 0.271, 'acc_1_1': 0.7352, 'mean_acc': 0.8592}\n",
      "Train(Cross entropy)(for all training set): {'worst_acc': 0.6395, 'acc_0_0': 0.9941, 'acc_0_1': 0.9875, 'acc_1_0': 0.6395, 'acc_1_1': 0.8813, 'mean_acc': 0.9664}\n",
      "Train(After CE): {'weighted_mean_acc': 0.9681, 'worst_acc': 0.7321, 'acc_0_0': 0.9931, 'acc_0_1': 0.837, 'acc_1_0': 0.7321, 'acc_1_1': 0.9205, 'mean_acc': 0.9681}\n",
      "Val(After CE): {'weighted_mean_acc': 0.9599, 'worst_acc': 0.5338, 'acc_0_0': 0.9936, 'acc_0_1': 0.7811, 'acc_1_0': 0.5338, 'acc_1_1': 0.9023, 'mean_acc': 0.8499}\n",
      "Test(After CE): {'weighted_mean_acc': 0.9571, 'worst_acc': 0.5639, 'acc_0_0': 0.9929, 'acc_0_1': 0.7486, 'acc_1_0': 0.5639, 'acc_1_1': 0.8956, 'mean_acc': 0.8395}\n",
      "No balancing contrastive samples (Focusing on class with more prediction errors)\n",
      "Shuffle for concatenated-contrastive-batch\n",
      "First 10 Anchor indices:  [2271 2446 1426  140 2021 1411 1466 3920 3861 2445]\n",
      "Shape of Contrastive Batch Samples :  (348, 1973)\n",
      "len(resampled_set.targets) 686604\n",
      "> batchsize of contrastive data loader : 63136\n",
      "> len of contrastive dataset : 686604\n",
      "--- Epoch 3 ---\n",
      ">>CA Optimzer.step\n",
      "Loss in Train(Contrastive Learning): 0.249 Pos:0.0714, Neg: 0.0677\n",
      "Train(After CA): {'weighted_mean_acc': 0.9449, 'worst_acc': 0.2143, 'acc_0_0': 0.9997, 'acc_0_1': 0.962, 'acc_1_0': 0.2143, 'acc_1_1': 0.7994, 'mean_acc': 0.9449}\n",
      "Val(After CA): {'weighted_mean_acc': 0.9426, 'worst_acc': 0.3008, 'acc_0_0': 0.9979, 'acc_0_1': 0.9227, 'acc_1_0': 0.3008, 'acc_1_1': 0.797, 'mean_acc': 0.8691}\n",
      "Test(After CA): {'weighted_mean_acc': 0.9324, 'worst_acc': 0.3006, 'acc_0_0': 0.9982, 'acc_0_1': 0.8993, 'acc_1_0': 0.3006, 'acc_1_1': 0.7539, 'mean_acc': 0.8554}\n",
      "Train(Cross entropy)(for all training set): {'worst_acc': 0.625, 'acc_0_0': 0.9962, 'acc_0_1': 0.9801, 'acc_1_0': 0.625, 'acc_1_1': 0.9233, 'mean_acc': 0.9746}\n",
      "Train(After CE): {'weighted_mean_acc': 0.9743, 'worst_acc': 0.788, 'acc_0_0': 0.9909, 'acc_0_1': 0.788, 'acc_1_0': 0.8036, 'acc_1_1': 0.9612, 'mean_acc': 0.9743}\n",
      "Val(After CE): {'weighted_mean_acc': 0.9598, 'worst_acc': 0.609, 'acc_0_0': 0.9914, 'acc_0_1': 0.6652, 'acc_1_0': 0.609, 'acc_1_1': 0.9248, 'mean_acc': 0.8148}\n",
      "Test(After CE): {'weighted_mean_acc': 0.9554, 'worst_acc': 0.6262, 'acc_0_0': 0.9854, 'acc_0_1': 0.6421, 'acc_1_0': 0.6262, 'acc_1_1': 0.9283, 'mean_acc': 0.8057}\n",
      "No balancing contrastive samples (Focusing on class with more prediction errors)\n",
      "Shuffle for concatenated-contrastive-batch\n",
      "First 10 Anchor indices:  [4594  102 3527 1411   95 2107 1527 2464 1970 1152]\n",
      "Shape of Contrastive Batch Samples :  (348, 1973)\n",
      "len(resampled_set.targets) 686604\n",
      "> batchsize of contrastive data loader : 63136\n",
      "> len of contrastive dataset : 686604\n",
      "--- Epoch 4 ---\n",
      ">>CA Optimzer.step\n",
      "Loss in Train(Contrastive Learning): 0.249 Pos:0.0775, Neg: 0.0741\n",
      "Train(After CA): {'weighted_mean_acc': 0.9604, 'worst_acc': 0.3214, 'acc_0_0': 0.9989, 'acc_0_1': 0.9511, 'acc_1_0': 0.3214, 'acc_1_1': 0.8685, 'mean_acc': 0.9604}\n",
      "Val(After CA): {'weighted_mean_acc': 0.9511, 'worst_acc': 0.391, 'acc_0_0': 0.9979, 'acc_0_1': 0.8584, 'acc_1_0': 0.391, 'acc_1_1': 0.8421, 'mean_acc': 0.859}\n",
      "Test(After CA): {'weighted_mean_acc': 0.9466, 'worst_acc': 0.352, 'acc_0_0': 0.9973, 'acc_0_1': 0.8412, 'acc_1_0': 0.352, 'acc_1_1': 0.8287, 'mean_acc': 0.8464}\n",
      "Train(Cross entropy)(for all training set): {'worst_acc': 0.7059, 'acc_0_0': 0.9948, 'acc_0_1': 0.9842, 'acc_1_0': 0.7059, 'acc_1_1': 0.9287, 'mean_acc': 0.9771}\n",
      "Train(After CE): {'weighted_mean_acc': 0.9783, 'worst_acc': 0.7321, 'acc_0_0': 0.9977, 'acc_0_1': 0.8641, 'acc_1_0': 0.7321, 'acc_1_1': 0.947, 'mean_acc': 0.9783}\n",
      "Val(After CE): {'weighted_mean_acc': 0.9609, 'worst_acc': 0.5038, 'acc_0_0': 0.9936, 'acc_0_1': 0.7725, 'acc_1_0': 0.5038, 'acc_1_1': 0.9098, 'mean_acc': 0.844}\n",
      "Test(After CE): {'weighted_mean_acc': 0.9598, 'worst_acc': 0.5436, 'acc_0_0': 0.9929, 'acc_0_1': 0.7446, 'acc_1_0': 0.5436, 'acc_1_1': 0.9097, 'mean_acc': 0.8372}\n",
      "No balancing contrastive samples (Focusing on class with more prediction errors)\n",
      "Shuffle for concatenated-contrastive-batch\n",
      "First 10 Anchor indices:  [2021  576  157  746 1789    4 1926   63  568 1426]\n",
      "Shape of Contrastive Batch Samples :  (348, 1973)\n",
      "len(resampled_set.targets) 686604\n",
      "> batchsize of contrastive data loader : 63136\n",
      "> len of contrastive dataset : 686604\n",
      "--- Epoch 5 ---\n",
      ">>CA Optimzer.step\n",
      "Loss in Train(Contrastive Learning): 0.245 Pos:0.0778, Neg: 0.0555\n",
      "Train(After CA): {'weighted_mean_acc': 0.9591, 'worst_acc': 0.2679, 'acc_0_0': 0.9994, 'acc_0_1': 0.962, 'acc_1_0': 0.2679, 'acc_1_1': 0.8619, 'mean_acc': 0.9591}\n",
      "Val(After CA): {'weighted_mean_acc': 0.9477, 'worst_acc': 0.3383, 'acc_0_0': 0.9979, 'acc_0_1': 0.8734, 'acc_1_0': 0.3383, 'acc_1_1': 0.8271, 'mean_acc': 0.8574}\n",
      "Test(After CA): {'weighted_mean_acc': 0.9444, 'worst_acc': 0.3364, 'acc_0_0': 0.9973, 'acc_0_1': 0.8506, 'acc_1_0': 0.3364, 'acc_1_1': 0.8178, 'mean_acc': 0.8471}\n",
      "Train(Cross entropy)(for all training set): {'worst_acc': 0.7778, 'acc_0_0': 0.9982, 'acc_0_1': 0.9871, 'acc_1_0': 0.7778, 'acc_1_1': 0.9429, 'mean_acc': 0.9829}\n",
      "Train(After CE): {'weighted_mean_acc': 0.9798, 'worst_acc': 0.7679, 'acc_0_0': 0.9969, 'acc_0_1': 0.8315, 'acc_1_0': 0.7679, 'acc_1_1': 0.9603, 'mean_acc': 0.9798}\n",
      "Val(After CE): {'weighted_mean_acc': 0.9666, 'worst_acc': 0.5489, 'acc_0_0': 0.9936, 'acc_0_1': 0.7339, 'acc_1_0': 0.5489, 'acc_1_1': 0.9398, 'mean_acc': 0.8374}\n",
      "Test(After CE): {'weighted_mean_acc': 0.9601, 'worst_acc': 0.5607, 'acc_0_0': 0.9907, 'acc_0_1': 0.7175, 'acc_1_0': 0.5607, 'acc_1_1': 0.9221, 'mean_acc': 0.8291}\n",
      "No balancing contrastive samples (Focusing on class with more prediction errors)\n",
      "Shuffle for concatenated-contrastive-batch\n",
      "First 10 Anchor indices:  [1079 1423  787 2561 3398  497 1736 3920 2703 4362]\n",
      "Shape of Contrastive Batch Samples :  (348, 1973)\n",
      "len(resampled_set.targets) 686604\n",
      "> batchsize of contrastive data loader : 63136\n",
      "> len of contrastive dataset : 686604\n",
      "========================================================================\n",
      "> end of training. \n",
      "\n",
      "best epoch : 3\n",
      "best training accuracy on [class]: {'worst_acc': 0.625, 'acc_0_0': 0.9962, 'acc_0_1': 0.9801, 'acc_1_0': 0.625, 'acc_1_1': 0.9233, 'mean_acc': 0.9746}\n",
      "best validation accuracy on [class]: {'weighted_mean_acc': 0.9598, 'worst_acc': 0.609, 'acc_0_0': 0.9914, 'acc_0_1': 0.6652, 'acc_1_0': 0.609, 'acc_1_1': 0.9248, 'mean_acc': 0.8148}\n",
      "best test accuracy on [class]: {'weighted_mean_acc': 0.9554, 'worst_acc': 0.6262, 'acc_0_0': 0.9854, 'acc_0_1': 0.6421, 'acc_1_0': 0.6262, 'acc_1_1': 0.9283, 'mean_acc': 0.8057}\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "best_model = None\n",
    "# opt = parse_option()\n",
    "\n",
    "# Main Ce code\n",
    "if opt.tl_method==\"contrastive_adapter\": \n",
    "    print(\"> set and load Contrastive data-handler\")\n",
    "    print('========================================================================')\n",
    "    sliced_data_indices, sliced_data_correct = compute_slice_indices(trainset)\n",
    "    contrastive_points = prepare_contrastive_points(trainset,sliced_data_indices,sliced_data_correct)\n",
    "    slice_anchors, slice_negatives, positives_by_class, all_targets = contrastive_points\n",
    "    \n",
    "    \n",
    "    adjust_num_pos_neg_(positives_by_class, slice_negatives, opt)\n",
    "    contrastive_loss = SupervisedContrastiveLoss(opt)\n",
    "    \n",
    "    \n",
    "    # Get contrastive batches for first epoch\n",
    "    original_contrastive_batch_samples = construct_contrastive_data(slice_anchors,slice_negatives,positives_by_class, opt) # #[(254, 1719), (94, 1)]\n",
    "    contrastive_dataloader = load_contrastive_loader(trainset, original_contrastive_batch_samples, opt, True)\n",
    "    \n",
    "    negatives_by_class = GetNegativesByClass(trainset, positives_by_class)\n",
    "    weights_resampled_ce = GetResampledWeightsCE(trainset, positives_by_class, negatives_by_class, opt)\n",
    "    ce_sampler = WeightedRandomSampler(weights = weights_resampled_ce, num_samples = len(trainset), replacement=True) # num_samples = len(trainset) -> oversampling 한 만큼 major group에서 unseen-sample 나옴\n",
    "    resampled_train_loader = DataLoader(trainset, sampler=ce_sampler, batch_size=opt.batch_size, num_workers=8)\n",
    "    skim_dataloader_by_group(resampled_train_loader)\n",
    "    \n",
    "    print('========================================================================')\n",
    "\n",
    "# build optimizer\n",
    "print(\"Set Optimizer: SGD (default)\")\n",
    "print('========================================================================')\n",
    "optimizer = set_optimizer(opt, classifier)\n",
    "\n",
    "# training routine\n",
    "train_losses = []\n",
    "train_losses_cl = []\n",
    "train_accs = []\n",
    "train_group_accs = []\n",
    "\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "val_group_accs = []\n",
    "\n",
    "test_losses = [] # NOTE: Don't peek ! \n",
    "test_accs = [] # NOTE: Don't peek ! \n",
    "test_group_accs = [] # NOTE: Don't peek ! \n",
    "\n",
    "# Validate train\n",
    "((_, _, _), \n",
    "     (total_embeddings, total_meta_results)) = validate_adapter_with_return(opt, train_loader, classifier, ce_loss, get_yp_func, train_group_ratio, target=opt.train_target, print_label=f'Train(Initial Adapter)')\n",
    "\n",
    "\n",
    "# entire training\n",
    "for epoch in range(1, opt.epochs + 1):\n",
    "    adjust_learning_rate(opt, optimizer, epoch)\n",
    "    print(f'--- Epoch {epoch} ---')\n",
    "    \n",
    "    \n",
    "    # train one epoch\n",
    "    loss_cl = train_one_epoch_cl(opt, contrastive_dataloader, classifier, contrastive_loss,\n",
    "                        optimizer, epoch, print_label=f'Train(Contrastive Learning)')\n",
    "    train_losses_cl.append(loss_cl)\n",
    "    \n",
    "    # Validate train\n",
    "    ((_, _, train_ca_group_acc), \n",
    "     (train_total_embeddings, train_total_meta_results)) = validate_adapter_with_return(opt, train_loader, classifier, ce_loss, get_yp_func, train_group_ratio, target=opt.train_target, print_label=f'Train(After CA)')\n",
    "    ((_, _, val_ca_group_acc), \n",
    "     (val_total_embeddings, val_total_meta_results)) = validate_adapter_with_return(opt, val_loader, classifier, ce_loss, get_yp_func, train_group_ratio, target=opt.train_target, print_label=f'Val(After CA)')\n",
    "    ((_, _, test_ca_group_acc), \n",
    "     (test_total_embeddings, test_total_meta_results)) = validate_adapter_with_return(opt, test_loader, classifier, ce_loss, get_yp_func, train_group_ratio, target='class', print_label=f'Test(After CA)')\n",
    "    \n",
    "    train_total_meta_results['training_method'] = \"CA\"; train_total_meta_results['group_accs'] = train_ca_group_acc; \n",
    "    val_total_meta_results['training_method'] = \"CA\"; val_total_meta_results['group_accs'] = val_ca_group_acc; \n",
    "    test_total_meta_results['training_method'] = \"CA\"; test_total_meta_results['group_accs'] = test_ca_group_acc; \n",
    "    \n",
    "    append_like_queue(train_ebd_q, (train_total_embeddings, train_total_meta_results), opt.max_length_ebd_queue)\n",
    "    append_like_queue(val_ebd_q, (val_total_embeddings, val_total_meta_results), opt.max_length_ebd_queue)\n",
    "    append_like_queue(test_ebd_q, (test_total_embeddings, test_total_meta_results), opt.max_length_ebd_queue)\n",
    "    \n",
    "    loss, acc, group_acc = train_one_epoch(opt, resampled_train_loader, classifier, ce_loss,\n",
    "                        optimizer, epoch, get_yp_func, target=opt.train_target, print_label=f'Train(Cross entropy)(for all training set)')\n",
    "    train_losses.append(loss); train_accs.append(acc); train_group_accs.append(group_acc)\n",
    "    \n",
    "    # Validate train\n",
    "    ((_, _, train_ce_group_acc), \n",
    "     (train_total_embeddings, train_total_meta_results)) = validate_adapter_with_return(opt, train_loader, classifier, ce_loss, get_yp_func, train_group_ratio, target=opt.train_target, print_label=f'Train(After CE)')\n",
    "    ((val_loss, val_acc, val_ce_group_acc), \n",
    "     (val_total_embeddings, val_total_meta_results)) = validate_adapter_with_return(opt, val_loader, classifier, ce_loss, get_yp_func, train_group_ratio, target=opt.train_target, print_label=f'Val(After CE)')\n",
    "    ((test_loss, test_acc, test_ce_group_acc), \n",
    "     (test_total_embeddings, test_total_meta_results)) = validate_adapter_with_return(opt, test_loader, classifier, ce_loss, get_yp_func, train_group_ratio, target='class', print_label=f'Test(After CE)')\n",
    "    \n",
    "    train_total_meta_results['training_method'] = \"CE\"; train_total_meta_results['group_accs'] = train_ce_group_acc; \n",
    "    val_total_meta_results['training_method'] = \"CE\"; val_total_meta_results['group_accs'] = val_ce_group_acc; \n",
    "    test_total_meta_results['training_method'] = \"CE\"; test_total_meta_results['group_accs'] = test_ce_group_acc; \n",
    "    \n",
    "    append_like_queue(train_ebd_q, (train_total_embeddings, train_total_meta_results), opt.max_length_ebd_queue)\n",
    "    append_like_queue(val_ebd_q, (val_total_embeddings, val_total_meta_results), opt.max_length_ebd_queue)\n",
    "    append_like_queue(test_ebd_q, (test_total_embeddings, test_total_meta_results), opt.max_length_ebd_queue)\n",
    "    \n",
    "    val_losses.append(val_loss); val_accs.append(val_acc); val_group_accs.append(val_ce_group_acc)\n",
    "    test_losses.append(test_loss); test_accs.append(test_acc); test_group_accs.append(test_ce_group_acc)\n",
    "    \n",
    "    # update best epoch by worst_group accuracy (default)\n",
    "    if val_ce_group_acc['worst_acc'] > best_acc:\n",
    "        best_acc = val_ce_group_acc['worst_acc']\n",
    "        best_epoch = epoch\n",
    "        best_model = copy.deepcopy(classifier)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if opt.re_shuffle_ca_loader:\n",
    "        contrastive_dataloader = load_contrastive_loader(trainset, original_contrastive_batch_samples, opt, True)\n",
    "\n",
    "\n",
    "print('========================================================================')\n",
    "print(\"> end of training. \\n\")\n",
    "print('best epoch : {}'.format(best_epoch))\n",
    "\n",
    "best_train_group_acc = train_group_accs[best_epoch-1]\n",
    "best_val_group_acc = val_group_accs[best_epoch-1]\n",
    "best_test_group_acc = test_group_accs[best_epoch-1]\n",
    "\n",
    "print(f'best training accuracy on [{opt.train_target}]: {best_train_group_acc}')\n",
    "print(f'best validation accuracy on [{opt.train_target}]: {best_val_group_acc}')\n",
    "print(f'best test accuracy on [{opt.train_target}]: {best_test_group_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

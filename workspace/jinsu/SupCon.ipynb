{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "sys.path.append(\"/home/jinsu/workstation/project/debiasing-multi-modal\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from util import AverageMeter\n",
    "from util import adjust_learning_rate, warmup_learning_rate, accuracy\n",
    "from util import set_optimizer\n",
    "\n",
    "from data.waterbirds_embeddings import WaterbirdsEmbeddings, load_waterbirds_embeddings\n",
    "from data.celeba_embeddings import CelebaEmbeddings, load_celeba_embeddings\n",
    "model_dict = {'resnet50': [None, 1024]} # (nn.module, 1024)\n",
    "new_order_for_print = [\n",
    "    'weighted_mean_acc',\n",
    "    'worst_acc',\n",
    "    'acc_0_0',\n",
    "    'acc_0_1',\n",
    "    'acc_1_0',\n",
    "    'acc_1_1',\n",
    "    'mean_acc'\n",
    "]\n",
    "from functools import partial\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=2):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, features):\n",
    "        return self.fc(features)\n",
    "\n",
    "\n",
    "\n",
    "class CustomCLIP(nn.Module):\n",
    "    def __init__(self, adapter, text_embedding_dir, text_spurious_embedding_dir, temperature=0.01):\n",
    "        super().__init__()\n",
    "        self.text_embedding_dir = text_embedding_dir\n",
    "        self.text_spurious_embedding_dir = text_spurious_embedding_dir\n",
    "        self.adapter = adapter\n",
    "        self.temperature = temperature # CA default : 0.01, B2T default : 0.02 (?) NOTE\n",
    "        \n",
    "        self.text_features = get_text_embedding(self.text_embedding_dir)\n",
    "        self.text_spurious_features = get_text_embedding(self.text_spurious_embedding_dir)\n",
    "        \n",
    "    def forward(self, features): \n",
    "        image_features =  self.adapter(features) # Un-normalized (B, 1024)\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True) # Normalized (B, 1024)\n",
    "\n",
    "        text_features = self.text_features # (Pre) Normalized (B, 2, 1024)\n",
    "        \n",
    "        logits = image_features @ text_features / self.temperature # (B, 1024) X (B, 2, 1024) = # (B, 2)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def forward_spurious(self, features): \n",
    "        image_features =  self.adapter(features) # Un-normalized (B, 1024)\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True) # Normalized (B, 1024)\n",
    "\n",
    "        text_spurious_features = self.text_spurious_features # (Pre) Normalized (B, 2, 1024)\n",
    "        \n",
    "        logits = image_features @ text_spurious_features / self.temperature # (B, 1024) X (B, 2, 1024) = # (B, 2)\n",
    "        \n",
    "        return logits\n",
    "        \n",
    "class Adapter(nn.Module):\n",
    "    \"\"\"\n",
    "    - Residual connetion : 제외 (original Adapter - 0.2*images + 0.8*adapter)\n",
    "    - Hidden dimension : args.adapter_feat_dim (original Adatper - input_dim // 4)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "    def forward(self, features):\n",
    "        return self.layers(features)\n",
    "\n",
    "def parse_option():\n",
    "    parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "    parser.add_argument('--print_freq', type=int, default=10,\n",
    "                        help='print frequency')\n",
    "    parser.add_argument('--save_freq', type=int, default=50,\n",
    "                        help='save frequency')\n",
    "    parser.add_argument('--batch_size', type=int, default=128,\n",
    "                        help='batch_size')\n",
    "    parser.add_argument('--num_workers', type=int, default=16,\n",
    "                        help='num of workers to use')\n",
    "    parser.add_argument('--epochs', type=int, default=100,\n",
    "                        help='number of training epochs')\n",
    "\n",
    "    # optimization\n",
    "    parser.add_argument('--learning_rate', type=float, default=1e-3, \n",
    "                        help='learning rate') # Tuning needed. \n",
    "    parser.add_argument('--lr_decay_epochs', type=str, default='60,75,90',\n",
    "                        help='where to decay lr, can be a list')\n",
    "    parser.add_argument('--lr_decay_rate', type=float, default=1,\n",
    "                        help='decay rate for learning rate') \n",
    "    parser.add_argument('--weight_decay', type=float, default=5e-5,\n",
    "                        help='weight decay') # Tuning needed. \n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "\n",
    "    # model dataset\n",
    "    parser.add_argument('--model', type=str, default='resnet50')\n",
    "    parser.add_argument('--dataset', type=str, default='waterbirds',\n",
    "                        choices=['celeba', 'waterbirds'], help='dataset')\n",
    "\n",
    "    # other setting\n",
    "    parser.add_argument('--cosine', action='store_true',\n",
    "                        help='using cosine annealing') # Tuning needed. \n",
    "    parser.add_argument('--warm', action='store_true',\n",
    "                        help='warm-up for large batch training') # Tuning needed. \n",
    "\n",
    "    parser.add_argument('--image_embedding_dir', type=str,\n",
    "                        help='extracted image embedding')\n",
    "    parser.add_argument('--text_embedding_dir', type=str,\n",
    "                        help='extracted text embedding')\n",
    "    parser.add_argument('--text_spurious_embedding_dir', type=str,\n",
    "                        help='extracted text embedding (about spurious attributes)')\n",
    "    parser.add_argument('--train_target', type=str, default=\"class\", choices=[\"class\", \"spurious\", \"group\"]) # label for prediction.\n",
    "    parser.add_argument('--data_dir', type=str,\n",
    "                    help='folder, in which metadata.csv] exist')\n",
    "    parser.add_argument('--tl_method', type=str, default= \"linear_probing\", choices=[\"linear_probing\", \"adapter\", \"contrastive_adapter\", \"ETC\"]\n",
    "                        ,help='transfer learning method')\n",
    "    parser.add_argument('--adapter_feat_dim', type=int, default= 128, help='reduced dimension in adapter')\n",
    "    parser.add_argument('--zs_temperature', type=float, default= 0.01, help='Temperature in zero-shot prediction')\n",
    "    parser.add_argument('--watch_batch_results', type=bool, default=False, help='Print results in each bach by [opt.print_freq]. Recommdned: True when single-run of CelebA(Large # of batch), False others')\n",
    "    parser.add_argument('--save_results', type=bool, default=True, help='Save the results of transfer learning (and final feature quality) in the folder where ')\n",
    "    \n",
    "\n",
    "    # parser.add_argument('--lr_linear_probing', type=float, default=1e-3, chocies=[1e-3, 1e-2, 1e-1, 1, 3, 10], help='learning rate for linear probing') # Tuning needed. \n",
    "      # -> Zero-shot으로 대체하는 게 맞을듯.\n",
    "\n",
    "    opt = parser.parse_args(args=[])\n",
    "\n",
    "    # set the path according to the environment\n",
    "\n",
    "    iterations = opt.lr_decay_epochs.split(',')\n",
    "    opt.lr_decay_epochs = list([])\n",
    "    for it in iterations:\n",
    "        opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "    if opt.warm:\n",
    "        opt.warmup_from = 0.01\n",
    "        opt.warm_epochs = 10\n",
    "        if opt.cosine:\n",
    "            eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "            opt.warmup_to = eta_min + (opt.learning_rate - eta_min) * (\n",
    "                    1 + math.cos(math.pi * opt.warm_epochs / opt.epochs)) / 2\n",
    "        else:\n",
    "            opt.warmup_to = opt.learning_rate\n",
    "            \n",
    "    if opt.dataset == 'celeba':\n",
    "        opt.n_cls = 2\n",
    "    elif opt.dataset == 'waterbirds':\n",
    "        opt.n_cls = 2\n",
    "    else:\n",
    "        raise ValueError('dataset not supported: {}'.format(opt.dataset))\n",
    "\n",
    "    return opt\n",
    "\n",
    "\n",
    "def set_model(opt):\n",
    "    # model = SupConResNet(name=opt.model)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "    _ , input_dim = model_dict[opt.model] # (Encoder(not use), feature dim)\n",
    "    \n",
    "    if opt.tl_method =='linear_probing':\n",
    "        print(\"Off-the-shelf classifier : [Linear Classifier]\")\n",
    "        classifier = LinearClassifier(input_dim = input_dim, num_classes = opt.n_cls)\n",
    "    elif opt.tl_method =='adapter':\n",
    "        print(\"Off-the-shelf classifier : [Adapter + (temperatured) image-text jointly normalized prediction]\")\n",
    "        adapter = Adapter(input_dim = input_dim, hidden_dim = opt.adapter_feat_dim) # Fixed by heuristics\n",
    "        classifier = CustomCLIP(adapter, opt.text_embedding_dir, opt.text_spurious_embedding_dir, temperature=opt.zs_temperature)\n",
    "    elif opt.tl_method =='contrastive_adapter':\n",
    "        print(\"Off-the-shelf classifier : [Adapter + (temperatured) image-text jointly normalized prediction]\")\n",
    "        adapter = Adapter(input_dim = input_dim, hidden_dim = opt.adapter_feat_dim) # Fixed by heuristics\n",
    "        classifier = CustomCLIP(adapter, opt.text_embedding_dir, opt.text_spurious_embedding_dir, temperature=opt.zs_temperature)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        classifier = classifier.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    return classifier, criterion # model, \n",
    "\n",
    "# Group-wise Accuracy Update.\n",
    "def update_dict(acc_groups, y, g, logits):\n",
    "    preds = torch.argmax(logits, axis=1)\n",
    "    correct_batch = (preds == y)\n",
    "    g = g.cpu()\n",
    "    for g_val in np.unique(g):\n",
    "        mask = g == g_val\n",
    "        n = mask.sum().item()\n",
    "        corr = correct_batch[mask].sum().item()\n",
    "        acc_groups[g_val].update(corr / n, n) \n",
    "\n",
    "\n",
    "# Mean/Worst acc (not weighted average)\n",
    "def get_results(acc_groups, get_yp_func): # Input 중 acc_groups : AverageMeter()를 담고있는 dict. get_yp_func : 미리 partial을 이용해 n_groups를 저장해놓음. \n",
    "    groups = acc_groups.keys() # 0, 1, 2, 3\n",
    "    results = {\n",
    "            f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\": acc_groups[g].avg\n",
    "            for g in groups\n",
    "    }\n",
    "    all_correct = sum([acc_groups[g].sum for g in groups])\n",
    "    all_total = sum([acc_groups[g].count for g in groups])\n",
    "    results.update({\"mean_acc\" : all_correct / all_total})\n",
    "    results.update({\"worst_acc\" : min(results.values())})\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Group -> class / spurious attributes\n",
    "def get_y_p(g, n_places):\n",
    "    y = g // n_places\n",
    "    p = g % n_places\n",
    "    return y, p\n",
    "\n",
    "def get_text_embedding(text_embedding_dir):\n",
    "    with open(text_embedding_dir, 'r') as f:\n",
    "        text_embeddings = json.load(f)\n",
    "\n",
    "    text_features = []\n",
    "    for class_template, class_embedding in text_embeddings.items():\n",
    "        text_features.append(torch.tensor(class_embedding))\n",
    "    text_features = torch.stack(text_features, dim=1).cuda() # (B, 2, 1024)\n",
    "    \n",
    "    \n",
    "    return text_features\n",
    "\n",
    "def train_one_epoch(opt, train_loader, classifier, criterion, optimizer, epoch, get_yp_func, target, print_label='Train'): # model,\n",
    "    \"\"\"one epoch training\"\"\"\n",
    "    # model.eval()\n",
    "    classifier.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(train_loader.dataset.n_groups)}\n",
    "\n",
    "    end = time.time()\n",
    "    for idx, data in enumerate(train_loader):  \n",
    "        \n",
    "        embeddings, all_labels, img_filenames = data # all_labels.keys() : ['class', 'group', 'spurious', 'ebd_pred'(CLIP-zeroshot)] \n",
    "        labels = all_labels[target] # target : one of [y, spurious, group]\n",
    "        groups = all_labels['group'] # For evaluating group accuracy (and further developing group-information-aware approaches)\n",
    "    \n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        embeddings = embeddings.cuda(non_blocking=True)\n",
    "        labels = labels.cuda(non_blocking=True)\n",
    "        bsz = labels.shape[0]\n",
    "\n",
    "        # warm-up learning rate\n",
    "        warmup_learning_rate(opt, epoch, idx, len(train_loader), optimizer)\n",
    "\n",
    "        # compute loss\n",
    "        output = classifier(embeddings.detach()) \n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # update metric\n",
    "        losses.update(loss.item(), bsz)\n",
    "        acc1 = accuracy(output, labels, bsz)\n",
    "        acc.update(acc1, bsz)\n",
    "\n",
    "        # SGD\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        # Update acc dict\n",
    "        update_dict(acc_groups, labels, groups, output)\n",
    "        \n",
    "        if opt.watch_batch_results:\n",
    "            if (idx + 1) % opt.print_freq == 0:\n",
    "                print(f'{print_label}: [{0}][{1}/{2}]\\t'\n",
    "                    'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                    'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                    'loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n",
    "                    'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                    epoch, idx + 1, len(train_loader), batch_time=batch_time,\n",
    "                    data_time=data_time, loss=losses, acc=acc))\n",
    "                sys.stdout.flush()\n",
    "            \n",
    "    group_acc = get_results(acc_groups, get_yp_func) # NOTE declared in [def main]\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print[1:]}\n",
    "    group_acc = {key: np.round(value, 4) for key, value in group_acc.items()}\n",
    "    print(f\"{print_label}:\", str(group_acc))\n",
    "    \n",
    "    return losses.avg, acc.avg, group_acc\n",
    "\n",
    "\n",
    "def validate(opt, val_loader, classifier, criterion, get_yp_func, train_group_ratio, target, print_label='Test'):\n",
    "    \"\"\"validation\"\"\"\n",
    "    \n",
    "    classifier.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(val_loader.dataset.n_groups)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            embeddings, all_labels, img_filenames = data # all_labels.keys() : ['class', 'group', 'spurious', 'ebd_pred'(CLIP-zeroshot)] \n",
    "            labels = all_labels[target] # target : one of [class, spurious, group]\n",
    "            groups = all_labels['group'] # For evaluating group accuracy (and further developing group-information-aware approaches)\n",
    "            \n",
    "            embeddings = embeddings.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "            bsz = labels.shape[0]\n",
    "\n",
    "            # forward\n",
    "            output = classifier(embeddings)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # update metric\n",
    "            losses.update(loss.item(), bsz)\n",
    "            acc1 = accuracy(output, labels, bsz)\n",
    "            acc.update(acc1, bsz)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            # Update acc dict\n",
    "            update_dict(acc_groups, labels, groups, output)\n",
    "        \n",
    "            if opt.watch_batch_results:\n",
    "                if (idx+1) % opt.print_freq == 0:\n",
    "                    print(f'{print_label}: [{0}/{1}]\\t'\n",
    "                        'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                        'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                        'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                        idx, len(val_loader), batch_time=batch_time,\n",
    "                        loss=losses, acc=acc))\n",
    "                    \n",
    "    group_acc = get_results(acc_groups, get_yp_func)\n",
    "\n",
    "    # NOTE Add Weighted mean acc.\n",
    "    groups = range(val_loader.dataset.n_groups) # 0, 1, 2, 3\n",
    "    group_acc_indiv =  [group_acc[f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\"] for g in groups]\n",
    "    weighted_mean_acc = (np.array(group_acc_indiv) * np.array(train_group_ratio)).sum() # Weighted Sum \\\n",
    "    \n",
    "    group_acc[\"weighted_mean_acc\"] = weighted_mean_acc\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print}\n",
    "    group_acc = {key: np.round(value, 4) for key, value in group_acc.items()}\n",
    "    print(f\"{print_label}:\", str(group_acc))\n",
    "\n",
    "    return losses.avg, acc.avg, group_acc    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def validate_zs(opt, val_loader, classifier, criterion, get_yp_func, train_group_ratio, target, print_label='Zero-shot Prediction (Test) (Class)'):\n",
    "    \"\"\"(Feature quality) validation using zeroshot-prediction\"\"\"\n",
    "\n",
    "    classifier.eval()\n",
    "\n",
    "\n",
    "    if opt.tl_method in [\"linear_probing\"]:\n",
    "        temperature = opt.zs_temperature\n",
    "        \n",
    "        if target==\"class\":\n",
    "            text_embeddings = get_text_embedding(opt.text_embedding_dir)\n",
    "        elif target=='spurious':\n",
    "            text_embeddings = get_text_embedding(opt.text_spurious_embedding_dir)\n",
    "        \n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(val_loader.dataset.n_groups)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            image_embeddings, all_labels, img_filenames = data # all_labels.keys() : ['class', 'group', 'spurious', 'ebd_pred'(CLIP-zeroshot)] \n",
    "            labels = all_labels[target] # target : one of [class, spurious, group]\n",
    "            groups = all_labels['group'] # For evaluating group accuracy (and further developing group-information-aware approaches)\n",
    "            \n",
    "            image_embeddings = image_embeddings.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "            bsz = labels.shape[0]\n",
    "            \n",
    "            if opt.tl_method in ['linear_probing']: # same to CLIP Embedding\n",
    "                image_embeddings = image_embeddings / image_embeddings.norm(dim=-1, keepdim=True) # Normalized (B, 1024)\n",
    "                output = image_embeddings @ text_embeddings / temperature # (B, 1024) X (B, 2, 1024) = # (B, 2)\n",
    "                \n",
    "            elif opt.tl_method in ['adapter', 'contrastive_adapter']: # Adpater, Contrastive Adapter : Embedding -> (1) (Adapted) Embedding -> (2) ZeroShot prediction as logit    (CustomCLIP.forward : (1)+(2))\n",
    "                # forward\n",
    "                if target=='class':\n",
    "                    output = classifier(image_embeddings)\n",
    "                elif target=='spurious':\n",
    "                    output = classifier.forward_spurious(image_embeddings)\n",
    "            \n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # update metric\n",
    "            losses.update(loss.item(), bsz)\n",
    "            acc1 = accuracy(output, labels, bsz)\n",
    "            acc.update(acc1, bsz)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            # Update acc dict\n",
    "            update_dict(acc_groups, labels, groups, output)\n",
    "        \n",
    "            if opt.watch_batch_results:\n",
    "                if (idx+1) % opt.print_freq == 0:\n",
    "                    print(f'{print_label}: [{0}/{1}]\\t'\n",
    "                        'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                        'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                        'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                        idx, len(val_loader), batch_time=batch_time,\n",
    "                        loss=losses, acc=acc))\n",
    "                    \n",
    "    group_acc = get_results(acc_groups, get_yp_func)\n",
    "\n",
    "    # NOTE Add Weighted mean acc.\n",
    "    groups = range(val_loader.dataset.n_groups) # 0, 1, 2, 3\n",
    "    group_acc_indiv =  [group_acc[f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\"] for g in groups]\n",
    "    weighted_mean_acc = (np.array(group_acc_indiv) * np.array(train_group_ratio)).sum() # Weighted Sum \\\n",
    "    \n",
    "    group_acc[\"weighted_mean_acc\"] = weighted_mean_acc\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print}\n",
    "    group_acc = {key: np.round(value, 4) for key, value in group_acc.items()}\n",
    "    print(f\"{print_label}:\", str(group_acc))\n",
    "    \n",
    "    return losses.avg, acc.avg, group_acc    \n",
    "\n",
    "def train_all_epochs(opt):\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    best_model = None\n",
    "    # opt = parse_option()\n",
    "    \n",
    "    \n",
    "    print(f\"> Start Transfer Learning using [{opt.tl_method}]\")\n",
    "    print('========================================================================')\n",
    "    if opt.dataset == 'waterbirds':\n",
    "        # build dataset example.\n",
    "        print(f\"Load image embedding of Waterbirds: {opt.image_embedding_dir}\")\n",
    "        trainset = WaterbirdsEmbeddings(opt.data_dir, 'train', opt.image_embedding_dir, None)\n",
    "        print(f\"ㄴ Corresponding text embedding of Waterbirds: {opt.text_embedding_dir}\")\n",
    "        # build data loader\n",
    "        print(\"Load Data Loader (train, validation, test)\")\n",
    "        train_loader, val_loader, test_loader = load_waterbirds_embeddings(opt.data_dir, opt.image_embedding_dir, opt.batch_size, opt.batch_size)\n",
    "        \n",
    "        # print training target\n",
    "        if opt.train_target == \"class\":\n",
    "            print(f\"Training target : {opt.train_target} (Land bird(0) / Water bird(1))\")\n",
    "        elif opt.train_target == \"spurious\":\n",
    "            print(f\"Training target : {opt.train_target} (Land background(0) / Water background(1))\")\n",
    "        \n",
    "    elif opt.dataset == 'celeba':\n",
    "        # build dataset example.\n",
    "        print(f\"Load embedding of CelebA: {opt.image_embedding_dir}\")\n",
    "        trainset = CelebaEmbeddings(opt.data_dir, 'train', opt.image_embedding_dir, None)\n",
    "        print(f\"ㄴ Corresponding text embedding of Waterbirds: {opt.text_embedding_dir}\")\n",
    "        # build data loader\n",
    "        print(\"Load Data Loader (train, validation, test)\")\n",
    "        train_loader, val_loader, test_loader = load_celeba_embeddings(opt.data_dir, opt.image_embedding_dir, opt.batch_size, opt.batch_size)\n",
    "        \n",
    "        # print training target\n",
    "        if opt.train_target == \"class\":\n",
    "            print(f\"Training target : {opt.train_target} (non-blond hair(0) / blond hair(1))\")\n",
    "        elif opt.train_target == \"spurious\":\n",
    "            print(f\"Training target : {opt.train_target} (female(0) / male(1))\")\n",
    "\n",
    "    # group information\n",
    "    get_yp_func = partial(get_y_p, n_places=trainset.n_places)\n",
    "    train_group_ratio = trainset.group_ratio\n",
    "    \n",
    "    # build model and criterion\n",
    "    classifier, criterion = set_model(opt) # model, \n",
    "\n",
    "    # build optimizer\n",
    "    print(\"Set Optimizer: SGD (default)\")\n",
    "    print('========================================================================')\n",
    "    optimizer = set_optimizer(opt, classifier)\n",
    "    \n",
    "    # training routine\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    train_group_accs = []\n",
    "    \n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    val_group_accs = []\n",
    "    \n",
    "    test_losses = [] # NOTE: Don't peek ! \n",
    "    test_accs = [] # NOTE: Don't peek ! \n",
    "    test_group_accs = [] # NOTE: Don't peek ! \n",
    "    \n",
    "    # entire training\n",
    "    for epoch in range(1, opt.epochs + 1):\n",
    "        adjust_learning_rate(opt, optimizer, epoch)\n",
    "        print(f'--- Epoch {epoch} ---')\n",
    "        \n",
    "        # train one epoch\n",
    "        loss, acc, group_acc = train_one_epoch(opt, train_loader, classifier, criterion,\n",
    "                          optimizer, epoch, get_yp_func, target=opt.train_target, print_label=f'Train({opt.train_target})')\n",
    "        \n",
    "        train_losses.append(loss); train_accs.append(acc); train_group_accs.append(group_acc)\n",
    "        \n",
    "        # eval for one epoch\n",
    "        val_loss, val_acc, val_group_acc = validate(opt, val_loader, classifier, criterion, get_yp_func, train_group_ratio, target=opt.train_target, print_label=f'Val({opt.train_target})')\n",
    "        val_losses.append(val_loss); val_accs.append(val_acc); val_group_accs.append(val_group_acc)\n",
    "        \n",
    "        # update best epoch by worst_group accuracy (default)\n",
    "        if val_group_acc['worst_acc'] > best_acc:\n",
    "            best_acc = val_group_acc['worst_acc']\n",
    "            best_epoch = epoch\n",
    "            best_model = copy.deepcopy(classifier)\n",
    "        \n",
    "        # test for one epoch\n",
    "        test_loss, test_acc, test_group_acc = validate(opt, test_loader, classifier, criterion, get_yp_func, train_group_ratio, target='class', print_label=f'Test({opt.train_target})')\n",
    "        \n",
    "        test_losses.append(test_loss); test_accs.append(test_acc); test_group_accs.append(test_group_acc)\n",
    "        \n",
    "\n",
    "    print('========================================================================')\n",
    "    print(\"> end of training. \\n\")\n",
    "    print('best epoch : {}'.format(best_epoch))\n",
    "    \n",
    "    best_train_group_acc = train_group_accs[best_epoch-1]\n",
    "    best_val_group_acc = val_group_accs[best_epoch-1]\n",
    "    best_test_group_acc = test_group_accs[best_epoch-1]\n",
    "    \n",
    "    print(f'best training accuracy on [{opt.train_target}]: {best_train_group_acc}')\n",
    "    print(f'best validation accuracy on [{opt.train_target}]: {best_val_group_acc}')\n",
    "    print(f'best test accuracy on [{opt.train_target}]: {best_test_group_acc}')\n",
    "    \n",
    "    # Evaluate Feature Quality using (Embedding-based) Zero-shot Prediction\n",
    "    print('========================================================================')\n",
    "    print(\"> start evaluating feature quality of best model. (using zero-shot prediction)\\n\")\n",
    "    \n",
    "    \n",
    "    # Zero-shot [class] prediction\n",
    "    zs_loss, zs_acc, zs_group_acc = validate_zs(opt, test_loader, best_model, criterion, get_yp_func, train_group_ratio, target=\"class\", print_label='zero-shot prediction (test) (class)')    \n",
    "    \n",
    "    if opt.tl_method in [\"linear_probing\"]:\n",
    "        print(f\" ㄴ Note that it should be same to [CLIP Zero-shot Baselines, of which worst acc is about 39%], in {opt.tl_method}\")\n",
    "    elif opt.tl_method in [\"adapter\", \"contrastive_adapt\"]: \n",
    "        print(f\" ㄴ Note that it should be same to [best test accuracy on [{opt.train_target}]], above, in {opt.tl_method}\")\n",
    "    \n",
    "    # Zero-shot [spurious] prediction\n",
    "    zs_loss_spurious, zs_acc_spurious, zs_group_acc_spurious = validate_zs(opt, test_loader, best_model, criterion, get_yp_func, train_group_ratio, target=\"spurious\", print_label='zero-shot prediction (test) (spurious)')    \n",
    "    print(f\" ㄴ Note that it is related to [richness of non-target (spurious) information] (-> 'mean_acc' is important)\")\n",
    "    \n",
    "    print('========================================================================')\n",
    "    # Recommendation : False when multiple training\n",
    "    if opt.save_results:\n",
    "        print('> Save results\\n')\n",
    "        all_results = {}\n",
    "        \n",
    "        for epoch in range(1, opt.epochs + 1):\n",
    "            all_results[f\"Epoch {epoch}\"] = {\"Train\": train_group_accs[epoch-1], \"Val\": test_group_accs[epoch-1], \"Test\": test_group_accs[epoch-1]}\n",
    "        \n",
    "        final_results = {\"Final Results (best epoch)\":  {f\"Epoch {best_epoch}\": {\"Train\": best_train_group_acc, \"Val\": best_val_group_acc, \"Test\": best_test_group_acc}}, \n",
    "                         \"Feature Quality (using zs)\":  {\"class\":  zs_group_acc, \"spurious\": zs_group_acc_spurious}, \n",
    "                         \"All Results (all epoch)\": all_results}\n",
    "        \n",
    "        # make result folder \n",
    "        final_result_folder = os.path.dirname(opt.image_embedding_dir).replace('data', 'results')\n",
    "        if not os.path.exists(final_result_folder):\n",
    "            os.makedirs(final_result_folder)\n",
    "            \n",
    "        image_ebd_file_name = os.path.basename(opt.image_embedding_dir).split(\".\")[0]\n",
    "        text_ebd_file_name = os.path.basename(opt.text_embedding_dir).split(\".\")[0]\n",
    "        \n",
    "        # result name\n",
    "        final_result_file_name = f\"im_{image_ebd_file_name}_t_{text_ebd_file_name}_tl_{opt.tl_method}_t_{opt.train_target}_lr_{opt.learning_rate}_bs_{opt.batch_size}\"\n",
    "        \n",
    "        # NOTE This file name can be modified when we add baselines\n",
    "        \"\"\"\n",
    "        E.g., if we use [flexable_adapter] and corresponding h.p. [flexable_weight], then, \n",
    "        if opt.tl_method == \"flexable_adpater\":\n",
    "            final_result_file_name += f\"_{opt.flexable_weight}\"\n",
    "        if opt.cosine:\n",
    "            opt.model_name = '{}_cosine'.format(opt.model_name)\n",
    "        if opt.warm:\n",
    "            opt.model_name = '{}_warm'.format(opt.model_name)\n",
    "        \"\"\"\n",
    "\n",
    "        # result path\n",
    "        final_result_file_path = os.path.join(final_result_folder, final_result_file_name + \".json\")\n",
    "        final_model_path = os.path.join(final_result_folder, final_result_file_name + \".pth\")\n",
    "        \n",
    "        print('final result path: ', final_result_file_path)\n",
    "        print('final model path: ', final_model_path)\n",
    "        \n",
    "        # save results, as json.\n",
    "        with open(final_result_file_path, \"w\") as f:\n",
    "            json.dump(final_results, f, indent=4)\n",
    "        \n",
    "        # save final model, as pth \n",
    "        torch.save(best_model.state_dict(), final_model_path)    \n",
    "            \n",
    "    \n",
    "    print('========================================================================')\n",
    "    print(\"> end\")\n",
    "    \n",
    "    return (best_train_group_acc, best_val_group_acc, best_test_group_acc), (train_group_accs, val_group_accs, test_group_accs) # (best_results, all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "parser.add_argument('--print_freq', type=int, default=20,\n",
    "                    help='print frequency')\n",
    "parser.add_argument('--save_freq', type=int, default=50,\n",
    "                    help='save frequency')\n",
    "parser.add_argument('--batch_size', type=int, default=128,\n",
    "                    help='batch_size')\n",
    "parser.add_argument('--num_workers', type=int, default=16,\n",
    "                    help='num of workers to use')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='number of training epochs')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--learning_rate', type=float, default=1e-3,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--lr_decay_epochs', type=str, default='60,75,90',\n",
    "                    help='where to decay lr, can be a list')\n",
    "parser.add_argument('--lr_decay_rate', type=float, default=1 ,\n",
    "                    help='decay rate for learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-5,\n",
    "                    help='weight decay')\n",
    "parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                    help='momentum')\n",
    "\n",
    "# model dataset\n",
    "parser.add_argument('--model', type=str, default='resnet50')\n",
    "parser.add_argument('--dataset', type=str, default='waterbirds',\n",
    "                    choices=['celeba', 'waterbirds'], help='dataset')\n",
    "\n",
    "# other setting\n",
    "parser.add_argument('--cosine', action='store_true',\n",
    "                    help='using cosine annealing')\n",
    "parser.add_argument('--warm', action='store_true',\n",
    "                    help='warm-up for large batch training')\n",
    "\n",
    "parser.add_argument('--image_embedding_dir', type=str, \n",
    "                    help='extracted image embedding')\n",
    "parser.add_argument('--text_embedding_dir', type=str, \n",
    "                    help='extracted text embedding')\n",
    "parser.add_argument('--train_target', type=str, default=\"class\", choices=[\"class\", \"spurious\", \"group\"]) # Label for training.\n",
    "parser.add_argument('--data_dir', type=str,\n",
    "                    help='folder, in which [metadata.csv] exists')\n",
    "parser.add_argument('--tl_method', type=str, default=\"linear_probing\", choices=[\"linear_probing\", \"adapter\", \"contrastive_adapter\"]\n",
    "                        ,help='transfer learning method')\n",
    "parser.add_argument('--adapter_feat_dim', type=int, default= 128, help='reduced dimension in adapter')\n",
    "# parser.add_argument('--watch_batch_results', type=bool, default=False, help='Print results in each bach by [opt.print_freq]. Recommdned: True when single-run of CelebA(Large dataset), False otherwises')\n",
    "\n",
    "parser.add_argument('--zs_temperature', type=float, default= 0.01, help='Temperature in zero-shot prediction')\n",
    "# parser.add_argument('--save_results', type=bool, default=True, help='Save the results of transfer learning (and final feature quality) in the folder where ')\n",
    "opt = parser.parse_args(args=[])   \n",
    "\n",
    "iterations = opt.lr_decay_epochs.split(',')\n",
    "opt.lr_decay_epochs = list([])\n",
    "for it in iterations:\n",
    "    opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "opt.model_name = '{}_{}_lr_{}_decay_{}_bsz_{}'.\\\n",
    "    format(opt.dataset, opt.model, opt.learning_rate, opt.weight_decay,\n",
    "            opt.batch_size)\n",
    "\n",
    "if opt.cosine:\n",
    "    opt.model_name = '{}_cosine'.format(opt.model_name)\n",
    "\n",
    "# warm-up for large-batch training,\n",
    "if opt.warm:\n",
    "    opt.model_name = '{}_warm'.format(opt.model_name)\n",
    "    opt.warmup_from = 0.01\n",
    "    opt.warm_epochs = 10\n",
    "    if opt.cosine:\n",
    "        eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "        opt.warmup_to = eta_min + (opt.learning_rate - eta_min) * (\n",
    "                1 + math.cos(math.pi * opt.warm_epochs / opt.epochs)) / 2\n",
    "    else:\n",
    "        opt.warmup_to = opt.learning_rate\n",
    "        \n",
    "if opt.dataset == 'celeba':\n",
    "    opt.n_cls = 2\n",
    "elif opt.dataset == 'waterbirds':\n",
    "    opt.n_cls = 2\n",
    "else:\n",
    "    raise ValueError('dataset not supported: {}'.format(opt.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.watch_batch_results = False\n",
    "opt.save_results = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.epochs = 1\n",
    "opt.learning_rate = 1e-1\n",
    "opt.batch_size = 128\n",
    "\n",
    "opt.dataset = 'waterbirds'\n",
    "\n",
    "opt.tl_method = \"contrastive_adapter\"\n",
    "opt.train_target = \"class\"\n",
    "\n",
    "non_target = \"spurious\"\n",
    "\n",
    "opt.text_embedding_dir = f\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/{opt.dataset}/clip_{opt.train_target}.json\"\n",
    "opt.text_spurious_embedding_dir = f\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/{opt.dataset}/clip_{non_target}.json\"\n",
    "opt.image_embedding_dir = f\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/RN50/clip.json\"\n",
    "opt.data_dir=\"/home/jinsu/workstation/project/debiasing-multi-modal/data/waterbirds/waterbird_complete95_forest2water2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Start Transfer Learning using [contrastive_adapter]\n",
      "========================================================================\n",
      "Load image embedding of Waterbirds: /home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/RN50/clip.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[39m=\u001b[39m train_all_epochs(opt)\n",
      "Cell \u001b[0;32mIn[60], line 474\u001b[0m, in \u001b[0;36mtrain_all_epochs\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[39mif\u001b[39;00m opt\u001b[39m.\u001b[39mdataset \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mwaterbirds\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    472\u001b[0m     \u001b[39m# build dataset example.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoad image embedding of Waterbirds: \u001b[39m\u001b[39m{\u001b[39;00mopt\u001b[39m.\u001b[39mimage_embedding_dir\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 474\u001b[0m     trainset \u001b[39m=\u001b[39m WaterbirdsEmbeddings(opt\u001b[39m.\u001b[39;49mdata_dir, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, opt\u001b[39m.\u001b[39;49mimage_embedding_dir, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    475\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mㄴ Corresponding text embedding of Waterbirds: \u001b[39m\u001b[39m{\u001b[39;00mopt\u001b[39m.\u001b[39mtext_embedding_dir\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    476\u001b[0m     \u001b[39m# build data loader\u001b[39;00m\n",
      "File \u001b[0;32m~/workstation/project/debiasing-multi-modal/data/waterbirds_embeddings.py:29\u001b[0m, in \u001b[0;36mWaterbirdsEmbeddings.__init__\u001b[0;34m(self, data_dir, split, embedding_dir, transform)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_dir, \u001b[39m'\u001b[39m\u001b[39mmetadata.csv\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata_df[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata_df[\u001b[39m'\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit]]\n\u001b[0;32m---> 29\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_dir) \u001b[39m# key : image_filename\u001b[39;00m\n\u001b[1;32m     30\u001b[0m indices_to_convert \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mplace\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgroup\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m# str -> int\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings_df\u001b[39m.\u001b[39mloc[indices_to_convert] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings_df\u001b[39m.\u001b[39mloc[indices_to_convert]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mint64\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/pandas/io/json/_json.py:784\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n\u001b[1;32m    783\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 784\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\u001b[39m.\u001b[39;49mread()\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/pandas/io/json/_json.py:975\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_object_parser(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_lines(data_lines))\n\u001b[1;32m    974\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 975\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_object_parser(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\n\u001b[1;32m    976\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype_backend \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n\u001b[1;32m    977\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39mconvert_dtypes(\n\u001b[1;32m    978\u001b[0m         infer_objects\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype_backend\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype_backend\n\u001b[1;32m    979\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/pandas/io/json/_json.py:1001\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    999\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 1001\u001b[0m     obj \u001b[39m=\u001b[39m FrameParser(json, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49mparse()\n\u001b[1;32m   1003\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1004\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/pandas/io/json/_json.py:1140\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_axes:\n\u001b[1;32m   1139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_axes()\n\u001b[0;32m-> 1140\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_convert_types()\n\u001b[1;32m   1141\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/pandas/io/json/_json.py:1382\u001b[0m, in \u001b[0;36mFrameParser._try_convert_types\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_dates:\n\u001b[1;32m   1380\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_convert_dates()\n\u001b[0;32m-> 1382\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_converter(\n\u001b[1;32m   1383\u001b[0m     \u001b[39mlambda\u001b[39;49;00m col, c: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_convert_data(col, c, convert_dates\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1384\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/pandas/io/json/_json.py:1364\u001b[0m, in \u001b[0;36mFrameParser._process_converter\u001b[0;34m(self, f, filt)\u001b[0m\n\u001b[1;32m   1362\u001b[0m \u001b[39mfor\u001b[39;00m i, (col, c) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(obj\u001b[39m.\u001b[39mitems()):\n\u001b[1;32m   1363\u001b[0m     \u001b[39mif\u001b[39;00m filt(col, c):\n\u001b[0;32m-> 1364\u001b[0m         new_data, result \u001b[39m=\u001b[39m f(col, c)\n\u001b[1;32m   1365\u001b[0m         \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m   1366\u001b[0m             c \u001b[39m=\u001b[39m new_data\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/pandas/io/json/_json.py:1383\u001b[0m, in \u001b[0;36mFrameParser._try_convert_types.<locals>.<lambda>\u001b[0;34m(col, c)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_dates:\n\u001b[1;32m   1380\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_convert_dates()\n\u001b[1;32m   1382\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_converter(\n\u001b[0;32m-> 1383\u001b[0m     \u001b[39mlambda\u001b[39;00m col, c: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_convert_data(col, c, convert_dates\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1384\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/pandas/io/json/_json.py:1222\u001b[0m, in \u001b[0;36mParser._try_convert_data\u001b[0;34m(self, name, data, use_dtypes, convert_dates)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39mand\u001b[39;00m data\u001b[39m.\u001b[39mdtype \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mfloat\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   1220\u001b[0m     \u001b[39m# coerce ints if we can\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1222\u001b[0m         new_data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mastype(\u001b[39m\"\u001b[39;49m\u001b[39mint64\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1223\u001b[0m         \u001b[39mif\u001b[39;00m (new_data \u001b[39m==\u001b[39m data)\u001b[39m.\u001b[39mall():\n\u001b[1;32m   1224\u001b[0m             data \u001b[39m=\u001b[39m new_data\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/pandas/core/generic.py:6313\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6310\u001b[0m                 \u001b[39mraise\u001b[39;00m\n\u001b[1;32m   6311\u001b[0m         results\u001b[39m.\u001b[39mappend(res_col)\n\u001b[0;32m-> 6313\u001b[0m \u001b[39melif\u001b[39;00m is_extension_array_dtype(dtype) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   6314\u001b[0m     \u001b[39m# GH 18099/22869: columnwise conversion to extension dtype\u001b[39;00m\n\u001b[1;32m   6315\u001b[0m     \u001b[39m# GH 24704: use iloc to handle duplicate column names\u001b[39;00m\n\u001b[1;32m   6316\u001b[0m     \u001b[39m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n\u001b[1;32m   6317\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[1;32m   6318\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m   6319\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[1;32m   6320\u001b[0m     ]\n\u001b[1;32m   6322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6323\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/pandas/core/dtypes/common.py:1386\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1384\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1385\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1386\u001b[0m     \u001b[39mreturn\u001b[39;00m registry\u001b[39m.\u001b[39;49mfind(dtype) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/pandas/core/dtypes/base.py:521\u001b[0m, in \u001b[0;36mRegistry.find\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[39mfor\u001b[39;00m dtype_type \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtypes:\n\u001b[1;32m    520\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 521\u001b[0m         \u001b[39mreturn\u001b[39;00m dtype_type\u001b[39m.\u001b[39;49mconstruct_from_string(dtype)\n\u001b[1;32m    522\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    523\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_mmd/lib/python3.8/site-packages/pandas/core/dtypes/base.py:282\u001b[0m, in \u001b[0;36mExtensionDtype.construct_from_string\u001b[0;34m(cls, string)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39m# error: Non-overlapping equality check (left operand type: \"str\", right\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39m#  operand type: \"Callable[[ExtensionDtype], str]\")  [comparison-overlap]\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39mstr\u001b[39m), (\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[0;32m--> 282\u001b[0m \u001b[39mif\u001b[39;00m string \u001b[39m!=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mname:\n\u001b[1;32m    283\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot construct a \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m from \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mstring\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    284\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = train_all_epochs(opt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Start Transfer Learning using [linear_probing]\n",
      "========================================================================\n",
      "Load image embedding of Waterbirds: None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mif\u001b[39;00m opt\u001b[39m.\u001b[39mdataset \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mwaterbirds\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     10\u001b[0m     \u001b[39m# build dataset example.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoad image embedding of Waterbirds: \u001b[39m\u001b[39m{\u001b[39;00mopt\u001b[39m.\u001b[39mimage_embedding_dir\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     trainset \u001b[39m=\u001b[39m WaterbirdsEmbeddings(opt\u001b[39m.\u001b[39;49mdata_dir, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, opt\u001b[39m.\u001b[39;49mimage_embedding_dir, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     13\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mㄴ Corresponding text embedding of Waterbirds: \u001b[39m\u001b[39m{\u001b[39;00mopt\u001b[39m.\u001b[39mtext_embedding_dir\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[39m# build data loader\u001b[39;00m\n",
      "File \u001b[0;32m~/workstation/project/debiasing-multi-modal/data/waterbirds_embeddings.py:26\u001b[0m, in \u001b[0;36mWaterbirdsEmbeddings.__init__\u001b[0;34m(self, data_dir, split, embedding_dir, transform)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_dir \u001b[39m=\u001b[39m embedding_dir\n\u001b[1;32m     24\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m2\u001b[39m}\n\u001b[0;32m---> 26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_dir, \u001b[39m'\u001b[39;49m\u001b[39mmetadata.csv\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata_df[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata_df[\u001b[39m'\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit]]\n\u001b[1;32m     29\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_json(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_dir) \u001b[39m# key : image_filename\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_mmd/lib/python3.8/posixpath.py:76\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(a, \u001b[39m*\u001b[39mp):\n\u001b[1;32m     72\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Join two or more pathname components, inserting '/' as needed.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39m    If any component is an absolute path, all previous path components\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m    will be discarded.  An empty last part will result in a path that\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39m    ends with a separator.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     a \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mfspath(a)\n\u001b[1;32m     77\u001b[0m     sep \u001b[39m=\u001b[39m _get_sep(a)\n\u001b[1;32m     78\u001b[0m     path \u001b[39m=\u001b[39m a\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "best_model = None\n",
    "# opt = parse_option()\n",
    "\n",
    "\n",
    "print(f\"> Start Transfer Learning using [{opt.tl_method}]\")\n",
    "print('========================================================================')\n",
    "if opt.dataset == 'waterbirds':\n",
    "    # build dataset example.\n",
    "    print(f\"Load image embedding of Waterbirds: {opt.image_embedding_dir}\")\n",
    "    trainset = WaterbirdsEmbeddings(opt.data_dir, 'train', opt.image_embedding_dir, None)\n",
    "    print(f\"ㄴ Corresponding text embedding of Waterbirds: {opt.text_embedding_dir}\")\n",
    "    # build data loader\n",
    "    print(\"Load Data Loader (train, validation, test)\")\n",
    "    train_loader, val_loader, test_loader = load_waterbirds_embeddings(opt.data_dir, opt.image_embedding_dir, opt.batch_size, opt.batch_size)\n",
    "    \n",
    "    # print training target\n",
    "    if opt.train_target == \"class\":\n",
    "        print(f\"Training target : {opt.train_target} (Land bird(0) / Water bird(1))\")\n",
    "    elif opt.train_target == \"spurious\":\n",
    "        print(f\"Training target : {opt.train_target} (Land background(0) / Water background(1))\")\n",
    "    \n",
    "elif opt.dataset == 'celeba':\n",
    "    # build dataset example.\n",
    "    print(f\"Load embedding of CelebA: {opt.image_embedding_dir}\")\n",
    "    trainset = CelebaEmbeddings(opt.data_dir, 'train', opt.image_embedding_dir, None)\n",
    "    print(f\"ㄴ Corresponding text embedding of Waterbirds: {opt.text_embedding_dir}\")\n",
    "    # build data loader\n",
    "    print(\"Load Data Loader (train, validation, test)\")\n",
    "    train_loader, val_loader, test_loader = load_celeba_embeddings(opt.data_dir, opt.image_embedding_dir, opt.batch_size, opt.batch_size)\n",
    "    \n",
    "    # print training target\n",
    "    if opt.train_target == \"class\":\n",
    "        print(f\"Training target : {opt.train_target} (non-blond hair(0) / blond hair(1))\")\n",
    "    elif opt.train_target == \"spurious\":\n",
    "        print(f\"Training target : {opt.train_target} (female(0) / male(1))\")\n",
    "\n",
    "# group information\n",
    "get_yp_func = partial(get_y_p, n_places=trainset.n_places)\n",
    "train_group_ratio = trainset.group_ratio\n",
    "\n",
    "# build model and criterion\n",
    "classifier, criterion = set_model(opt) # model, \n",
    "\n",
    "# build optimizer\n",
    "print(\"Set Optimizer: SGD (default)\")\n",
    "print('========================================================================')\n",
    "optimizer = set_optimizer(opt, classifier)\n",
    "\n",
    "# training routine\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "train_group_accs = []\n",
    "\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "val_group_accs = []\n",
    "\n",
    "test_losses = [] # NOTE: Don't peek ! \n",
    "test_accs = [] # NOTE: Don't peek ! \n",
    "test_group_accs = [] # NOTE: Don't peek ! \n",
    "\n",
    "# entire training\n",
    "for epoch in range(1, opt.epochs + 1):\n",
    "    adjust_learning_rate(opt, optimizer, epoch)\n",
    "    print(f'--- Epoch {epoch} ---')\n",
    "    \n",
    "    # train one epoch\n",
    "    loss, acc, group_acc = train_one_epoch(opt, train_loader, classifier, criterion,\n",
    "                        optimizer, epoch, get_yp_func, target=opt.train_target, print_label=f'Train({opt.train_target})')\n",
    "    \n",
    "    train_losses.append(loss); train_accs.append(acc); train_group_accs.append(group_acc)\n",
    "    \n",
    "    # eval for one epoch\n",
    "    val_loss, val_acc, val_group_acc = validate(opt, val_loader, classifier, criterion, get_yp_func, train_group_ratio, target=opt.train_target, print_label=f'Val({opt.train_target})')\n",
    "    val_losses.append(val_loss); val_accs.append(val_acc); val_group_accs.append(val_group_acc)\n",
    "    \n",
    "    # update best epoch by worst_group accuracy (default)\n",
    "    if val_group_acc['worst_acc'] > best_acc:\n",
    "        best_acc = val_group_acc['worst_acc']\n",
    "        best_epoch = epoch\n",
    "        best_model = copy.deepcopy(classifier)\n",
    "    \n",
    "    # test for one epoch\n",
    "    test_loss, test_acc, test_group_acc = validate(opt, test_loader, classifier, criterion, get_yp_func, train_group_ratio, target='class', print_label=f'Test({opt.train_target})')\n",
    "    \n",
    "    test_losses.append(test_loss); test_accs.append(test_acc); test_group_accs.append(test_group_acc)\n",
    "    \n",
    "\n",
    "print('========================================================================')\n",
    "print(\"> end of training. \\n\")\n",
    "print('best epoch : {}'.format(best_epoch))\n",
    "\n",
    "best_train_group_acc = train_group_accs[best_epoch-1]\n",
    "best_val_group_acc = val_group_accs[best_epoch-1]\n",
    "best_test_group_acc = test_group_accs[best_epoch-1]\n",
    "\n",
    "print(f'best training accuracy on [{opt.train_target}]: {best_train_group_acc}')\n",
    "print(f'best validation accuracy on [{opt.train_target}]: {best_val_group_acc}')\n",
    "print(f'best test accuracy on [{opt.train_target}]: {best_test_group_acc}')\n",
    "\n",
    "# Evaluate Feature Quality using (Embedding-based) Zero-shot Prediction\n",
    "print('========================================================================')\n",
    "print(\"> start evaluating feature quality of best model. (using zero-shot prediction)\\n\")\n",
    "\n",
    "\n",
    "# Zero-shot [class] prediction\n",
    "zs_loss, zs_acc, zs_group_acc = validate_zs(opt, test_loader, best_model, criterion, get_yp_func, train_group_ratio, target=\"class\", print_label='zero-shot prediction (test) (class)')    \n",
    "\n",
    "if opt.tl_method in [\"linear_probing\"]:\n",
    "    print(f\" ㄴ Note that it should be same to [CLIP Zero-shot Baselines, of which worst acc is about 39%], in {opt.tl_method}\")\n",
    "elif opt.tl_method in [\"adapter\", \"contrastive_adapt\"]: \n",
    "    print(f\" ㄴ Note that it should be same to [best test accuracy on [{opt.train_target}]], above, in {opt.tl_method}\")\n",
    "\n",
    "# Zero-shot [spurious] prediction\n",
    "zs_loss_spurious, zs_acc_spurious, zs_group_acc_spurious = validate_zs(opt, test_loader, best_model, criterion, get_yp_func, train_group_ratio, target=\"spurious\", print_label='zero-shot prediction (test) (spurious)')    \n",
    "print(f\" ㄴ Note that it is related to [richness of non-target (spurious) information] (-> 'mean_acc' is important)\")\n",
    "\n",
    "print('========================================================================')\n",
    "# Recommendation : False when multiple training\n",
    "if opt.save_results:\n",
    "    print('> Save results\\n')\n",
    "    all_results = {}\n",
    "    \n",
    "    for epoch in range(1, opt.epochs + 1):\n",
    "        all_results[f\"Epoch {epoch}\"] = {\"Train\": train_group_accs[epoch-1], \"Val\": test_group_accs[epoch-1], \"Test\": test_group_accs[epoch-1]}\n",
    "    \n",
    "    final_results = {\"Final Results (best epoch)\":  {f\"Epoch {best_epoch}\": {\"Train\": best_train_group_acc, \"Val\": best_val_group_acc, \"Test\": best_test_group_acc}}, \n",
    "                        \"Feature Quality (using zs)\":  {\"class\":  zs_group_acc, \"spurious\": zs_group_acc_spurious}, \n",
    "                        \"All Results (all epoch)\": all_results}\n",
    "    \n",
    "    # make result folder \n",
    "    final_result_folder = os.path.dirname(opt.image_embedding_dir).replace('data', 'results')\n",
    "    if not os.path.exists(final_result_folder):\n",
    "        os.makedirs(final_result_folder)\n",
    "        \n",
    "    image_ebd_file_name = os.path.basename(opt.image_embedding_dir).split(\".\")[0]\n",
    "    text_ebd_file_name = os.path.basename(opt.text_embedding_dir).split(\".\")[0]\n",
    "    \n",
    "    # result name\n",
    "    final_result_file_name = f\"im_{image_ebd_file_name}_t_{text_ebd_file_name}_tl_{opt.tl_method}_t_{opt.train_target}_lr_{opt.learning_rate}_bs_{opt.batch_size}\"\n",
    "    \n",
    "    # NOTE This file name can be modified when we add baselines\n",
    "    \"\"\"\n",
    "    E.g., if we use [flexable_adapter] and corresponding h.p. [flexable_weight], then, \n",
    "    if opt.tl_method == \"flexable_adpater\":\n",
    "        final_result_file_name += f\"_{opt.flexable_weight}\"\n",
    "    if opt.cosine:\n",
    "        opt.model_name = '{}_cosine'.format(opt.model_name)\n",
    "    if opt.warm:\n",
    "        opt.model_name = '{}_warm'.format(opt.model_name)\n",
    "    \"\"\"\n",
    "\n",
    "    # result path\n",
    "    final_result_file_path = os.path.join(final_result_folder, final_result_file_name + \".json\")\n",
    "    final_model_path = os.path.join(final_result_folder, final_result_file_name + \".pth\")\n",
    "    \n",
    "    print('final result path: ', final_result_file_path)\n",
    "    print('final model path: ', final_model_path)\n",
    "    \n",
    "    # save results, as json.\n",
    "    with open(final_result_file_path, \"w\") as f:\n",
    "        json.dump(final_results, f, indent=4)\n",
    "    \n",
    "    # save final model, as pth \n",
    "    torch.save(best_model.state_dict(), final_model_path)    \n",
    "        \n",
    "\n",
    "print('========================================================================')\n",
    "print(\"> end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_slice_indices(dataset):\n",
    "    \"\"\"\n",
    "    Get \"slices\" of data belonging to different subgroups from the pre-extracted embeddings\n",
    "    (cf. [data/embeddings_unnormalized/[waterbirds/celeba]/RN50/clip.json])\n",
    "\n",
    "    Args:\n",
    "    - dataset : Custom Dataset (cf. [[waterbirds/celeba]_embedding.py])\n",
    "    Returns:\n",
    "    - sliced_data_indices (int(np.array)[]): List of numpy arrays denoting indices of the dataloader.dataset\n",
    "                                             corresponding to different slices \n",
    "    \"\"\"\n",
    "    # First compute pseudolabels\n",
    "    \n",
    "    # pseudo_labels = torch.hstack(all_predicted) # [N, ]\n",
    "    # correct = torch.hstack(all_correct) # [N, \n",
    "    \n",
    "    embeddings_df = dataset.embeddings_df\n",
    "    train_indices = (embeddings_df.loc[\"split\"]==dataset.split_dict[trainset.split]).values\n",
    "    train_embeddings_df = embeddings_df.T[train_indices]\n",
    "    train_embeddings_df = train_embeddings_df.T\n",
    "    \n",
    "    pseudo_labels = train_embeddings_df.loc[\"y_pred\"].values # [0, 1, 1, 0, 1....]\n",
    "    labels =  train_embeddings_df.loc[\"y\"].values # [1, 1, 0, 0, 1, ....]\n",
    "    correct = (pseudo_labels == labels) # [False, True, False, True, True, ...]\n",
    "    \n",
    "    sliced_data_indices = []\n",
    "    all_correct = []\n",
    "    for label in np.unique(pseudo_labels): # 0으로 예측\n",
    "        group = np.where(pseudo_labels == label)[0] # [0, 3, ...] / [1, 2, 4, ...]\n",
    "        correct_by_group = correct[group] # [False, True, ...] / [True, False, True, ...]\n",
    "        \n",
    "        sliced_data_indices.append(group) # \n",
    "        all_correct.append(correct_by_group) \n",
    "    \n",
    "    \n",
    "    return sliced_data_indices, all_correct # [[0, 3,...], [1, 2, 4, ...]], [[False, True, ...], [True, False, True, ...]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_contrastive_points(dataset, sliced_data_indices,\n",
    "                               sliced_data_correct,\n",
    "                               ):\n",
    "    train_targets = dataset.y_array\n",
    "    train_spurious = dataset.confounder_array\n",
    "    sliced_data_indices_all = np.concatenate(sliced_data_indices)\n",
    "    sliced_data_correct_all = np.zeros(len(train_targets))\n",
    "    sliced_data_correct_all[sliced_data_indices_all] = np.concatenate(\n",
    "        sliced_data_correct)\n",
    "    \n",
    "    sliced_data_incorrect = []\n",
    "    for slice_ix, boolean_array in enumerate(sliced_data_correct):\n",
    "        sliced_data_incorrect.append(np.array([not bool for bool in boolean_array]))\n",
    "    sliced_data_incorrect = np.array(sliced_data_incorrect)\n",
    "    \n",
    "    all_anchors = {'slice_ix': np.zeros(len(train_targets)).astype(int), # 4765\n",
    "                   'in_slice_ix': np.zeros(len(train_targets)).astype(int)} # 4765\n",
    "\n",
    "    \n",
    "    # Store all anchors and negatives\n",
    "    slice_anchors = [None] * len(sliced_data_indices)\n",
    "    slice_negatives = [None] * len(sliced_data_indices)\n",
    "    \n",
    "    \n",
    "    # For positives, just specify by the ground-truth NOTE No.\n",
    "    # (These are the same as negatives in another slice, just organized by class) \n",
    "     ## another slice : 1 prediction. 0 class (즉, 그냥 틀린 친구들 in CnC)\n",
    "     \n",
    "     \n",
    "    # Cnc : Anchor -> correct \n",
    "      # Neg : Different class & Same Prediction\n",
    "      # Pos : Different prediction & Same class\n",
    "    # CA : Anchor -> incorrect\n",
    "    positives_by_class = {}\n",
    "\n",
    "    for slice_ix, data_indices in enumerate(sliced_data_indices): # slice_ix = 0 (즉, prediction=0일 때 기준 서술)\n",
    "        \n",
    "        target_class, target_counts = np.unique(train_targets[data_indices],\n",
    "                                                return_counts=True)\n",
    "        \n",
    "        for tc_ix, tc in enumerate(target_class):\n",
    "            print(f'>> Slice {slice_ix}, target: {tc}, counts: {target_counts[tc_ix]}')\n",
    "        \n",
    "        # Anchors are datapoints in the slice that the model got in-correct (False)\n",
    "        ix = np.where(sliced_data_incorrect[slice_ix])[0] # prediction 0, class 1\n",
    "        print(\n",
    "            f'Slice {slice_ix} % incorrect: {len(ix) / len(data_indices) * 100:<.4f} %')\n",
    "\n",
    "        slice_ix_anchors = {'ix': data_indices[ix],\n",
    "                            'target': train_targets[data_indices][ix], # Only 1\n",
    "                            'incorrect': sliced_data_incorrect[slice_ix][ix], # all True\n",
    "                            'source': np.ones(len(data_indices[ix])).astype(int) * slice_ix, # zero_prediction\n",
    "                            'spurious': train_spurious[data_indices][ix], # 0 or 1 (다만 1이 그 전체 양(5%)에 비해선 비교적 많을 것)\n",
    "                            'ix_by_class': {},} # 1: data_indices[ix] (Class 1)\n",
    "        # Zeroshot prediction 값([0/1])에 따른 data indices 들에 대한 정보들\n",
    "        \n",
    "        # anchor: prediction 0 -> class 1 (즉, zero-prediction에 대한 anchor는 모두 class 1) -> indices\n",
    "        for t in np.unique(train_targets[data_indices][ix]):\n",
    "            tix = np.where(train_targets[data_indices][ix] == t)[0]\n",
    "            slice_ix_anchors['ix_by_class'][t] = data_indices[ix][tix] \n",
    "            \n",
    "        # Negatives: prediction 0 -> class 0 (즉, Anchor와 Different Class) -> indices\n",
    "        # TODO Negatives: prediction 1 -> class 0 (즉, Anchor와 Different Class) 추가해야함.\n",
    "        ## 이 중에 가까운 샘플만 골라서 사용(Water birds에서는 거의 대부분 사용한다고 봐도 무방하다) \n",
    "        nix = np.setdiff1d(np.arange(len(data_indices)), ix) # prediction 0, class 0 (True)\n",
    "        # target_class, target_counts = np.unique(train_targets[data_indices][ix], # Anchor와 같은 Class\n",
    "        #                                         return_counts=True) # (1, 254) (Class 1, anchor 개수)\n",
    "        print(f'Slice {slice_ix} # negative (correct): {len(nix)}')\n",
    "        print(\n",
    "            f'Slice {slice_ix} % negative (correct): {len(nix) / len(data_indices) * 100 :<.4f} %')\n",
    "        \n",
    "        # TODO Negatives: prediction 1 -> class 0 (즉, Anchor와 Different Class) 추가해야함.\n",
    "        print(\n",
    "            f'Unique negative targets: {np.unique(train_targets[data_indices][nix], return_counts=True)}')\n",
    "\n",
    "        slice_ix_negatives = {'ix': list(data_indices[nix]),\n",
    "                                'target': list(train_targets[data_indices][nix]), # All 0\n",
    "                                'incorrect': list(sliced_data_incorrect[slice_ix][nix]),# All False\n",
    "                                'source': list(np.ones(len(data_indices[nix])).astype(int) * slice_ix), # All 0\n",
    "                                'spurious': list(train_spurious[data_indices][nix])} # 0이 많을 것(Major group) (True)\n",
    "\n",
    "        \n",
    "        \n",
    "        # Positives: \"Different prediction\" and \"Same Class(True)\"\n",
    "        ## 즉, 0 prediction & 0 class (다른 Slice의 Positive다)\n",
    "        # Positives, for other slices - for here just save by unique class that was also \"correct\"\n",
    "        ## 즉, \n",
    "        target_class, target_counts = np.unique(train_targets[data_indices][nix], # nix : correct\n",
    "                                                return_counts=True) # (0, 3588) (Class 0, # Correct sample )\n",
    "        correct_data_indices = data_indices[nix] # Pred 0 \n",
    "        \n",
    "        print(f\"Slice {slice_ix} # Positive: (for 'other' slice)\", len(correct_data_indices))\n",
    "        \n",
    "        # print(f'Slice {slice_ix} # positive (correct): {len(nix)}')\n",
    "        \n",
    "        for cix, c in enumerate(target_class): # only 0\n",
    "            pix = np.where(train_targets[correct_data_indices] == c)[0]            \n",
    "\n",
    "            pos_data_indices = list(correct_data_indices[pix])\n",
    "            pos_data_targets = list(\n",
    "                train_targets[correct_data_indices][pix])\n",
    "            pos_data_correct = list(\n",
    "                sliced_data_correct[slice_ix][nix][pix])\n",
    "            pos_data_source = list(\n",
    "                np.ones(len(data_indices[nix][pix])).astype(int) * slice_ix)\n",
    "            pos_data_spurious = list(\n",
    "                train_spurious[correct_data_indices][pix])\n",
    "            # print(\"pos_data_indices\", pos_data_indices[:5])\n",
    "            # print(\"pos_data_targets\", pos_data_targets[:5])\n",
    "            # print(\"pos_data_correct \", pos_data_correct[:5])\n",
    "            # print(\"pos_data_source \",pos_data_source[:5])\n",
    "            # print(\"pos_data_spurious\", pos_data_spurious[:5])\n",
    "            # print(\"pos_data_indices\", len(pos_data_indices))\n",
    "            # print(\"pos_data_targets\", len(pos_data_targets))\n",
    "            # print(\"pos_data_correct \", len(pos_data_correct))\n",
    "            # print(\"pos_data_source \",len(pos_data_source))\n",
    "            # print(\"pos_data_spurious\", len(pos_data_spurious))\n",
    "            if c in positives_by_class:\n",
    "                positives_by_class[c]['ix'].extend(pos_data_indices)\n",
    "                positives_by_class[c]['target'].extend(pos_data_targets)\n",
    "                positives_by_class[c]['correct'].extend(pos_data_correct)\n",
    "                positives_by_class[c]['source'].extend(pos_data_source)\n",
    "                positives_by_class[c]['spurious'].extend(pos_data_spurious)\n",
    "            else:\n",
    "                positives_by_class[c] = {'ix': pos_data_indices,\n",
    "                                            'target': pos_data_targets,\n",
    "                                            'correct': pos_data_correct,\n",
    "                                            'source': pos_data_source,\n",
    "                                            'spurious': pos_data_spurious}\n",
    "            \n",
    "        # Save\n",
    "        slice_anchors[slice_ix] = slice_ix_anchors\n",
    "        slice_negatives[slice_ix] = slice_ix_negatives\n",
    "\n",
    "    # Fill in positives if no slices had the class as spurious\n",
    "    for slice_ix, data_indices in enumerate(sliced_data_indices):\n",
    "        target_class, target_counts = np.unique(train_targets[data_indices],\n",
    "                                                return_counts=True)\n",
    "\n",
    "        # Compare average correctness, still use the max_class variable\n",
    "        avg_correct = []\n",
    "        for c in target_class:\n",
    "            class_indices = np.where(train_targets[data_indices] == c)[0]\n",
    "            class_correct = sliced_data_correct[slice_ix][class_indices]\n",
    "            avg_correct.append(np.mean(class_correct))\n",
    "        max_class_ix = np.argmax(avg_correct)\n",
    "\n",
    "        for c in target_class:\n",
    "            if c not in positives_by_class:\n",
    "                print(\n",
    "                    f'> Loading correct datapoints as positives for class {c} from slice {slice_ix}')\n",
    "                ix = np.where(train_targets[data_indices] == c)[0]\n",
    "                positives_by_class[c] = {'ix': list(data_indices[ix]),\n",
    "                                         'target': list(train_targets[data_indices][ix]),\n",
    "                                         'correct': list(sliced_data_correct[slice_ix][ix]),\n",
    "                                         'source': list(np.ones(len(data_indices[ix])).astype(int) * slice_ix),\n",
    "                                         'spurious': list(train_spurious[data_indices][ix])}\n",
    "\n",
    "    # Convert casted lists back to ndarrays\n",
    "    for c, class_dict in positives_by_class.items():\n",
    "        for k, v in class_dict.items():\n",
    "            positives_by_class[c][k] = np.array(v)\n",
    "\n",
    "    for ix, slice_negative in enumerate(slice_negatives):\n",
    "        for k, v in slice_negative.items():\n",
    "            slice_negatives[ix][k] = np.array(v)\n",
    "\n",
    "\n",
    "    return slice_anchors, slice_negatives, positives_by_class, all_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.n_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust number of negatives or positives if > sliced neg / pos\n",
    "def adjust_num_pos_neg_(positives_by_class, slice_negatives,\n",
    "                        args):\n",
    "    \n",
    "    print(f'given number of positives: {args.num_anchor}')\n",
    "    print(f'given number of positives: {args.num_positive}')\n",
    "    print(f'given number of negatives: {args.num_negative}')\n",
    "    num_pos = np.min([len(positives_by_class[c]['target'])\n",
    "                      for c in range(args.n_cls)])\n",
    "    num_neg = np.min([len(negative_dict['target'])\n",
    "                      for negative_dict in slice_negatives])\n",
    "    num_pos = np.min((args.num_positive, num_pos))\n",
    "    num_neg = np.min((args.num_negative, num_neg))\n",
    "\n",
    "    # Tentative\n",
    "    num_anc = np.min((args.num_anchor, np.min((num_pos, num_neg))))\n",
    "\n",
    "    # Adjust experiment name to reflect\n",
    "    # args.experiment_name = args.experiment_name.replace(\n",
    "    #     f'-na={args.num_anchor}-np={args.num_positive}-nn={args.num_negative}',\n",
    "    #     f'-na={num_anc}-np={num_pos}-nn={num_neg}')\n",
    "    # Adjust arguments\n",
    "    args.num_positive = num_pos\n",
    "    args.num_negative = num_neg\n",
    "    args.num_anchor = num_anc\n",
    "    print(f'Adjusted number of anchors:   {args.num_anchor}')\n",
    "    print(f'Adjusted number of positives: {args.num_positive}')\n",
    "    print(f'Adjusted number of negatives: {args.num_negative}')\n",
    "    \n",
    "# Adjust number of anchors or hard negatives if > sliced anc / neg\n",
    "def adjust_num_anc_neg_(slice_anchors, slice_negatives,\n",
    "                        args):\n",
    "    num_anc = np.min([len(anchor_dict['target'])\n",
    "                      for anchor_dict in slice_anchors])\n",
    "    num_neg = np.min([len(negative_dict['target'])\n",
    "                      for negative_dict in slice_negatives])\n",
    "    num_anc = np.min((args.num_anchor, num_anc))\n",
    "    # num_neg Because now both anchors and negatives are from the nonspurious groups\n",
    "    num_neg = np.min((args.num_negative_easy, num_anc))\n",
    "\n",
    "    # Tentative\n",
    "    # num_anc = np.min((args.num_anchor, np.min((num_pos, num_neg))))\n",
    "\n",
    "    # Adjust experiment name to reflect\n",
    "    # args.experiment_name = args.experiment_name.replace(\n",
    "    #     f'-na={args.num_anchor}-np={args.num_positive}-nn={args.num_negative}-ne={args.num_negative_easy}',\n",
    "    #     f'-na={num_anc}-np={args.num_positive}-nn={args.num_negative}-ne={num_neg}')\n",
    "    # Adjust arguments\n",
    "    args.num_anchor = num_anc\n",
    "    args.num_negative_easy = num_neg\n",
    "    print(f'Adjusted number of anchors:   {args.num_anchor}')\n",
    "    print(f'Adjusted number of (hard) negatives: {args.num_negative_easy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.num_anchor = 1\n",
    "opt.num_positive = 2048\n",
    "opt.num_negative = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.anc_loss_temp = 0.5\n",
    "opt.pos_loss_temp = 0.5\n",
    "opt.neg_loss_temp = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_anchors(anchor_class, anchor_dict, num_anchor):\n",
    "    p = None\n",
    "\n",
    "    num_samples = num_anchor\n",
    "    sample_indices = anchor_dict['ix_by_class'][anchor_class]\n",
    "    replace = True if num_samples > len(sample_indices) else False\n",
    "    sample_indices = np.random.choice(sample_indices,\n",
    "                                      size=num_samples,\n",
    "                                      replace=replace,\n",
    "                                      p=p)\n",
    "    return sample_indices\n",
    "\n",
    "\n",
    "def sample_positives(anchor_class, positives_by_class, num_positive):\n",
    "    positive_dict = positives_by_class[anchor_class]\n",
    "    p = None\n",
    "    num_samples = num_positive\n",
    "    replace = True if num_samples > len(positive_dict['ix']) else False\n",
    "\n",
    "    sample_indices = np.random.choice(np.arange(len(positive_dict['ix'])),\n",
    "                                      size=num_samples,\n",
    "                                      replace=replace,\n",
    "                                      p=p)\n",
    "    sample_slice_sources = positive_dict['source'][sample_indices]\n",
    "    sample_indices = positive_dict['ix'][sample_indices]\n",
    "    return sample_indices, sample_slice_sources\n",
    "\n",
    "\n",
    "def sample_negatives(negative_dict, num_negative):\n",
    "    p = None\n",
    "\n",
    "    num_samples = num_negative\n",
    "    replace = True if num_samples > len(negative_dict['ix']) else False\n",
    "    sample_indices = np.random.choice(negative_dict['ix'],\n",
    "                                      size=num_samples,\n",
    "                                      replace=replace,\n",
    "                                      p=p)\n",
    "    return sample_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resampled_set(dataset, resampled_set_indices, copy_dataset=False):\n",
    "    \"\"\"\n",
    "    Obtain spurious dataset resampled_set\n",
    "    Args:\n",
    "    - dataset (torch.utils.data.Dataset): Spurious correlations dataset\n",
    "    - resampled_set_indices (int[]): List-like of indices \n",
    "    - deepcopy (bool): If true, copy the dataset\n",
    "    \"\"\"\n",
    "    resampled_set = copy.deepcopy(dataset) if copy_dataset else dataset\n",
    "    try:  # Some dataset classes may not have these attributes\n",
    "        resampled_set.y_array = resampled_set.y_array[resampled_set_indices]\n",
    "        resampled_set.group_array = resampled_set.group_array[resampled_set_indices]\n",
    "        resampled_set.split_array = resampled_set.split_array[resampled_set_indices]\n",
    "        resampled_set.targets = resampled_set.y_array\n",
    "        try:  # Depending on the dataset these are responsible for the X features\n",
    "            resampled_set.filename_array = resampled_set.filename_array[resampled_set_indices]\n",
    "        except:\n",
    "            resampled_set.x_array = resampled_set.x_array[resampled_set_indices]\n",
    "    except AttributeError as e:\n",
    "        raise NameError (\"resampled dataset 수정.\")\n",
    "        try:\n",
    "            resampled_set.targets = resampled_set.targets[resampled_set_indices]\n",
    "        except:\n",
    "            resampled_set_indices = np.concatenate(resampled_set_indices)\n",
    "            resampled_set.targets = resampled_set.targets[resampled_set_indices]\n",
    "        try:\n",
    "            resampled_set.df = resampled_set.df.iloc[resampled_set_indices]\n",
    "        except AttributeError:\n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            resampled_set.data = resampled_set.data[resampled_set_indices]\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        \n",
    "        try:  # Depending on the dataset these are responsible for the X features\n",
    "            resampled_set.filename_array = resampled_set.filename_array[resampled_set_indices]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    resampled_embeddings_df = resampled_set.embeddings_df.copy()\n",
    "    resampled_embeddings_df = resampled_embeddings_df.T\n",
    "    resampled_set.embeddings_df = resampled_embeddings_df.iloc[resampled_set_indices]\n",
    "        \n",
    "    print('len(resampled_set.targets)', len(resampled_set.targets))\n",
    "    return resampled_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_contrastive_data(train_loader, slice_anchors,\n",
    "                          slice_negatives, positives_by_class,\n",
    "                          seed, args, supervised_contrast=True):\n",
    "    # Get number of negatives per target class\n",
    "    args.num_negatives_by_target = [0] * args.n_cls\n",
    "\n",
    "    batch_samples = []\n",
    "    batch_samples_old = []\n",
    "\n",
    "    for slice_ix, anchor_dict in enumerate(slice_anchors):\n",
    "        batch_samples_per_slice = []  # First aggregate within\n",
    "        negative_dict = slice_negatives[slice_ix]\n",
    "        # For hard negative\n",
    "        args.num_negatives_by_target[slice_ix] = len(negative_dict['ix'])\n",
    "\n",
    "        anchor_targets = anchor_dict['target']\n",
    "        anchor_indices = anchor_dict['ix']\n",
    "\n",
    "        # 254, 94 (Prediction 0에서의 False, Prediction 1에서의 False )\n",
    "        for aix, anchor_ix in enumerate(tqdm(anchor_indices, desc=f'Generating data from slice {slice_ix}')): \n",
    "            anchor_class = anchor_targets[aix]\n",
    "            # Sample additional positives\n",
    "            anchor_indices = sample_anchors(anchor_class,\n",
    "                                            anchor_dict,\n",
    "                                            args.num_anchor - 1)\n",
    "            anchor_indices = np.concatenate([[anchor_ix], anchor_indices]) # (1, )\n",
    "            \n",
    "            positive_outputs = sample_positives(anchor_class,\n",
    "                                                positives_by_class,\n",
    "                                                args.num_positive)\n",
    "            positive_indices, positive_slice_sources = positive_outputs # (n_positives, )\n",
    "            \n",
    "            # Keep as this, in case want to generate new neg per pos as before\n",
    "            samples = [anchor_indices, positive_indices]\n",
    "            negative_indices = sample_negatives(negative_dict,\n",
    "                                                args.num_negative) # (n_negatives, )\n",
    "            samples.append(negative_indices)\n",
    "    \n",
    "            batch_sample = np.concatenate(samples) # (# positive * # negative)\n",
    "            batch_samples_per_slice.append(batch_sample)\n",
    "            batch_samples_old.append(batch_sample)\n",
    "            \n",
    "        np.random.shuffle(batch_samples_per_slice) # (# anchor, # positive * # negative): (254, 1719) / (94. 1719)\n",
    "        batch_samples.append(batch_samples_per_slice)\n",
    "        print(\"batch_samples_per_slice.shape\", np.array(batch_samples_per_slice).shape) \n",
    "\n",
    "    # print(\"batch_samples.shape\", np.array(batch_samples[0]).shape) # (254, 1719)\n",
    "    # print(\"batch_samples.shape\", np.array(batch_samples[1]).shape) # (94, 1719)\n",
    "    batch_samples = list(zip(*batch_samples)) # (94, 2, 1719) (우선 Prediction 비율에 따라 Balanced로 구성.)\n",
    "    print(np.array(batch_samples).shape)\n",
    "    \n",
    "    batch_samples = np.array(batch_samples).reshape(-1, len(batch_sample)) # (188, 1719)\n",
    "    \n",
    "    contrastive_indices = np.concatenate(batch_samples)\n",
    "    contrastive_train_set = get_resampled_set(train_loader.dataset,\n",
    "                                              contrastive_indices,\n",
    "                                              copy_dataset=True)\n",
    "\n",
    "    contrastive_dataloader = DataLoader(contrastive_train_set,\n",
    "                                        batch_size=len(\n",
    "                                            batch_samples[0]) * int(args.batch_factor),\n",
    "                                        shuffle=False, num_workers=args.num_workers)\n",
    "\n",
    "    return contrastive_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(SupervisedContrastiveLoss, self).__init__()\n",
    "        self.temperature = args.zs_temperature\n",
    "        self.n_positives = args.num_positive\n",
    "        self.n_negatives = args.num_negative\n",
    "        self.arch = args.model\n",
    "        self.args = args\n",
    "    \n",
    "        self.sim = nn.CosineSimilarity(dim=1)\n",
    "        \n",
    "    def forward(self, model, contrastive_batch):\n",
    "        # Compute negative similarities\n",
    "        neg_indices = [0] + list(range(len(contrastive_batch))[\n",
    "            -self.n_negatives:])\n",
    "        anchor_negatives = contrastive_batch[neg_indices]\n",
    "        exp_neg = self.compute_exp_sim(model, anchor_negatives,\n",
    "                                       return_sum=False)\n",
    "    \n",
    "        sum_exp_neg = exp_neg.sum(0, keepdim=True)\n",
    "            \n",
    "        # Compute positive similarities\n",
    "        anchor_positives = contrastive_batch[:1 + self.n_positives]\n",
    "        exp_pos = self.compute_exp_sim(model, anchor_positives, \n",
    "                                       return_sum=False)\n",
    "        \n",
    "        \n",
    "        log_probs = (torch.log(exp_pos) - \n",
    "                        torch.log(sum_exp_neg + exp_pos.sum(0, keepdim=True)))\n",
    "        loss = -1 * log_probs\n",
    "        del exp_pos; del exp_neg; del log_probs\n",
    "        return loss.mean()\n",
    "    \n",
    "    def compute_exp_sim(self, model, features, return_sum=True):\n",
    "        \"\"\"\n",
    "        Compute sum(sim(anchor, pos)) or sum(sim(anchor, neg))\n",
    "        \"\"\"\n",
    "    \n",
    "        outputs = model(features)\n",
    "        \n",
    "        sim = self.sim(outputs[0].view(1, -1), outputs[1:])\n",
    "        exp_sim = torch.exp(torch.div(sim, self.temperature))\n",
    "        # Should not detach from graph\n",
    "        features = features.to(torch.device('cpu'))\n",
    "        outputs = outputs.to(torch.device('cpu'))\n",
    "        if return_sum:\n",
    "            sum_exp_sim = exp_sim.sum(0, keepdim=True)\n",
    "            exp_sim.detach_().cpu(); del exp_sim\n",
    "            return sum_exp_sim\n",
    "        return exp_sim\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in [def compute_slice_indices()]\n",
    "  - labels에 따른 subsampling 생략.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.batch_factor = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2874852/3558943042.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sliced_data_incorrect = np.array(sliced_data_incorrect)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Slice 0, target: 0, counts: 3588\n",
      ">> Slice 0, target: 1, counts: 254\n",
      "Slice 0 % incorrect: 6.6111 %\n",
      "Slice 0 # negative (correct): 3588\n",
      "Slice 0 % negative (correct): 93.3889 %\n",
      "Unique negative targets: (array([0]), array([3588]))\n",
      "Slice 0 # Positive: (for 'other' slice) 3588\n",
      ">> Slice 1, target: 0, counts: 94\n",
      ">> Slice 1, target: 1, counts: 859\n",
      "Slice 1 % incorrect: 9.8636 %\n",
      "Slice 1 # negative (correct): 859\n",
      "Slice 1 % negative (correct): 90.1364 %\n",
      "Unique negative targets: (array([1]), array([859]))\n",
      "Slice 1 # Positive: (for 'other' slice) 859\n",
      "given number of positives: 1\n",
      "given number of positives: 859\n",
      "given number of negatives: 859\n",
      "Adjusted number of anchors:   1\n",
      "Adjusted number of positives: 859\n",
      "Adjusted number of negatives: 859\n",
      "Off-the-shelf classifier : [Adapter + (temperatured) image-text jointly normalized prediction]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data from slice 0: 100%|██████████| 254/254 [00:00<00:00, 9830.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_samples_per_slice.shape (254, 1719)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data from slice 1: 100%|██████████| 94/94 [00:00<00:00, 9413.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_samples_per_slice.shape (94, 1719)\n",
      "(94, 2, 1719)\n",
      "len(resampled_set.targets) 323172\n",
      "Set Optimizer: SGD (default)\n",
      "========================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Main Code\n",
    "sliced_data_indices, sliced_data_correct = compute_slice_indices(trainset)\n",
    "contrastive_points = prepare_contrastive_points(trainset,sliced_data_indices,sliced_data_correct)\n",
    "\n",
    "\n",
    "slice_anchors, slice_negatives, positives_by_class, all_targets = contrastive_points\n",
    "\n",
    "adjust_num_pos_neg_(positives_by_class, slice_negatives, opt)\n",
    "\n",
    "checkpoint = None\n",
    "\n",
    "# build model and criterion\n",
    "classifier, ce_loss = set_model(opt) # model, \n",
    "\n",
    "if opt.tl_method==\"contrastive_adapter\":\n",
    "    contrastive_loss = SupervisedContrastiveLoss(opt)\n",
    "    train_losses_ce = []\n",
    "    val_losses_ce = []\n",
    "    \n",
    "    # Get contrastive batches for first epoch\n",
    "    contrastive_dataloader = load_contrastive_data(train_loader,\n",
    "                                                    slice_anchors,\n",
    "                                                    slice_negatives,\n",
    "                                                    positives_by_class,\n",
    "                                                    42, opt, True)\n",
    "\n",
    "# build optimizer\n",
    "print(\"Set Optimizer: SGD (default)\")\n",
    "print('========================================================================')\n",
    "optimizer = set_optimizer(opt, classifier)\n",
    "\n",
    "\n",
    "# # training routine\n",
    "# train_losses = []\n",
    "\n",
    "# train_accs = []\n",
    "# train_group_accs = []\n",
    "\n",
    "# val_losses = []\n",
    "# val_accs = []\n",
    "# val_group_accs = []\n",
    "\n",
    "# test_losses = [] # NOTE: Don't peek ! \n",
    "# test_accs = [] # NOTE: Don't peek ! \n",
    "# test_group_accs = [] # NOTE: Don't peek ! \n",
    "\n",
    "# # entire training\n",
    "# for epoch in range(1, opt.epochs + 1):\n",
    "#     adjust_learning_rate(opt, optimizer, epoch)\n",
    "#     print(f'--- Epoch {epoch} ---')\n",
    "    \n",
    "#     # train one epoch\n",
    "#     loss, acc, group_acc = train_one_epoch(opt, train_loader, classifier, ce_loss,\n",
    "#                         optimizer, epoch, get_yp_func, target=opt.train_target, print_label=f'Train({opt.train_target})')\n",
    "    \n",
    "#     train_losses.append(loss); train_accs.append(acc); train_group_accs.append(group_acc)\n",
    "    \n",
    "#     # eval for one epoch\n",
    "#     val_loss, val_acc, val_group_acc = validate(opt, val_loader, classifier, ce_loss, get_yp_func, train_group_ratio, target=opt.train_target, print_label=f'Val({opt.train_target})')\n",
    "#     val_losses.append(val_loss); val_accs.append(val_acc); val_group_accs.append(val_group_acc)\n",
    "    \n",
    "#     # update best epoch by worst_group accuracy (default)\n",
    "#     if val_group_acc['worst_acc'] > best_acc:\n",
    "#         best_acc = val_group_acc['worst_acc']\n",
    "#         best_epoch = epoch\n",
    "#         best_model = deepcopy(classifier)\n",
    "    \n",
    "#     # test for one epoch\n",
    "#     test_loss, test_acc, test_group_acc = validate(opt, test_loader, classifier, ce_loss, get_yp_func, train_group_ratio, target='class', print_label=f'Test({opt.train_target})')\n",
    "    \n",
    "#     test_losses.append(test_loss); test_accs.append(test_acc); test_group_accs.append(test_group_acc)\n",
    "    \n",
    "\n",
    "# print('========================================================================')\n",
    "# print(\"> end of training. \\n\")\n",
    "# print('best epoch : {}'.format(best_epoch))\n",
    "\n",
    "# best_train_group_acc = train_group_accs[best_epoch-1]\n",
    "# best_val_group_acc = val_group_accs[best_epoch-1]\n",
    "# best_test_group_acc = test_group_accs[best_epoch-1]\n",
    "\n",
    "# print(f'best training accuracy on [{opt.train_target}]: {best_train_group_acc}')\n",
    "# print(f'best validation accuracy on [{opt.train_target}]: {best_val_group_acc}')\n",
    "# print(f'best test accuracy on [{opt.train_target}]: {best_test_group_acc}')\n",
    "\n",
    "# # Evaluate Feature Quality using (Embedding-based) Zero-shot Prediction\n",
    "# print('========================================================================')\n",
    "# print(\"> start evaluating feature quality of best model. (using zero-shot prediction)\\n\")\n",
    "\n",
    "\n",
    "# # Zero-shot [class] prediction\n",
    "# zs_loss, zs_acc, zs_group_acc = validate_zs(opt, test_loader, best_model, criterion, get_yp_func, train_group_ratio, target=\"class\", print_label='zero-shot prediction (test) (class)')    \n",
    "\n",
    "# if opt.tl_method in [\"linear_probing\"]:\n",
    "#     print(f\" ㄴ Note that it should be same to [CLIP Zero-shot Baselines, of which worst acc is about 39%], in {opt.tl_method}\")\n",
    "# elif opt.tl_method in [\"adapter\", \"contrastive_adapt\"]: \n",
    "#     print(f\" ㄴ Note that it should be same to [best test accuracy on [{opt.train_target}]], above, in {opt.tl_method}\")\n",
    "\n",
    "# # Zero-shot [spurious] prediction\n",
    "# zs_loss_spurious, zs_acc_spurious, zs_group_acc_spurious = validate_zs(opt, test_loader, best_model, criterion, get_yp_func, train_group_ratio, target=\"spurious\", print_label='zero-shot prediction (test) (spurious)')    \n",
    "# print(f\" ㄴ Note that it is related to [richness of non-target (spurious) information] (-> 'mean_acc' is important)\")\n",
    "\n",
    "# print('========================================================================')\n",
    "# # Recommendation : False when multiple training\n",
    "# if opt.save_results:\n",
    "#     print('> Save results\\n')\n",
    "#     all_results = {}\n",
    "    \n",
    "#     for epoch in range(1, opt.epochs + 1):\n",
    "#         all_results[f\"Epoch {epoch}\"] = {\"Train\": train_group_accs[epoch-1], \"Val\": test_group_accs[epoch-1], \"Test\": test_group_accs[epoch-1]}\n",
    "    \n",
    "#     final_results = {\"Final Results (best epoch)\":  {f\"Epoch {best_epoch}\": {\"Train\": best_train_group_acc, \"Val\": best_val_group_acc, \"Test\": best_test_group_acc}}, \n",
    "#                         \"Feature Quality (using zs)\":  {\"class\":  zs_group_acc, \"spurious\": zs_group_acc_spurious}, \n",
    "#                         \"All Results (all epoch)\": all_results}\n",
    "    \n",
    "#     # make result folder \n",
    "#     final_result_folder = os.path.dirname(opt.image_embedding_dir).replace('data', 'results')\n",
    "#     if not os.path.exists(final_result_folder):\n",
    "#         os.makedirs(final_result_folder)\n",
    "        \n",
    "#     image_ebd_file_name = os.path.basename(opt.image_embedding_dir).split(\".\")[0]\n",
    "#     text_ebd_file_name = os.path.basename(opt.text_embedding_dir).split(\".\")[0]\n",
    "    \n",
    "#     # result name\n",
    "#     final_result_file_name = f\"im_{image_ebd_file_name}_t_{text_ebd_file_name}_tl_{opt.tl_method}_t_{opt.train_target}_lr_{opt.learning_rate}_bs_{opt.batch_size}\"\n",
    "    \n",
    "#     # NOTE This file name can be modified when we add baselines\n",
    "#     \"\"\"\n",
    "#     E.g., if we use [flexable_adapter] and corresponding h.p. [flexable_weight], then, \n",
    "#     if opt.tl_method == \"flexable_adpater\":\n",
    "#         final_result_file_name += f\"_{opt.flexable_weight}\"\n",
    "#     if opt.cosine:\n",
    "#         opt.model_name = '{}_cosine'.format(opt.model_name)\n",
    "#     if opt.warm:\n",
    "#         opt.model_name = '{}_warm'.format(opt.model_name)\n",
    "#     \"\"\"\n",
    "\n",
    "#     # result path\n",
    "#     final_result_file_path = os.path.join(final_result_folder, final_result_file_name + \".json\")\n",
    "#     final_model_path = os.path.join(final_result_folder, final_result_file_name + \".pth\")\n",
    "    \n",
    "#     print('final result path: ', final_result_file_path)\n",
    "#     print('final model path: ', final_model_path)\n",
    "    \n",
    "#     # save results, as json.\n",
    "#     with open(final_result_file_path, \"w\") as f:\n",
    "#         json.dump(final_results, f, indent=4)\n",
    "    \n",
    "#     # save final model, as pth \n",
    "#     torch.save(best_model.state_dict(), final_model_path)    \n",
    "        \n",
    "\n",
    "# print('========================================================================')\n",
    "# print(\"> end\")\n",
    "\n",
    "\n",
    "\n",
    "# # Reference Code\n",
    "# # slice_outputs = compute_slice_indices()\n",
    "\n",
    "# # sliced_data_indices, sliced_data_correct, = slice_outputs\n",
    "\n",
    "# # -------------\n",
    "# # Train encoder\n",
    "# # -------------\n",
    "\n",
    "# # contrastive_points = prepare_contrastive_points(sliced_data_indices,\n",
    "# #                                                 sliced_data_correct,\n",
    "# #                                                 train_loader, args)\n",
    "# # slice_anchors, slice_negatives, positives_by_class, all_targets = contrastive_points\n",
    "\n",
    "# # adjust_num_pos_neg_(positives_by_class, slice_negatives, args)\n",
    "# # update_args(args)\n",
    "\n",
    "# # project = not args.no_projection_head\n",
    "\n",
    "# # if args.load_encoder != '':\n",
    "# #     args.checkpoint_name = args.load_encoder\n",
    "# #     start_epoch = int(args.checkpoint_name.split(\n",
    "# #         '-cpe=')[-1].split('-')[0])\n",
    "# #     checkpoint = torch.load(os.path.join(args.model_path,\n",
    "# #                                             args.checkpoint_name))\n",
    "# #     print(f'Checkpoint loading from {args.load_encoder}!')\n",
    "# #     print(f'- Resuming training at epoch {start_epoch}')\n",
    "# # else:\n",
    "# #     checkpoint = None\n",
    "\n",
    "# # classifier = copy.deepcopy(encoder.classifier)\n",
    "# # for p in encoder.classifier.parameters():\n",
    "# #     p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ㅁㄴㅇㄹㅁㄴㅇㄹㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdfasfsdfsf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_mmd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

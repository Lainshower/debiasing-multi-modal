{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "sys.path.append(\"/home/jinsu/workstation/project/debiasing-multi-modal\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from util import AverageMeter\n",
    "from util import adjust_learning_rate, warmup_learning_rate, accuracy\n",
    "from util import set_optimizer\n",
    "\n",
    "from data.waterbirds_embeddings import WaterbirdsEmbeddings, load_waterbirds_embeddings\n",
    "from data.celeba_embeddings import CelebaEmbeddings, load_celeba_embeddings\n",
    "model_dict = {'resnet50': [None, 1024]} # (nn.module, 1024)\n",
    "new_order_for_print = [\n",
    "    'weighted_mean_acc',\n",
    "    'worst_acc',\n",
    "    'acc_0_0',\n",
    "    'acc_0_1',\n",
    "    'acc_1_0',\n",
    "    'acc_1_1',\n",
    "    'mean_acc'\n",
    "]\n",
    "from functools import partial\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=2):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, features):\n",
    "        return self.fc(features)\n",
    "\n",
    "\n",
    "\n",
    "class CustomCLIP(nn.Module):\n",
    "    def __init__(self, adapter, text_embedding_dir, text_spurious_embedding_dir, temperature=0.01):\n",
    "        super().__init__()\n",
    "        self.text_embedding_dir = text_embedding_dir\n",
    "        self.text_spurious_embedding_dir = text_spurious_embedding_dir\n",
    "        self.adapter = adapter\n",
    "        self.temperature = temperature # CA default : 0.01, B2T default : 0.02 (?) NOTE\n",
    "        \n",
    "        self.text_features = get_text_embedding(self.text_embedding_dir)\n",
    "        self.text_spurious_features = get_text_embedding(self.text_spurious_embedding_dir)\n",
    "        \n",
    "    def forward(self, features): \n",
    "        image_features =  self.adapter(features) # Un-normalized (B, 1024)\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True) # Normalized (B, 1024)\n",
    "\n",
    "        text_features = self.text_features # (Pre) Normalized (B, 2, 1024)\n",
    "        \n",
    "        logits = image_features @ text_features / self.temperature # (B, 1024) X (B, 2, 1024) = # (B, 2)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def forward_spurious(self, features): \n",
    "        image_features =  self.adapter(features) # Un-normalized (B, 1024)\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True) # Normalized (B, 1024)\n",
    "\n",
    "        text_spurious_features = self.text_spurious_features # (Pre) Normalized (B, 2, 1024)\n",
    "        \n",
    "        logits = image_features @ text_spurious_features / self.temperature # (B, 1024) X (B, 2, 1024) = # (B, 2)\n",
    "        \n",
    "        return logits\n",
    "        \n",
    "class Adapter(nn.Module):\n",
    "    \"\"\"\n",
    "    - Residual connetion : 제외 (original Adapter - 0.2*images + 0.8*adapter)\n",
    "    - Hidden dimension : args.adapter_feat_dim (original Adatper - input_dim // 4)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "    def forward(self, features):\n",
    "        return self.layers(features)\n",
    "\n",
    "def parse_option():\n",
    "    parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "    parser.add_argument('--print_freq', type=int, default=10,\n",
    "                        help='print frequency')\n",
    "    parser.add_argument('--save_freq', type=int, default=50,\n",
    "                        help='save frequency')\n",
    "    parser.add_argument('--batch_size', type=int, default=128,\n",
    "                        help='batch_size')\n",
    "    parser.add_argument('--num_workers', type=int, default=16,\n",
    "                        help='num of workers to use')\n",
    "    parser.add_argument('--epochs', type=int, default=100,\n",
    "                        help='number of training epochs')\n",
    "\n",
    "    # optimization\n",
    "    parser.add_argument('--learning_rate', type=float, default=1e-3, \n",
    "                        help='learning rate') # Tuning needed. \n",
    "    parser.add_argument('--lr_decay_epochs', type=str, default='60,75,90',\n",
    "                        help='where to decay lr, can be a list')\n",
    "    parser.add_argument('--lr_decay_rate', type=float, default=1,\n",
    "                        help='decay rate for learning rate') \n",
    "    parser.add_argument('--weight_decay', type=float, default=5e-5,\n",
    "                        help='weight decay') # Tuning needed. \n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "\n",
    "    # model dataset\n",
    "    parser.add_argument('--model', type=str, default='resnet50')\n",
    "    parser.add_argument('--dataset', type=str, default='waterbirds',\n",
    "                        choices=['celeba', 'waterbirds'], help='dataset')\n",
    "\n",
    "    # other setting\n",
    "    parser.add_argument('--cosine', action='store_true',\n",
    "                        help='using cosine annealing') # Tuning needed. \n",
    "    parser.add_argument('--warm', action='store_true',\n",
    "                        help='warm-up for large batch training') # Tuning needed. \n",
    "\n",
    "    parser.add_argument('--image_embedding_dir', type=str,\n",
    "                        help='extracted image embedding')\n",
    "    parser.add_argument('--text_embedding_dir', type=str,\n",
    "                        help='extracted text embedding')\n",
    "    parser.add_argument('--text_spurious_embedding_dir', type=str,\n",
    "                        help='extracted text embedding (about spurious attributes)')\n",
    "    parser.add_argument('--train_target', type=str, default=\"class\", choices=[\"class\", \"spurious\", \"group\"]) # label for prediction.\n",
    "    parser.add_argument('--data_dir', type=str,\n",
    "                    help='folder, in which metadata.csv] exist')\n",
    "    parser.add_argument('--tl_method', type=str, default= \"linear_probing\", choices=[\"linear_probing\", \"adapter\", \"contrastive_adapter\", \"ETC\"]\n",
    "                        ,help='transfer learning method')\n",
    "    parser.add_argument('--adapter_feat_dim', type=int, default= 128, help='reduced dimension in adapter')\n",
    "    parser.add_argument('--zs_temperature', type=float, default= 0.01, help='Temperature in zero-shot prediction')\n",
    "    parser.add_argument('--watch_batch_results', type=bool, default=False, help='Print results in each bach by [opt.print_freq]. Recommdned: True when single-run of CelebA(Large # of batch), False others')\n",
    "    parser.add_argument('--save_results', type=bool, default=True, help='Save the results of transfer learning (and final feature quality) in the folder where ')\n",
    "    \n",
    "\n",
    "    # parser.add_argument('--lr_linear_probing', type=float, default=1e-3, chocies=[1e-3, 1e-2, 1e-1, 1, 3, 10], help='learning rate for linear probing') # Tuning needed. \n",
    "      # -> Zero-shot으로 대체하는 게 맞을듯.\n",
    "\n",
    "    opt = parser.parse_args(args=[])\n",
    "\n",
    "    # set the path according to the environment\n",
    "\n",
    "    iterations = opt.lr_decay_epochs.split(',')\n",
    "    opt.lr_decay_epochs = list([])\n",
    "    for it in iterations:\n",
    "        opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "    if opt.warm:\n",
    "        opt.warmup_from = 0.01\n",
    "        opt.warm_epochs = 10\n",
    "        if opt.cosine:\n",
    "            eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "            opt.warmup_to = eta_min + (opt.learning_rate - eta_min) * (\n",
    "                    1 + math.cos(math.pi * opt.warm_epochs / opt.epochs)) / 2\n",
    "        else:\n",
    "            opt.warmup_to = opt.learning_rate\n",
    "            \n",
    "    if opt.dataset == 'celeba':\n",
    "        opt.n_cls = 2\n",
    "    elif opt.dataset == 'waterbirds':\n",
    "        opt.n_cls = 2\n",
    "    else:\n",
    "        raise ValueError('dataset not supported: {}'.format(opt.dataset))\n",
    "\n",
    "    return opt\n",
    "\n",
    "\n",
    "def set_model(opt):\n",
    "    # model = SupConResNet(name=opt.model)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "    _ , input_dim = model_dict[opt.model] # (Encoder(not use), feature dim)\n",
    "    \n",
    "    if opt.tl_method =='linear_probing':\n",
    "        print(\"Off-the-shelf classifier : [Linear Classifier]\")\n",
    "        classifier = LinearClassifier(input_dim = input_dim, num_classes = opt.n_cls)\n",
    "    elif opt.tl_method =='adapter':\n",
    "        print(\"Off-the-shelf classifier : [Adapter + (temperatured) image-text jointly normalized prediction]\")\n",
    "        adapter = Adapter(input_dim = input_dim, hidden_dim = opt.adapter_feat_dim) # Fixed by heuristics\n",
    "        classifier = CustomCLIP(adapter, opt.text_embedding_dir, opt.text_spurious_embedding_dir, temperature=opt.zs_temperature)\n",
    "    elif opt.tl_method =='contrastive_adapter':\n",
    "        print(\"Off-the-shelf classifier : [Adapter + (temperatured) image-text jointly normalized prediction]\")\n",
    "        adapter = Adapter(input_dim = input_dim, hidden_dim = opt.adapter_feat_dim) # Fixed by heuristics\n",
    "        classifier = CustomCLIP(adapter, opt.text_embedding_dir, opt.text_spurious_embedding_dir, temperature=opt.zs_temperature)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        classifier = classifier.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    return classifier, criterion # model, \n",
    "\n",
    "# Group-wise Accuracy Update.\n",
    "def update_dict(acc_groups, y, g, logits):\n",
    "    preds = torch.argmax(logits, axis=1)\n",
    "    correct_batch = (preds == y)\n",
    "    g = g.cpu()\n",
    "    for g_val in np.unique(g):\n",
    "        mask = g == g_val\n",
    "        n = mask.sum().item()\n",
    "        corr = correct_batch[mask].sum().item()\n",
    "        acc_groups[g_val].update(corr / n, n) \n",
    "\n",
    "\n",
    "# Mean/Worst acc (not weighted average)\n",
    "def get_results(acc_groups, get_yp_func): # Input 중 acc_groups : AverageMeter()를 담고있는 dict. get_yp_func : 미리 partial을 이용해 n_groups를 저장해놓음. \n",
    "    groups = acc_groups.keys() # 0, 1, 2, 3\n",
    "    results = {\n",
    "            f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\": acc_groups[g].avg\n",
    "            for g in groups\n",
    "    }\n",
    "    all_correct = sum([acc_groups[g].sum for g in groups])\n",
    "    all_total = sum([acc_groups[g].count for g in groups])\n",
    "    results.update({\"mean_acc\" : all_correct / all_total})\n",
    "    results.update({\"worst_acc\" : min(results.values())})\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Group -> class / spurious attributes\n",
    "def get_y_p(g, n_places):\n",
    "    y = g // n_places\n",
    "    p = g % n_places\n",
    "    return y, p\n",
    "\n",
    "def get_text_embedding(text_embedding_dir):\n",
    "    with open(text_embedding_dir, 'r') as f:\n",
    "        text_embeddings = json.load(f)\n",
    "\n",
    "    text_features = []\n",
    "    for class_template, class_embedding in text_embeddings.items():\n",
    "        text_features.append(torch.tensor(class_embedding))\n",
    "    text_features = torch.stack(text_features, dim=1).cuda() # (B, 2, 1024)\n",
    "    \n",
    "    \n",
    "    return text_features\n",
    "\n",
    "def train_one_epoch(opt, train_loader, classifier, criterion, optimizer, epoch, get_yp_func, target, print_label='Train'): # model,\n",
    "    \"\"\"one epoch training\"\"\"\n",
    "    # model.eval()\n",
    "    classifier.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(train_loader.dataset.n_groups)}\n",
    "\n",
    "    end = time.time()\n",
    "    for idx, data in enumerate(train_loader):  \n",
    "        \n",
    "        embeddings, all_labels, img_filenames = data # all_labels.keys() : ['class', 'group', 'spurious', 'ebd_pred'(CLIP-zeroshot)] \n",
    "        labels = all_labels[target] # target : one of [y, spurious, group]\n",
    "        groups = all_labels['group'] # For evaluating group accuracy (and further developing group-information-aware approaches)\n",
    "    \n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        embeddings = embeddings.cuda(non_blocking=True)\n",
    "        labels = labels.cuda(non_blocking=True)\n",
    "        bsz = labels.shape[0]\n",
    "\n",
    "        # warm-up learning rate\n",
    "        warmup_learning_rate(opt, epoch, idx, len(train_loader), optimizer)\n",
    "\n",
    "        # compute loss\n",
    "        output = classifier(embeddings.detach()) \n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # update metric\n",
    "        losses.update(loss.item(), bsz)\n",
    "        acc1 = accuracy(output, labels, bsz)\n",
    "        acc.update(acc1, bsz)\n",
    "\n",
    "        # SGD\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        # Update acc dict\n",
    "        update_dict(acc_groups, labels, groups, output)\n",
    "        \n",
    "        if opt.watch_batch_results:\n",
    "            if (idx + 1) % opt.print_freq == 0:\n",
    "                print(f'{print_label}: [{0}][{1}/{2}]\\t'\n",
    "                    'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                    'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                    'loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n",
    "                    'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                    epoch, idx + 1, len(train_loader), batch_time=batch_time,\n",
    "                    data_time=data_time, loss=losses, acc=acc))\n",
    "                sys.stdout.flush()\n",
    "            \n",
    "    group_acc = get_results(acc_groups, get_yp_func) # NOTE declared in [def main]\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print[1:]}\n",
    "    group_acc = {key: np.round(value, 4) for key, value in group_acc.items()}\n",
    "    print(f\"{print_label}:\", str(group_acc))\n",
    "    \n",
    "    return losses.avg, acc.avg, group_acc\n",
    "\n",
    "def train_one_epoch_cl(opt, train_loader, classifier, contrastive_loss, optimizer, epoch, print_label='Train'):\n",
    "    \"\"\"\n",
    "    Train contrastive epoch\n",
    "    \"\"\"\n",
    "    classifier.train()\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    # acc = AverageMeter()\n",
    "    # acc_groups = {g_idx : AverageMeter() for g_idx in range(train_loader.dataset.n_groups)}\n",
    "\n",
    "    # contrastive_weight = args.contrastive_weight\n",
    "    loss_compute_size = int(opt.num_anchor +\n",
    "                            opt.num_negative +\n",
    "                            opt.num_positive)\n",
    "    \n",
    "    end = time.time()\n",
    "    for idx, batch_data in enumerate(train_loader):\n",
    "        # Setup main contrastive batch\n",
    "        ## 순서대로 임베딩, \n",
    "        all_batch_inputs, all_batch_labels, _ = batch_data\n",
    "        \n",
    "        all_batch_inputs = all_batch_inputs.cuda(non_blocking=True) \n",
    "        # 각각 1개의 Anchor, N개의 Positive , M개의 Negative\n",
    "        # 총 opt.batch_factor 개의 Triplet. \n",
    "        batch_inputs = torch.split(all_batch_inputs,\n",
    "                                  loss_compute_size)\n",
    "        \n",
    "        # 기본적인 CA에선 사용 x\n",
    "        # all_batch_labels, all_batch_group, all_batch_spurious, all_batch_zs_pred = all_batch_labels.values()\n",
    "\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # warm-up learning rate\n",
    "        warmup_learning_rate(opt, epoch, idx, len(train_loader), optimizer)\n",
    "        \n",
    "        neg_start_ix = opt.num_anchor + opt.num_positive\n",
    "        neg_end_ix = neg_start_ix + opt.num_negative\n",
    "        \n",
    "        for ix, batch_input in enumerate(batch_inputs):\n",
    "            inputs_a = batch_input[:opt.num_anchor]\n",
    "            inputs_p = batch_input[opt.num_anchor:neg_start_ix]\n",
    "            inputs_n = batch_input[neg_start_ix:neg_end_ix]\n",
    "\n",
    "            # Just do contrastive loss against first anchor for now\n",
    "            inputs_a_ = [inputs_a[0]] # [1, 1024]\n",
    "\n",
    "            # in Contrastive Adapter, iterated over only \"single\" anchor\n",
    "            for anchor_ix, input_a in enumerate(inputs_a_):\n",
    "                contrastive_batch = torch.vstack((input_a.unsqueeze(0),\n",
    "                                                  inputs_p, inputs_n))\n",
    "                # compute loss\n",
    "                loss = contrastive_loss(classifier, contrastive_batch)\n",
    "                contrastive_batch = contrastive_batch.detach().cpu()\n",
    "                \n",
    "            # update metric\n",
    "            losses.update(loss.item(), 1)\n",
    "            # acc1 = accuracy(output, labels, 1)\n",
    "            # acc.update(acc1, 1)\n",
    "\n",
    "            # SGD\n",
    "            \n",
    "            for n, p in classifier.named_parameters():\n",
    "                if 'bias' not in n:\n",
    "                    print(n, p.shape)\n",
    "                    if len(p.shape)>1:\n",
    "                        print(f\"Before({n})\", p[8, :3])\n",
    "                    else:\n",
    "                        print(f\"Before({n})\", p[8])            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            for n, p in classifier.named_parameters():\n",
    "                if 'bias' not in n:\n",
    "                    if len(p.shape)>1:\n",
    "                        print(f\"After({n})\", p[8, :3])\n",
    "                    else:\n",
    "                        print(f\"After({n})\", p[8])\n",
    "            \n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            # Update acc dict\n",
    "            # update_dict(acc_groups, labels, groups, output)\n",
    "\n",
    "            print(f'{print_label}: [{0}][{1}/{2}]\\t'\n",
    "                        'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                        'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                        'loss {loss.val:.3f} ({loss.avg:.3f})\\t'.format(\n",
    "                        epoch, idx + 1, len(train_loader), batch_time=batch_time,\n",
    "                        data_time=data_time, loss=losses))\n",
    "            sys.stdout.flush()\n",
    "            # if opt.watch_batch_results:\n",
    "            #     if (idx + 1) % (opt.print_freq//3) == 0:\n",
    "            #         print(f'{print_label}: [{0}][{1}/{2}]\\t'\n",
    "            #             'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "            #             'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "            #             'loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n",
    "            #             'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "            #             epoch, idx + 1, len(train_loader), batch_time=batch_time,\n",
    "            #             data_time=data_time, loss=losses, acc=None))\n",
    "            #         sys.stdout.flush()\n",
    "\n",
    "    # group_acc = get_results(acc_groups, get_yp_func) # NOTE declared in [def main]\n",
    "    # group_acc = {key: group_acc[key] for key in new_order_for_print[1:]}\n",
    "    # group_acc = {key: np.round(value, 4) for key, value in group_acc.items()}\n",
    "    print(f\"Loss in {print_label}:\", str(losses.avg))\n",
    "    \n",
    "\n",
    "\n",
    "    return losses.avg # , acc.avg, group_acc\n",
    "\n",
    "\n",
    "def validate(opt, val_loader, classifier, criterion, get_yp_func, train_group_ratio, target, print_label='Test'):\n",
    "    \"\"\"validation\"\"\"\n",
    "    \n",
    "    classifier.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(val_loader.dataset.n_groups)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            embeddings, all_labels, img_filenames = data # all_labels.keys() : ['class', 'group', 'spurious', 'ebd_pred'(CLIP-zeroshot)] \n",
    "            labels = all_labels[target] # target : one of [class, spurious, group]\n",
    "            groups = all_labels['group'] # For evaluating group accuracy (and further developing group-information-aware approaches)\n",
    "            \n",
    "            embeddings = embeddings.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "            bsz = labels.shape[0]\n",
    "\n",
    "            # forward\n",
    "            output = classifier(embeddings)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # update metric\n",
    "            losses.update(loss.item(), bsz)\n",
    "            acc1 = accuracy(output, labels, bsz)\n",
    "            acc.update(acc1, bsz)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            # Update acc dict\n",
    "            update_dict(acc_groups, labels, groups, output)\n",
    "        \n",
    "            if opt.watch_batch_results:\n",
    "                if (idx+1) % opt.print_freq == 0:\n",
    "                    print(f'{print_label}: [{0}/{1}]\\t'\n",
    "                        'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                        'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                        'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                        idx, len(val_loader), batch_time=batch_time,\n",
    "                        loss=losses, acc=acc))\n",
    "                    \n",
    "    group_acc = get_results(acc_groups, get_yp_func)\n",
    "\n",
    "    # NOTE Add Weighted mean acc.\n",
    "    groups = range(val_loader.dataset.n_groups) # 0, 1, 2, 3\n",
    "    group_acc_indiv =  [group_acc[f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\"] for g in groups]\n",
    "    weighted_mean_acc = (np.array(group_acc_indiv) * np.array(train_group_ratio)).sum() # Weighted Sum \\\n",
    "    \n",
    "    group_acc[\"weighted_mean_acc\"] = weighted_mean_acc\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print}\n",
    "    group_acc = {key: np.round(value, 4) for key, value in group_acc.items()}\n",
    "    print(f\"{print_label}:\", str(group_acc))\n",
    "\n",
    "    return losses.avg, acc.avg, group_acc    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def validate_zs(opt, val_loader, classifier, criterion, get_yp_func, train_group_ratio, target, print_label='Zero-shot Prediction (Test) (Class)'):\n",
    "    \"\"\"(Feature quality) validation using zeroshot-prediction\"\"\"\n",
    "\n",
    "    classifier.eval()\n",
    "\n",
    "\n",
    "    if opt.tl_method in [\"linear_probing\"]:\n",
    "        temperature = opt.zs_temperature\n",
    "        \n",
    "        if target==\"class\":\n",
    "            text_embeddings = get_text_embedding(opt.text_embedding_dir)\n",
    "        elif target=='spurious':\n",
    "            text_embeddings = get_text_embedding(opt.text_spurious_embedding_dir)\n",
    "        \n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(val_loader.dataset.n_groups)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            image_embeddings, all_labels, img_filenames = data # all_labels.keys() : ['class', 'group', 'spurious', 'ebd_pred'(CLIP-zeroshot)] \n",
    "            labels = all_labels[target] # target : one of [class, spurious, group]\n",
    "            groups = all_labels['group'] # For evaluating group accuracy (and further developing group-information-aware approaches)\n",
    "            \n",
    "            image_embeddings = image_embeddings.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "            bsz = labels.shape[0]\n",
    "            \n",
    "            if opt.tl_method in ['linear_probing']: # same to CLIP Embedding\n",
    "                image_embeddings = image_embeddings / image_embeddings.norm(dim=-1, keepdim=True) # Normalized (B, 1024)\n",
    "                output = image_embeddings @ text_embeddings / temperature # (B, 1024) X (B, 2, 1024) = # (B, 2)\n",
    "                \n",
    "            elif opt.tl_method in ['adapter', 'contrastive_adapter']: # Adpater, Contrastive Adapter : Embedding -> (1) (Adapted) Embedding -> (2) ZeroShot prediction as logit    (CustomCLIP.forward : (1)+(2))\n",
    "                # forward\n",
    "                if target=='class':\n",
    "                    output = classifier(image_embeddings)\n",
    "                elif target=='spurious':\n",
    "                    output = classifier.forward_spurious(image_embeddings)\n",
    "            \n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # update metric\n",
    "            losses.update(loss.item(), bsz)\n",
    "            acc1 = accuracy(output, labels, bsz)\n",
    "            acc.update(acc1, bsz)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            # Update acc dict\n",
    "            update_dict(acc_groups, labels, groups, output)\n",
    "        \n",
    "            if opt.watch_batch_results:\n",
    "                if (idx+1) % opt.print_freq == 0:\n",
    "                    print(f'{print_label}: [{0}/{1}]\\t'\n",
    "                        'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                        'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                        'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                        idx, len(val_loader), batch_time=batch_time,\n",
    "                        loss=losses, acc=acc))\n",
    "                    \n",
    "    group_acc = get_results(acc_groups, get_yp_func)\n",
    "\n",
    "    # NOTE Add Weighted mean acc.\n",
    "    groups = range(val_loader.dataset.n_groups) # 0, 1, 2, 3\n",
    "    group_acc_indiv =  [group_acc[f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\"] for g in groups]\n",
    "    weighted_mean_acc = (np.array(group_acc_indiv) * np.array(train_group_ratio)).sum() # Weighted Sum \\\n",
    "    \n",
    "    group_acc[\"weighted_mean_acc\"] = weighted_mean_acc\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print}\n",
    "    group_acc = {key: np.round(value, 4) for key, value in group_acc.items()}\n",
    "    print(f\"{print_label}:\", str(group_acc))\n",
    "    \n",
    "    return losses.avg, acc.avg, group_acc    \n",
    "\n",
    "def train_all_epochs(opt):\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    best_model = None\n",
    "    # opt = parse_option()\n",
    "    \n",
    "    \n",
    "    print(f\"> Start Transfer Learning using [{opt.tl_method}]\")\n",
    "    print('========================================================================')\n",
    "    if opt.dataset == 'waterbirds':\n",
    "        # build dataset example.\n",
    "        print(f\"Load image embedding of Waterbirds: {opt.image_embedding_dir}\")\n",
    "        trainset = WaterbirdsEmbeddings(opt.data_dir, 'train', opt.image_embedding_dir, None)\n",
    "        print(f\"ㄴ Corresponding text embedding of Waterbirds: {opt.text_embedding_dir}\")\n",
    "        # build data loader\n",
    "        print(\"Load Data Loader (train, validation, test)\")\n",
    "        train_loader, val_loader, test_loader = load_waterbirds_embeddings(opt.data_dir, opt.image_embedding_dir, opt.batch_size, opt.batch_size)\n",
    "        \n",
    "        # print training target\n",
    "        if opt.train_target == \"class\":\n",
    "            print(f\"Training target : {opt.train_target} (Land bird(0) / Water bird(1))\")\n",
    "        elif opt.train_target == \"spurious\":\n",
    "            print(f\"Training target : {opt.train_target} (Land background(0) / Water background(1))\")\n",
    "        \n",
    "    elif opt.dataset == 'celeba':\n",
    "        # build dataset example.\n",
    "        print(f\"Load embedding of CelebA: {opt.image_embedding_dir}\")\n",
    "        trainset = CelebaEmbeddings(opt.data_dir, 'train', opt.image_embedding_dir, None)\n",
    "        print(f\"ㄴ Corresponding text embedding of Waterbirds: {opt.text_embedding_dir}\")\n",
    "        # build data loader\n",
    "        print(\"Load Data Loader (train, validation, test)\")\n",
    "        train_loader, val_loader, test_loader = load_celeba_embeddings(opt.data_dir, opt.image_embedding_dir, opt.batch_size, opt.batch_size)\n",
    "        \n",
    "        # print training target\n",
    "        if opt.train_target == \"class\":\n",
    "            print(f\"Training target : {opt.train_target} (non-blond hair(0) / blond hair(1))\")\n",
    "        elif opt.train_target == \"spurious\":\n",
    "            print(f\"Training target : {opt.train_target} (female(0) / male(1))\")\n",
    "\n",
    "    # group information\n",
    "    get_yp_func = partial(get_y_p, n_places=trainset.n_places)\n",
    "    train_group_ratio = trainset.group_ratio\n",
    "    \n",
    "    # build model and criterion\n",
    "    classifier, criterion = set_model(opt) # model, \n",
    "\n",
    "    # build optimizer\n",
    "    print(\"Set Optimizer: SGD (default)\")\n",
    "    print('========================================================================')\n",
    "    optimizer = set_optimizer(opt, classifier)\n",
    "    \n",
    "    # training routine\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    train_group_accs = []\n",
    "    \n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    val_group_accs = []\n",
    "    \n",
    "    test_losses = [] # NOTE: Don't peek ! \n",
    "    test_accs = [] # NOTE: Don't peek ! \n",
    "    test_group_accs = [] # NOTE: Don't peek ! \n",
    "    \n",
    "    # entire training\n",
    "    for epoch in range(1, opt.epochs + 1):\n",
    "        adjust_learning_rate(opt, optimizer, epoch)\n",
    "        print(f'--- Epoch {epoch} ---')\n",
    "        \n",
    "        # train one epoch\n",
    "        loss, acc, group_acc = train_one_epoch(opt, train_loader, classifier, criterion,\n",
    "                          optimizer, epoch, get_yp_func, target=opt.train_target, print_label=f'Train({opt.train_target})')\n",
    "        \n",
    "        train_losses.append(loss); train_accs.append(acc); train_group_accs.append(group_acc)\n",
    "        \n",
    "        # eval for one epoch\n",
    "        val_loss, val_acc, val_group_acc = validate(opt, val_loader, classifier, criterion, get_yp_func, train_group_ratio, target=opt.train_target, print_label=f'Val({opt.train_target})')\n",
    "        val_losses.append(val_loss); val_accs.append(val_acc); val_group_accs.append(val_group_acc)\n",
    "        \n",
    "        # update best epoch by worst_group accuracy (default)\n",
    "        if val_group_acc['worst_acc'] > best_acc:\n",
    "            best_acc = val_group_acc['worst_acc']\n",
    "            best_epoch = epoch\n",
    "            best_model = copy.deepcopy(classifier)\n",
    "        \n",
    "        # test for one epoch\n",
    "        test_loss, test_acc, test_group_acc = validate(opt, test_loader, classifier, criterion, get_yp_func, train_group_ratio, target='class', print_label=f'Test({opt.train_target})')\n",
    "        \n",
    "        test_losses.append(test_loss); test_accs.append(test_acc); test_group_accs.append(test_group_acc)\n",
    "        \n",
    "\n",
    "    print('========================================================================')\n",
    "    print(\"> end of training. \\n\")\n",
    "    print('best epoch : {}'.format(best_epoch))\n",
    "    \n",
    "    best_train_group_acc = train_group_accs[best_epoch-1]\n",
    "    best_val_group_acc = val_group_accs[best_epoch-1]\n",
    "    best_test_group_acc = test_group_accs[best_epoch-1]\n",
    "    \n",
    "    print(f'best training accuracy on [{opt.train_target}]: {best_train_group_acc}')\n",
    "    print(f'best validation accuracy on [{opt.train_target}]: {best_val_group_acc}')\n",
    "    print(f'best test accuracy on [{opt.train_target}]: {best_test_group_acc}')\n",
    "    \n",
    "    # Evaluate Feature Quality using (Embedding-based) Zero-shot Prediction\n",
    "    print('========================================================================')\n",
    "    print(\"> start evaluating feature quality of best model. (using zero-shot prediction)\\n\")\n",
    "    \n",
    "    \n",
    "    # Zero-shot [class] prediction\n",
    "    zs_loss, zs_acc, zs_group_acc = validate_zs(opt, test_loader, best_model, criterion, get_yp_func, train_group_ratio, target=\"class\", print_label='zero-shot prediction (test) (class)')    \n",
    "    \n",
    "    if opt.tl_method in [\"linear_probing\"]:\n",
    "        print(f\" ㄴ Note that it should be same to [CLIP Zero-shot Baselines, of which worst acc is about 39%], in {opt.tl_method}\")\n",
    "    elif opt.tl_method in [\"adapter\", \"contrastive_adapt\"]: \n",
    "        print(f\" ㄴ Note that it should be same to [best test accuracy on [{opt.train_target}]], above, in {opt.tl_method}\")\n",
    "    \n",
    "    # Zero-shot [spurious] prediction\n",
    "    zs_loss_spurious, zs_acc_spurious, zs_group_acc_spurious = validate_zs(opt, test_loader, best_model, criterion, get_yp_func, train_group_ratio, target=\"spurious\", print_label='zero-shot prediction (test) (spurious)')    \n",
    "    print(f\" ㄴ Note that it is related to [richness of non-target (spurious) information] (-> 'mean_acc' is important)\")\n",
    "    \n",
    "    print('========================================================================')\n",
    "    # Recommendation : False when multiple training\n",
    "    if opt.save_results:\n",
    "        print('> Save results\\n')\n",
    "        all_results = {}\n",
    "        \n",
    "        for epoch in range(1, opt.epochs + 1):\n",
    "            all_results[f\"Epoch {epoch}\"] = {\"Train\": train_group_accs[epoch-1], \"Val\": test_group_accs[epoch-1], \"Test\": test_group_accs[epoch-1]}\n",
    "        \n",
    "        final_results = {\"Final Results (best epoch)\":  {f\"Epoch {best_epoch}\": {\"Train\": best_train_group_acc, \"Val\": best_val_group_acc, \"Test\": best_test_group_acc}}, \n",
    "                         \"Feature Quality (using zs)\":  {\"class\":  zs_group_acc, \"spurious\": zs_group_acc_spurious}, \n",
    "                         \"All Results (all epoch)\": all_results}\n",
    "        \n",
    "        # make result folder \n",
    "        final_result_folder = os.path.dirname(opt.image_embedding_dir).replace('data', 'results')\n",
    "        if not os.path.exists(final_result_folder):\n",
    "            os.makedirs(final_result_folder)\n",
    "            \n",
    "        image_ebd_file_name = os.path.basename(opt.image_embedding_dir).split(\".\")[0]\n",
    "        text_ebd_file_name = os.path.basename(opt.text_embedding_dir).split(\".\")[0]\n",
    "        \n",
    "        # result name\n",
    "        final_result_file_name = f\"im_{image_ebd_file_name}_t_{text_ebd_file_name}_tl_{opt.tl_method}_t_{opt.train_target}_lr_{opt.learning_rate}_bs_{opt.batch_size}\"\n",
    "        \n",
    "        # NOTE This file name can be modified when we add baselines\n",
    "        \"\"\"\n",
    "        E.g., if we use [flexable_adapter] and corresponding h.p. [flexable_weight], then, \n",
    "        if opt.tl_method == \"flexable_adpater\":\n",
    "            final_result_file_name += f\"_{opt.flexable_weight}\"\n",
    "        if opt.cosine:\n",
    "            opt.model_name = '{}_cosine'.format(opt.model_name)\n",
    "        if opt.warm:\n",
    "            opt.model_name = '{}_warm'.format(opt.model_name)\n",
    "        \"\"\"\n",
    "\n",
    "        # result path\n",
    "        final_result_file_path = os.path.join(final_result_folder, final_result_file_name + \".json\")\n",
    "        final_model_path = os.path.join(final_result_folder, final_result_file_name + \".pth\")\n",
    "        \n",
    "        print('final result path: ', final_result_file_path)\n",
    "        print('final model path: ', final_model_path)\n",
    "        \n",
    "        # save results, as json.\n",
    "        with open(final_result_file_path, \"w\") as f:\n",
    "            json.dump(final_results, f, indent=4)\n",
    "        \n",
    "        # save final model, as pth \n",
    "        torch.save(best_model.state_dict(), final_model_path)    \n",
    "            \n",
    "    \n",
    "    print('========================================================================')\n",
    "    print(\"> end\")\n",
    "    \n",
    "    return (best_train_group_acc, best_val_group_acc, best_test_group_acc), (train_group_accs, val_group_accs, test_group_accs) # (best_results, all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "parser.add_argument('--print_freq', type=int, default=20,\n",
    "                    help='print frequency')\n",
    "parser.add_argument('--save_freq', type=int, default=50,\n",
    "                    help='save frequency')\n",
    "parser.add_argument('--batch_size', type=int, default=128,\n",
    "                    help='batch_size')\n",
    "parser.add_argument('--num_workers', type=int, default=16,\n",
    "                    help='num of workers to use')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='number of training epochs')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--learning_rate', type=float, default=1e-3,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--lr_decay_epochs', type=str, default='60,75,90',\n",
    "                    help='where to decay lr, can be a list')\n",
    "parser.add_argument('--lr_decay_rate', type=float, default=1 ,\n",
    "                    help='decay rate for learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-5,\n",
    "                    help='weight decay')\n",
    "parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                    help='momentum')\n",
    "\n",
    "# model dataset\n",
    "parser.add_argument('--model', type=str, default='resnet50')\n",
    "parser.add_argument('--dataset', type=str, default='waterbirds',\n",
    "                    choices=['celeba', 'waterbirds'], help='dataset')\n",
    "\n",
    "# other setting\n",
    "parser.add_argument('--cosine', action='store_true',\n",
    "                    help='using cosine annealing')\n",
    "parser.add_argument('--warm', action='store_true',\n",
    "                    help='warm-up for large batch training')\n",
    "\n",
    "parser.add_argument('--image_embedding_dir', type=str, \n",
    "                    help='extracted image embedding')\n",
    "parser.add_argument('--text_embedding_dir', type=str, \n",
    "                    help='extracted text embedding')\n",
    "parser.add_argument('--train_target', type=str, default=\"class\", choices=[\"class\", \"spurious\", \"group\"]) # Label for training.\n",
    "parser.add_argument('--data_dir', type=str,\n",
    "                    help='folder, in which [metadata.csv] exists')\n",
    "parser.add_argument('--tl_method', type=str, default=\"linear_probing\", choices=[\"linear_probing\", \"adapter\", \"contrastive_adapter\"]\n",
    "                        ,help='transfer learning method')\n",
    "parser.add_argument('--adapter_feat_dim', type=int, default= 128, help='reduced dimension in adapter')\n",
    "# parser.add_argument('--watch_batch_results', type=bool, default=False, help='Print results in each bach by [opt.print_freq]. Recommdned: True when single-run of CelebA(Large dataset), False otherwises')\n",
    "\n",
    "parser.add_argument('--zs_temperature', type=float, default= 0.01, help='Temperature in zero-shot prediction')\n",
    "# parser.add_argument('--save_results', type=bool, default=True, help='Save the results of transfer learning (and final feature quality) in the folder where ')\n",
    "opt = parser.parse_args(args=[])   \n",
    "\n",
    "iterations = opt.lr_decay_epochs.split(',')\n",
    "opt.lr_decay_epochs = list([])\n",
    "for it in iterations:\n",
    "    opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "opt.model_name = '{}_{}_lr_{}_decay_{}_bsz_{}'.\\\n",
    "    format(opt.dataset, opt.model, opt.learning_rate, opt.weight_decay,\n",
    "            opt.batch_size)\n",
    "\n",
    "if opt.cosine:\n",
    "    opt.model_name = '{}_cosine'.format(opt.model_name)\n",
    "\n",
    "# warm-up for large-batch training,\n",
    "if opt.warm:\n",
    "    opt.model_name = '{}_warm'.format(opt.model_name)\n",
    "    opt.warmup_from = 0.01\n",
    "    opt.warm_epochs = 10\n",
    "    if opt.cosine:\n",
    "        eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "        opt.warmup_to = eta_min + (opt.learning_rate - eta_min) * (\n",
    "                1 + math.cos(math.pi * opt.warm_epochs / opt.epochs)) / 2\n",
    "    else:\n",
    "        opt.warmup_to = opt.learning_rate\n",
    "        \n",
    "if opt.dataset == 'celeba':\n",
    "    opt.n_cls = 2\n",
    "elif opt.dataset == 'waterbirds':\n",
    "    opt.n_cls = 2\n",
    "else:\n",
    "    raise ValueError('dataset not supported: {}'.format(opt.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.watch_batch_results = True\n",
    "opt.save_results = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.epochs = 20\n",
    "opt.learning_rate = 1e-3\n",
    "opt.batch_size = 128\n",
    "opt.batch_factor = 32 # 튜닝 필요\n",
    "opt.num_anchor = 1\n",
    "opt.num_positive = 2048\n",
    "opt.num_negative = 2048\n",
    "\n",
    "opt.anc_loss_temp = 0.5\n",
    "opt.pos_loss_temp = 0.5\n",
    "opt.neg_loss_temp = 0.5\n",
    "\n",
    "opt.dataset = 'waterbirds'\n",
    "\n",
    "opt.tl_method = \"contrastive_adapter\"\n",
    "opt.train_target = \"class\"\n",
    "\n",
    "non_target = \"spurious\"\n",
    "\n",
    "opt.text_embedding_dir = f\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/{opt.dataset}/clip_{opt.train_target}.json\"\n",
    "opt.text_spurious_embedding_dir = f\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/{opt.dataset}/clip_{non_target}.json\"\n",
    "opt.image_embedding_dir = f\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/RN50/clip.json\"\n",
    "opt.data_dir=\"/home/jinsu/workstation/project/debiasing-multi-modal/data/waterbirds/waterbird_complete95_forest2water2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = train_all_epochs(opt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_anchors(anchor_class, anchor_dict, num_anchor):\n",
    "    p = None\n",
    "\n",
    "    num_samples = num_anchor\n",
    "    sample_indices = anchor_dict['ix_by_class'][anchor_class]\n",
    "    replace = True if num_samples > len(sample_indices) else False\n",
    "    sample_indices = np.random.choice(sample_indices,\n",
    "                                      size=num_samples,\n",
    "                                      replace=replace,\n",
    "                                      p=p)\n",
    "    return sample_indices\n",
    "\n",
    "\n",
    "def sample_positives(anchor_class, positives_by_class, num_positive):\n",
    "    positive_dict = positives_by_class[anchor_class]\n",
    "    p = None\n",
    "    num_samples = num_positive\n",
    "    replace = True if num_samples > len(positive_dict['ix']) else False\n",
    "\n",
    "    sample_indices = np.random.choice(np.arange(len(positive_dict['ix'])),\n",
    "                                      size=num_samples,\n",
    "                                      replace=replace,\n",
    "                                      p=p)\n",
    "    sample_slice_sources = positive_dict['source'][sample_indices]\n",
    "    sample_indices = positive_dict['ix'][sample_indices]\n",
    "    return sample_indices, sample_slice_sources\n",
    "\n",
    "\n",
    "def sample_negatives(negative_dict, num_negative):\n",
    "    p = None\n",
    "\n",
    "    num_samples = num_negative\n",
    "    replace = True if num_samples > len(negative_dict['ix']) else False\n",
    "    sample_indices = np.random.choice(negative_dict['ix'],\n",
    "                                      size=num_samples,\n",
    "                                      replace=replace,\n",
    "                                      p=p)\n",
    "    return sample_indices\n",
    "\n",
    "\n",
    "# Adjust number of negatives or positives if > sliced neg / pos\n",
    "def adjust_num_pos_neg_(positives_by_class, slice_negatives,\n",
    "                        args):\n",
    "    \n",
    "    print(f'given number of positives: {args.num_anchor}')\n",
    "    print(f'given number of positives: {args.num_positive}')\n",
    "    print(f'given number of negatives: {args.num_negative}')\n",
    "    num_pos = np.min([len(positives_by_class[c]['target'])\n",
    "                      for c in range(args.n_cls)])\n",
    "    num_neg = np.min([len(negative_dict['target'])\n",
    "                      for negative_dict in slice_negatives])\n",
    "    num_pos = np.min((args.num_positive, num_pos))\n",
    "    num_neg = np.min((args.num_negative, num_neg))\n",
    "\n",
    "    # Tentative\n",
    "    num_anc = np.min((args.num_anchor, np.min((num_pos, num_neg))))\n",
    "\n",
    "    # Adjust experiment name to reflect\n",
    "    # args.experiment_name = args.experiment_name.replace(\n",
    "    #     f'-na={args.num_anchor}-np={args.num_positive}-nn={args.num_negative}',\n",
    "    #     f'-na={num_anc}-np={num_pos}-nn={num_neg}')\n",
    "    # Adjust arguments\n",
    "    args.num_positive = num_pos\n",
    "    args.num_negative = num_neg\n",
    "    args.num_anchor = num_anc\n",
    "    print(f'Adjusted number of anchors:   {args.num_anchor}')\n",
    "    print(f'Adjusted number of positives: {args.num_positive}')\n",
    "    print(f'Adjusted number of negatives: {args.num_negative}')\n",
    "    \n",
    "# Adjust number of anchors or hard negatives if > sliced anc / neg\n",
    "def adjust_num_anc_neg_(slice_anchors, slice_negatives,\n",
    "                        args):\n",
    "    num_anc = np.min([len(anchor_dict['target'])\n",
    "                      for anchor_dict in slice_anchors])\n",
    "    num_neg = np.min([len(negative_dict['target'])\n",
    "                      for negative_dict in slice_negatives])\n",
    "    num_anc = np.min((args.num_anchor, num_anc))\n",
    "    # num_neg Because now both anchors and negatives are from the nonspurious groups\n",
    "    num_neg = np.min((args.num_negative_easy, num_anc))\n",
    "\n",
    "    # Tentative\n",
    "    # num_anc = np.min((args.num_anchor, np.min((num_pos, num_neg))))\n",
    "\n",
    "    # Adjust experiment name to reflect\n",
    "    # args.experiment_name = args.experiment_name.replace(\n",
    "    #     f'-na={args.num_anchor}-np={args.num_positive}-nn={args.num_negative}-ne={args.num_negative_easy}',\n",
    "    #     f'-na={num_anc}-np={args.num_positive}-nn={args.num_negative}-ne={num_neg}')\n",
    "    # Adjust arguments\n",
    "    args.num_anchor = num_anc\n",
    "    args.num_negative_easy = num_neg\n",
    "    print(f'Adjusted number of anchors:   {args.num_anchor}')\n",
    "    print(f'Adjusted number of (hard) negatives: {args.num_negative_easy}')\n",
    "\n",
    "def compute_slice_indices(dataset):\n",
    "    \"\"\"\n",
    "    Get \"slices\" of data belonging to different subgroups from the pre-extracted embeddings\n",
    "    (cf. [data/embeddings_unnormalized/[waterbirds/celeba]/RN50/clip.json])\n",
    "\n",
    "    Args:\n",
    "    - dataset : Custom Dataset (cf. [[waterbirds/celeba]_embedding.py])\n",
    "    Returns:\n",
    "    - sliced_data_indices (int(np.array)[]): List of numpy arrays denoting indices of the dataloader.dataset\n",
    "                                             corresponding to different slices \n",
    "    \"\"\"\n",
    "    # First compute pseudolabels\n",
    "    \n",
    "    # pseudo_labels = torch.hstack(all_predicted) # [N, ]\n",
    "    # correct = torch.hstack(all_correct) # [N, \n",
    "    \n",
    "    embeddings_df = dataset.embeddings_df\n",
    "    train_indices = (embeddings_df.loc[\"split\"]==dataset.split_dict[trainset.split]).values\n",
    "    train_embeddings_df = embeddings_df.T[train_indices]\n",
    "    train_embeddings_df = train_embeddings_df.T\n",
    "    \n",
    "    pseudo_labels = train_embeddings_df.loc[\"y_pred\"].values # [0, 1, 1, 0, 1....]\n",
    "    labels =  train_embeddings_df.loc[\"y\"].values # [1, 1, 0, 0, 1, ....]\n",
    "    correct = (pseudo_labels == labels) # [False, True, False, True, True, ...]\n",
    "    \n",
    "    sliced_data_indices = []\n",
    "    all_correct = []\n",
    "    for label in np.unique(pseudo_labels): # 0으로 예측\n",
    "        group = np.where(pseudo_labels == label)[0] # [0, 3, ...] / [1, 2, 4, ...]\n",
    "        correct_by_group = correct[group] # [False, True, ...] / [True, False, True, ...]\n",
    "        \n",
    "        sliced_data_indices.append(group) # \n",
    "        all_correct.append(correct_by_group) \n",
    "    \n",
    "    \n",
    "    return sliced_data_indices, all_correct # [[0, 3,...], [1, 2, 4, ...]], [[False, True, ...], [True, False, True, ...]]\n",
    "\n",
    "\n",
    "def prepare_contrastive_points(dataset, sliced_data_indices,\n",
    "                               sliced_data_correct,\n",
    "                               ):\n",
    "    train_targets = dataset.y_array\n",
    "    train_spurious = dataset.confounder_array\n",
    "    sliced_data_indices_all = np.concatenate(sliced_data_indices)\n",
    "    sliced_data_correct_all = np.zeros(len(train_targets))\n",
    "    sliced_data_correct_all[sliced_data_indices_all] = np.concatenate(\n",
    "        sliced_data_correct)\n",
    "    \n",
    "    sliced_data_incorrect = []\n",
    "    for slice_ix, boolean_array in enumerate(sliced_data_correct):\n",
    "        sliced_data_incorrect.append(np.array([not bool for bool in boolean_array]))\n",
    "    sliced_data_incorrect = np.array(sliced_data_incorrect)\n",
    "    \n",
    "    all_anchors = {'slice_ix': np.zeros(len(train_targets)).astype(int), # 4765\n",
    "                   'in_slice_ix': np.zeros(len(train_targets)).astype(int)} # 4765\n",
    "\n",
    "    # Store all anchors and negatives\n",
    "    slice_anchors = [None] * len(sliced_data_indices)\n",
    "    slice_negatives = [None] * len(sliced_data_indices)\n",
    "    \n",
    "    # For positives, just specify by the ground-truth NOTE No.\n",
    "    # (These are the same as negatives in another slice, just organized by class) \n",
    "     ## another slice : 1 prediction. 0 class (즉, 그냥 틀린 친구들 in CnC)\n",
    "     \n",
    "     \n",
    "    # Cnc : Anchor -> correct \n",
    "      # Neg : Different class & Same Prediction\n",
    "      # Pos : Different prediction & Same class\n",
    "    # CA : Anchor -> incorrect\n",
    "    positives_by_class = {}\n",
    "\n",
    "    for slice_ix, data_indices in enumerate(sliced_data_indices): # slice_ix = 0 (즉, prediction=0일 때 기준 서술)\n",
    "        \n",
    "        target_class, target_counts = np.unique(train_targets[data_indices],\n",
    "                                                return_counts=True)\n",
    "        \n",
    "        for tc_ix, tc in enumerate(target_class):\n",
    "            print(f'>> Slice {slice_ix}, target: {tc}, counts: {target_counts[tc_ix]}')\n",
    "        \n",
    "        # Anchors are datapoints in the slice that the model got in-correct (False)\n",
    "        ix = np.where(sliced_data_incorrect[slice_ix])[0] # prediction 0, class 1\n",
    "        print(\n",
    "            f'Slice {slice_ix} % incorrect: {len(ix) / len(data_indices) * 100:<.4f} %')\n",
    "\n",
    "        slice_ix_anchors = {'ix': data_indices[ix],\n",
    "                            'target': train_targets[data_indices][ix], # Only 1\n",
    "                            'incorrect': sliced_data_incorrect[slice_ix][ix], # all True\n",
    "                            'source': np.ones(len(data_indices[ix])).astype(int) * slice_ix, # zero_prediction\n",
    "                            'spurious': train_spurious[data_indices][ix], # 0 or 1 (다만 1이 그 전체 양(5%)에 비해선 비교적 많을 것)\n",
    "                            'ix_by_class': {},} # 1: data_indices[ix] (Class 1)\n",
    "        # Zeroshot prediction 값([0/1])에 따른 data indices 들에 대한 정보들\n",
    "        \n",
    "        # anchor: prediction 0 -> class 1 (즉, zero-prediction에 대한 anchor는 모두 class 1) -> indices\n",
    "        for t in np.unique(train_targets[data_indices][ix]):\n",
    "            tix = np.where(train_targets[data_indices][ix] == t)[0]\n",
    "            slice_ix_anchors['ix_by_class'][t] = data_indices[ix][tix] \n",
    "            \n",
    "        # Negatives: prediction 0 -> class 0 (즉, Anchor와 Different Class) -> indices\n",
    "        ## 이 중에 가까운 샘플만 골라서 사용(Water birds에서는 거의 대부분 사용한다고 봐도 무방하다) \n",
    "        nix = np.setdiff1d(np.arange(len(data_indices)), ix) # prediction 0, class 0 (True)\n",
    "        # target_class, target_counts = np.unique(train_targets[data_indices][ix], # Anchor와 같은 Class\n",
    "        #                                         return_counts=True) # (1, 254) (Class 1, anchor 개수)\n",
    "        print(f'Slice {slice_ix} # negative (correct): {len(nix)}')\n",
    "        print(\n",
    "            f'Slice {slice_ix} % negative (correct): {len(nix) / len(data_indices) * 100 :<.4f} %')\n",
    "        \n",
    "        print(\n",
    "            f'Unique negative targets: {np.unique(train_targets[data_indices][nix], return_counts=True)}')\n",
    "\n",
    "        slice_ix_negatives = {'ix': list(data_indices[nix]),\n",
    "                                'target': list(train_targets[data_indices][nix]), # All 0\n",
    "                                'incorrect': list(sliced_data_incorrect[slice_ix][nix]),# All False\n",
    "                                'source': list(np.ones(len(data_indices[nix])).astype(int) * slice_ix), # All 0\n",
    "                                'spurious': list(train_spurious[data_indices][nix])} # 0이 많을 것(Major group) (True)\n",
    "\n",
    "        # Positives: \"Different prediction\" and \"Same Class(True)\"\n",
    "        ## 즉, 0 prediction & 0 class (다른 Slice의 Positive다)\n",
    "        # Positives, for other slices - for here just save by unique class that was also \"correct\"\n",
    "        ## 즉, \n",
    "        target_class, target_counts = np.unique(train_targets[data_indices][nix], # nix : correct\n",
    "                                                return_counts=True) # (0, 3588) (Class 0, # Correct sample )\n",
    "        correct_data_indices = data_indices[nix] # Pred 0 \n",
    "        \n",
    "        print(f\"Slice {slice_ix} # Positive: (for 'other' slice)\", len(correct_data_indices))\n",
    "        \n",
    "        # print(f'Slice {slice_ix} # positive (correct): {len(nix)}')\n",
    "        \n",
    "        for cix, c in enumerate(target_class): # only 0\n",
    "            pix = np.where(train_targets[correct_data_indices] == c)[0]            \n",
    "\n",
    "            pos_data_indices = list(correct_data_indices[pix])\n",
    "            pos_data_targets = list(\n",
    "                train_targets[correct_data_indices][pix])\n",
    "            pos_data_correct = list(\n",
    "                sliced_data_correct[slice_ix][nix][pix])\n",
    "            pos_data_source = list(\n",
    "                np.ones(len(data_indices[nix][pix])).astype(int) * slice_ix)\n",
    "            pos_data_spurious = list(\n",
    "                train_spurious[correct_data_indices][pix])\n",
    "            # print(\"pos_data_indices\", pos_data_indices[:5])\n",
    "            # print(\"pos_data_targets\", pos_data_targets[:5])\n",
    "            # print(\"pos_data_correct \", pos_data_correct[:5])\n",
    "            # print(\"pos_data_source \",pos_data_source[:5])\n",
    "            # print(\"pos_data_spurious\", pos_data_spurious[:5])\n",
    "            # print(\"pos_data_indices\", len(pos_data_indices))\n",
    "            # print(\"pos_data_targets\", len(pos_data_targets))\n",
    "            # print(\"pos_data_correct \", len(pos_data_correct))\n",
    "            # print(\"pos_data_source \",len(pos_data_source))\n",
    "            # print(\"pos_data_spurious\", len(pos_data_spurious))\n",
    "            if c in positives_by_class:\n",
    "                positives_by_class[c]['ix'].extend(pos_data_indices)\n",
    "                positives_by_class[c]['target'].extend(pos_data_targets)\n",
    "                positives_by_class[c]['correct'].extend(pos_data_correct)\n",
    "                positives_by_class[c]['source'].extend(pos_data_source)\n",
    "                positives_by_class[c]['spurious'].extend(pos_data_spurious)\n",
    "            else:\n",
    "                positives_by_class[c] = {'ix': pos_data_indices,\n",
    "                                            'target': pos_data_targets,\n",
    "                                            'correct': pos_data_correct,\n",
    "                                            'source': pos_data_source,\n",
    "                                            'spurious': pos_data_spurious}\n",
    "            \n",
    "        # Save\n",
    "        slice_anchors[slice_ix] = slice_ix_anchors\n",
    "        slice_negatives[slice_ix] = slice_ix_negatives\n",
    "\n",
    "    # Fill in positives if no slices had the class as spurious\n",
    "    for slice_ix, data_indices in enumerate(sliced_data_indices):\n",
    "        target_class, target_counts = np.unique(train_targets[data_indices],\n",
    "                                                return_counts=True)\n",
    "\n",
    "        # Compare average correctness, still use the max_class variable\n",
    "        avg_correct = []\n",
    "        for c in target_class:\n",
    "            class_indices = np.where(train_targets[data_indices] == c)[0]\n",
    "            class_correct = sliced_data_correct[slice_ix][class_indices]\n",
    "            avg_correct.append(np.mean(class_correct))\n",
    "        max_class_ix = np.argmax(avg_correct)\n",
    "\n",
    "        for c in target_class:\n",
    "            if c not in positives_by_class:\n",
    "                print(\n",
    "                    f'> Loading correct datapoints as positives for class {c} from slice {slice_ix}')\n",
    "                ix = np.where(train_targets[data_indices] == c)[0]\n",
    "                positives_by_class[c] = {'ix': list(data_indices[ix]),\n",
    "                                         'target': list(train_targets[data_indices][ix]),\n",
    "                                         'correct': list(sliced_data_correct[slice_ix][ix]),\n",
    "                                         'source': list(np.ones(len(data_indices[ix])).astype(int) * slice_ix),\n",
    "                                         'spurious': list(train_spurious[data_indices][ix])}\n",
    "\n",
    "    # Convert casted lists back to ndarrays\n",
    "    for c, class_dict in positives_by_class.items():\n",
    "        for k, v in class_dict.items():\n",
    "            positives_by_class[c][k] = np.array(v)\n",
    "\n",
    "    for ix, slice_negative in enumerate(slice_negatives):\n",
    "        for k, v in slice_negative.items():\n",
    "            slice_negatives[ix][k] = np.array(v)\n",
    "\n",
    "\n",
    "    return slice_anchors, slice_negatives, positives_by_class, all_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_contrastive_data(train_loader, slice_anchors,\n",
    "                          slice_negatives, positives_by_class, args,\n",
    "                          persistent_workers=True): # Data processing 오류 핸들링.\n",
    "    # Get number of negatives per target class\n",
    "    args.num_negatives_by_target = [0] * args.n_cls\n",
    "\n",
    "    batch_samples = []\n",
    "    batch_samples_old = []\n",
    "\n",
    "    for slice_ix, anchor_dict in enumerate(slice_anchors):\n",
    "        batch_samples_per_slice = []  # First aggregate within\n",
    "        negative_dict = slice_negatives[slice_ix]\n",
    "        # For hard negative\n",
    "        args.num_negatives_by_target[slice_ix] = len(negative_dict['ix'])\n",
    "\n",
    "        anchor_targets = anchor_dict['target']\n",
    "        anchor_indices = anchor_dict['ix']\n",
    "\n",
    "        # 254, 94 (Prediction 0에서의 False, Prediction 1에서의 False )\n",
    "        for aix, anchor_ix in enumerate(tqdm(anchor_indices, desc=f'Generating data from slice {slice_ix}')): \n",
    "            anchor_class = anchor_targets[aix]\n",
    "            # Sample additional positives\n",
    "            anchor_indices = sample_anchors(anchor_class,\n",
    "                                            anchor_dict,\n",
    "                                            args.num_anchor - 1)\n",
    "            anchor_indices = np.concatenate([[anchor_ix], anchor_indices]) # (1, )\n",
    "            \n",
    "            positive_outputs = sample_positives(anchor_class,\n",
    "                                                positives_by_class,\n",
    "                                                args.num_positive)\n",
    "            positive_indices, positive_slice_sources = positive_outputs # (n_positives, )\n",
    "            \n",
    "            # Keep as this, in case want to generate new neg per pos as before\n",
    "            samples = [anchor_indices, positive_indices]\n",
    "            negative_indices = sample_negatives(negative_dict,\n",
    "                                                args.num_negative) # (n_negatives, )\n",
    "            samples.append(negative_indices)\n",
    "    \n",
    "            batch_sample = np.concatenate(samples) # (# positive * # negative)\n",
    "            batch_samples_per_slice.append(batch_sample)\n",
    "            batch_samples_old.append(batch_sample)\n",
    "            \n",
    "        np.random.shuffle(batch_samples_per_slice) # (# anchor, # positive * # negative): (254, 1719) / (94. 1719)\n",
    "        batch_samples.append(batch_samples_per_slice)\n",
    "        print(\"batch_samples_per_slice.shape\", np.array(batch_samples_per_slice).shape) \n",
    "\n",
    "    # print(\"batch_samples.shape\", np.array(batch_samples[0]).shape) # (254, 1719)\n",
    "    # print(\"batch_samples.shape\", np.array(batch_samples[1]).shape) # (94, 1719)\n",
    "    batch_samples = list(zip(*batch_samples)) # (94, 2, 1719) (우선 Prediction 비율에 따라 Balanced로 구성.)\n",
    "    print(np.array(batch_samples).shape)\n",
    "    \n",
    "    batch_samples = np.array(batch_samples).reshape(-1, len(batch_sample)) # (188, 1719)\n",
    "    \n",
    "    contrastive_indices = np.concatenate(batch_samples)\n",
    "    contrastive_train_set = get_resampled_set(train_loader.dataset,\n",
    "                                              contrastive_indices,\n",
    "                                              copy_dataset=True)\n",
    "    \n",
    "    \n",
    "    contrastive_dataloader = DataLoader(contrastive_train_set,\n",
    "                                        batch_size=len(\n",
    "                                            batch_samples[0]) * int(args.batch_factor),\n",
    "                                        shuffle=False, num_workers=args.num_workers, persistent_workers = persistent_workers)\n",
    "    print(\"> batchsize of contrastive data loader :\", len(batch_samples[0]) * int(args.batch_factor)) # (32) * (1719)[1 + pos + neg]\n",
    "    print(\"> len of contrastive dataset :\", len(contrastive_train_set)) # (188*1719, )\n",
    "    return contrastive_dataloader\n",
    "\n",
    "def get_resampled_set(dataset, resampled_set_indices, copy_dataset=False):\n",
    "    \"\"\"\n",
    "    Obtain spurious dataset resampled_set\n",
    "    Args:\n",
    "    - dataset (torch.utils.data.Dataset): Spurious correlations dataset\n",
    "    - resampled_set_indices (int[]): List-like of indices \n",
    "    - deepcopy (bool): If true, copy the dataset\n",
    "    \"\"\"\n",
    "    resampled_set = copy.deepcopy(dataset) if copy_dataset else dataset\n",
    "    try:  # Some dataset classes may not have these attributes (WaterbirdsEmbeddingsDatasets 특화)\n",
    "        resampled_set.y_array = resampled_set.y_array[resampled_set_indices]\n",
    "        resampled_set.group_array = resampled_set.group_array[resampled_set_indices]\n",
    "        resampled_set.split_array = resampled_set.split_array[resampled_set_indices]\n",
    "        resampled_set.targets = resampled_set.targets[resampled_set_indices]\n",
    "        resampled_set.targets_group = resampled_set.targets_group[resampled_set_indices]\n",
    "        resampled_set.targets_spurious = resampled_set.targets_spurious[resampled_set_indices]\n",
    "        try:  # Depending on the dataset these are responsible for the X features\n",
    "            resampled_set.filename_array = resampled_set.filename_array[resampled_set_indices]\n",
    "        except:\n",
    "            resampled_set.x_array = resampled_set.x_array[resampled_set_indices]\n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "\n",
    "    # Main Embedding Information을 담고있는 Dataframe 조절 (6, 11760) -> (6, 323171...)\n",
    "    resampled_embeddings_df = resampled_set.embeddings_df.copy()\n",
    "    resampled_embeddings_df = resampled_embeddings_df.T\n",
    "    resampled_embeddings_df = resampled_embeddings_df.iloc[resampled_set_indices]\n",
    "    resampled_set.embeddings_df = resampled_embeddings_df.T.copy()\n",
    "    \n",
    "    # Indexing 방식 수정 (dataframe+key -> dataframe+iloc)\n",
    "    resampled_set.on_contrastive_batch = True\n",
    "\n",
    "    print('len(resampled_set.targets)', len(resampled_set.targets))\n",
    "    return resampled_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(SupervisedContrastiveLoss, self).__init__()\n",
    "        self.temperature = args.zs_temperature\n",
    "        self.n_positives = args.num_positive\n",
    "        self.n_negatives = args.num_negative\n",
    "        self.args = args\n",
    "    \n",
    "        self.sim = nn.CosineSimilarity(dim=1)\n",
    "        \n",
    "    def forward(self, model, contrastive_batch):\n",
    "        \n",
    "        # contrastive_batch [anc; pos; neg] : (1+N+M(=N), )\n",
    "        \n",
    "        # Compute negative similarities\n",
    "        neg_indices = [0] + list(range(len(contrastive_batch))[\n",
    "            -self.n_negatives:])\n",
    "        anchor_negatives = contrastive_batch[neg_indices]\n",
    "        \n",
    "        # M(=N)개의 exp(sim) score\n",
    "        exp_neg = self.compute_exp_sim(model, anchor_negatives,\n",
    "                                       return_sum=False)\n",
    "\n",
    "        sum_exp_neg = exp_neg.sum(0, keepdim=True)\n",
    "            \n",
    "        # Compute positive similarities\n",
    "        anchor_positives = contrastive_batch[:1 + self.n_positives]\n",
    "        exp_pos = self.compute_exp_sim(model, anchor_positives, \n",
    "                                       return_sum=False)\n",
    "        \n",
    "        \n",
    "        log_probs = (torch.log(exp_pos) - \n",
    "                        torch.log(sum_exp_neg + exp_pos.sum(0, keepdim=True)))\n",
    "        loss = -1 * log_probs\n",
    "        del exp_pos; del exp_neg; del log_probs\n",
    "        return loss.mean()\n",
    "    \n",
    "    def compute_exp_sim(self, model, features, return_sum=True):\n",
    "        \"\"\"\n",
    "        Compute sum(sim(anchor, pos)) or sum(sim(anchor, neg))\n",
    "        First index : anchor\n",
    "        \"\"\"\n",
    "        # in Contrastive Adapter, features:CLIP, outputs:Adapted-CLIP \n",
    "        \n",
    "        if self.args.tl_method ==\"contrastive_adapter\":\n",
    "            outputs = model.adapter(features) # model.forward : (normalized) logits까지. \n",
    "        \n",
    "        sim = self.sim(outputs[0].view(1, -1), outputs[1:]) # (N,) or (M,)\n",
    "        exp_sim = torch.exp(torch.div(sim, self.temperature))\n",
    "        # Should not detach from graph\n",
    "        features = features.to(torch.device('cpu'))\n",
    "        outputs = outputs.to(torch.device('cpu'))\n",
    "        if return_sum:\n",
    "            sum_exp_sim = exp_sim.sum(0, keepdim=True) # (1,)\n",
    "            exp_sim.detach_().cpu(); del exp_sim\n",
    "            return sum_exp_sim\n",
    "        return exp_sim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Start Transfer Learning using [contrastive_adapter]\n",
      "========================================================================\n",
      "Load image embedding of Waterbirds: /home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/RN50/clip.json\n",
      "/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/RN50/clip.json\n",
      "ㄴ Corresponding text embedding of Waterbirds: /home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/clip_class.json\n",
      "Load Data Loader (train, validation, test)\n",
      "/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/RN50/clip.json\n",
      "/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/RN50/clip.json\n",
      "/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/RN50/clip.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3651297/1385120296.py:145: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sliced_data_incorrect = np.array(sliced_data_incorrect)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target : class (Land bird(0) / Water bird(1))\n",
      "Off-the-shelf classifier : [Adapter + (temperatured) image-text jointly normalized prediction]\n",
      "> set and load Contrastive data-handler\n",
      "========================================================================\n",
      ">> Slice 0, target: 0, counts: 3588\n",
      ">> Slice 0, target: 1, counts: 254\n",
      "Slice 0 % incorrect: 6.6111 %\n",
      "Slice 0 # negative (correct): 3588\n",
      "Slice 0 % negative (correct): 93.3889 %\n",
      "Unique negative targets: (array([0]), array([3588]))\n",
      "Slice 0 # Positive: (for 'other' slice) 3588\n",
      ">> Slice 1, target: 0, counts: 94\n",
      ">> Slice 1, target: 1, counts: 859\n",
      "Slice 1 % incorrect: 9.8636 %\n",
      "Slice 1 # negative (correct): 859\n",
      "Slice 1 % negative (correct): 90.1364 %\n",
      "Unique negative targets: (array([1]), array([859]))\n",
      "Slice 1 # Positive: (for 'other' slice) 859\n",
      "given number of positives: 1\n",
      "given number of positives: 2048\n",
      "given number of negatives: 2048\n",
      "Adjusted number of anchors:   1\n",
      "Adjusted number of positives: 859\n",
      "Adjusted number of negatives: 859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data from slice 0: 100%|██████████| 254/254 [00:00<00:00, 8552.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_samples_per_slice.shape (254, 1719)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data from slice 1: 100%|██████████| 94/94 [00:00<00:00, 9034.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_samples_per_slice.shape (94, 1719)\n",
      "(94, 2, 1719)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(resampled_set.targets) 323172\n",
      "> batchsize of contrastive data loader : 55008\n",
      "> len of contrastive dataset : 323172\n",
      "========================================================================\n",
      "Set Optimizer: SGD (default)\n",
      "========================================================================\n",
      "--- Epoch 1 ---\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "best_model = None\n",
    "# opt = parse_option()\n",
    "\n",
    "\n",
    "print(f\"> Start Transfer Learning using [{opt.tl_method}]\")\n",
    "print('========================================================================')\n",
    "if opt.dataset == 'waterbirds':\n",
    "    # build dataset example.\n",
    "    print(f\"Load image embedding of Waterbirds: {opt.image_embedding_dir}\")\n",
    "    trainset = WaterbirdsEmbeddings(opt.data_dir, 'train', opt.image_embedding_dir, None)\n",
    "    print(f\"ㄴ Corresponding text embedding of Waterbirds: {opt.text_embedding_dir}\")\n",
    "    # build data loader\n",
    "    print(\"Load Data Loader (train, validation, test)\")\n",
    "    train_loader, val_loader, test_loader = load_waterbirds_embeddings(opt.data_dir, opt.image_embedding_dir, opt.batch_size, opt.batch_size)\n",
    "    \n",
    "    # print training target\n",
    "    if opt.train_target == \"class\":\n",
    "        print(f\"Training target : {opt.train_target} (Land bird(0) / Water bird(1))\")\n",
    "    elif opt.train_target == \"spurious\":\n",
    "        print(f\"Training target : {opt.train_target} (Land background(0) / Water background(1))\")\n",
    "    \n",
    "elif opt.dataset == 'celeba':\n",
    "    # build dataset example.\n",
    "    print(f\"Load embedding of CelebA: {opt.image_embedding_dir}\")\n",
    "    trainset = CelebaEmbeddings(opt.data_dir, 'train', opt.image_embedding_dir, None)\n",
    "    print(f\"ㄴ Corresponding text embedding of Waterbirds: {opt.text_embedding_dir}\")\n",
    "    # build data loader\n",
    "    print(\"Load Data Loader (train, validation, test)\")\n",
    "    train_loader, val_loader, test_loader = load_celeba_embeddings(opt.data_dir, opt.image_embedding_dir, opt.batch_size, opt.batch_size)\n",
    "    \n",
    "    # print training target\n",
    "    if opt.train_target == \"class\":\n",
    "        print(f\"Training target : {opt.train_target} (non-blond hair(0) / blond hair(1))\")\n",
    "    elif opt.train_target == \"spurious\":\n",
    "        print(f\"Training target : {opt.train_target} (female(0) / male(1))\")\n",
    "\n",
    "# group information\n",
    "get_yp_func = partial(get_y_p, n_places=trainset.n_places)\n",
    "train_group_ratio = trainset.group_ratio\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# build model and criterion\n",
    "classifier, ce_loss = set_model(opt) # model, \n",
    "\n",
    "\n",
    "# Main Ce code\n",
    "if opt.tl_method==\"contrastive_adapter\": \n",
    "    print(\"> set and load Contrastive data-handler\")\n",
    "    print('========================================================================')\n",
    "    sliced_data_indices, sliced_data_correct = compute_slice_indices(trainset)\n",
    "    contrastive_points = prepare_contrastive_points(trainset,sliced_data_indices,sliced_data_correct)\n",
    "    slice_anchors, slice_negatives, positives_by_class, all_targets = contrastive_points\n",
    "    \n",
    "    adjust_num_pos_neg_(positives_by_class, slice_negatives, opt)\n",
    "\n",
    "    contrastive_loss = SupervisedContrastiveLoss(opt)\n",
    "    \n",
    "    # Get contrastive batches for first epoch\n",
    "    contrastive_dataloader = load_contrastive_data(train_loader,\n",
    "                                                    slice_anchors,\n",
    "                                                    slice_negatives,\n",
    "                                                    positives_by_class,\n",
    "                                                    opt, True)\n",
    "    print('========================================================================')\n",
    "# build optimizer\n",
    "print(\"Set Optimizer: SGD (default)\")\n",
    "print('========================================================================')\n",
    "optimizer = set_optimizer(opt, classifier)\n",
    "\n",
    "\n",
    "# training routine\n",
    "train_losses = []\n",
    "train_losses_cl = []\n",
    "train_accs = []\n",
    "train_group_accs = []\n",
    "\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "val_group_accs = []\n",
    "\n",
    "test_losses = [] # NOTE: Don't peek ! \n",
    "test_accs = [] # NOTE: Don't peek ! \n",
    "test_group_accs = [] # NOTE: Don't peek ! \n",
    "\n",
    "# entire training\n",
    "for epoch in range(1, opt.epochs + 1):\n",
    "    adjust_learning_rate(opt, optimizer, epoch)\n",
    "    print(f'--- Epoch {epoch} ---')\n",
    "    \n",
    "    # train one epoch\n",
    "    loss_cl = train_one_epoch_cl(opt, contrastive_dataloader, classifier, contrastive_loss,\n",
    "                        optimizer, epoch, print_label=f'Train(Contrastive Learning)')\n",
    "    train_losses_cl.append(loss_cl)\n",
    "    \n",
    "    loss, acc, group_acc = train_one_epoch(opt, train_loader, classifier, ce_loss,\n",
    "                        optimizer, epoch, get_yp_func, target=opt.train_target, print_label=f'Train({opt.train_target})')\n",
    "    \n",
    "    train_losses.append(loss); train_accs.append(acc); train_group_accs.append(group_acc)\n",
    "    \n",
    "    # eval for one epoch\n",
    "    val_loss, val_acc, val_group_acc = validate(opt, val_loader, classifier, ce_loss, get_yp_func, train_group_ratio, target=opt.train_target, print_label=f'Val({opt.train_target})')\n",
    "    val_losses.append(val_loss); val_accs.append(val_acc); val_group_accs.append(val_group_acc)\n",
    "    \n",
    "    # update best epoch by worst_group accuracy (default)\n",
    "    if val_group_acc['worst_acc'] > best_acc:\n",
    "        best_acc = val_group_acc['worst_acc']\n",
    "        best_epoch = epoch\n",
    "        best_model = deepcopy(classifier)\n",
    "    \n",
    "    # test for one epoch\n",
    "    test_loss, test_acc, test_group_acc = validate(opt, test_loader, classifier, ce_loss, get_yp_func, train_group_ratio, target='class', print_label=f'Test({opt.train_target})')\n",
    "    \n",
    "    test_losses.append(test_loss); test_accs.append(test_acc); test_group_accs.append(test_group_acc)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debuging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader Iteration 오류  \n",
    "#### Conclusion\n",
    "- Add \"datasets.on_contrastive_batch\" for swichting indexing mechanism.\n",
    "  - in def get_resampled_dataset \n",
    "  - in {dataset}_embeddings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = copy.deepcopy(contrastive_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_batch_size = 1 + opt.num_positive + opt.num_negative\n",
    "print(\"Size of each data\", each_batch_size)\n",
    "full_data_size = len(dataset_test.embeddings_df.columns)\n",
    "print(\"Number of Full sample : \", full_data_size)\n",
    "num_data = full_data_size // each_batch_size\n",
    "print(\"Number of data : \", num_data, \"Anchor ~ \")\n",
    "\n",
    "offset = 0\n",
    "for _ in range(num_data):\n",
    "    each_data = dataset_test.embeddings_df.iloc[:, offset: offset+each_batch_size]\n",
    "    offset += each_batch_size\n",
    "\n",
    "    # 하나의 anc-pos-neg triplet 안에 중복되는 샘플이 있는지.\n",
    "    assert(len(np.unique(each_data.columns)) == each_batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test.embeddings_df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    try:\n",
    "        sample = dataset_test[i]\n",
    "    except:\n",
    "        \n",
    "        print(\"Problem Index : \", i)\n",
    "        print(\"len(File_name.array)\", len(dataset_test.filename_array))\n",
    "        \n",
    "        img_filename = dataset_test.filename_array[i]\n",
    "        print(\"filename\", img_filename)\n",
    "        # print(e)\n",
    "        ebd_full = dataset_test.embeddings_df[img_filename]\n",
    "        print(ebd_full)\n",
    "        break\n",
    "        \n",
    "\n",
    "# File 이름은 하나지만, 그에 따라 인덱싱되는 샘플이 여러개라 오류 발생.\n",
    "## Waterbirds_embeddings.py에서, self.on_contrastive_batch = [True/False] 를 이용해 인덱싱 방식을 바꿔준다.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: filename_array[idx] == embeddings_df.columns[idx]\n",
    "\n",
    "for idx in range(full_data_size):\n",
    "    # print(dataset_test.filename_array[idx])\n",
    "    # print(dataset_test.embeddings_df.columns[idx]) # ㄹ\n",
    "    # print(dataset_test.embeddings_df.iloc[:, idx])\n",
    "    \n",
    "    # print(dataset_test.embeddings_df[dataset_test.filename_array[idx]].shape) # 문제상황\n",
    "    \n",
    "    assert dataset_test.filename_array[idx] == dataset_test.embeddings_df.columns[idx] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27504, 1024])\n",
      "torch.Size([27504])\n",
      "torch.Size([27504])\n",
      "torch.Size([27504])\n",
      "torch.Size([27504])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_iter = iter(contrastive_dataloader)\n",
    "\n",
    "each_batch =  data_iter.next()\n",
    "ebd, full_y, _ = each_batch\n",
    "\n",
    "target, group, spurious, zs_pred = full_y.values()\n",
    "\n",
    "print(ebd.shape)\n",
    "print(target.shape)\n",
    "print(group.shape)\n",
    "print(spurious.shape)\n",
    "print(zs_pred.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_mmd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

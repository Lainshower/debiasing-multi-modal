{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/jinsu/workstation/project/debiasing-multi-modal\")\n",
    "\n",
    "\n",
    "df_zs_embeddings = pd.read_json(\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/waterbirds/RN50/embedding_prediction.json\")\n",
    "df_meta = pd.read_csv(\"/home/jinsu/workstation/project/debiasing-multi-modal/data/waterbirds/waterbird_complete95_forest2water2/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>001.Black_footed_Albatross/Black_Footed_Albatross_0009_34.jpg</th>\n",
       "      <th>001.Black_footed_Albatross/Black_Footed_Albatross_0074_59.jpg</th>\n",
       "      <th>001.Black_footed_Albatross/Black_Footed_Albatross_0014_89.jpg</th>\n",
       "      <th>001.Black_footed_Albatross/Black_Footed_Albatross_0031_100.jpg</th>\n",
       "      <th>001.Black_footed_Albatross/Black_Footed_Albatross_0010_796097.jpg</th>\n",
       "      <th>001.Black_footed_Albatross/Black_Footed_Albatross_0023_796059.jpg</th>\n",
       "      <th>001.Black_footed_Albatross/Black_Footed_Albatross_0040_796066.jpg</th>\n",
       "      <th>001.Black_footed_Albatross/Black_Footed_Albatross_0089_796069.jpg</th>\n",
       "      <th>001.Black_footed_Albatross/Black_Footed_Albatross_0067_170.jpg</th>\n",
       "      <th>001.Black_footed_Albatross/Black_Footed_Albatross_0060_796076.jpg</th>\n",
       "      <th>...</th>\n",
       "      <th>200.Common_Yellowthroat/Common_Yellowthroat_0021_190655.jpg</th>\n",
       "      <th>200.Common_Yellowthroat/Common_Yellowthroat_0011_190401.jpg</th>\n",
       "      <th>200.Common_Yellowthroat/Common_Yellowthroat_0029_190403.jpg</th>\n",
       "      <th>200.Common_Yellowthroat/Common_Yellowthroat_0071_190665.jpg</th>\n",
       "      <th>200.Common_Yellowthroat/Common_Yellowthroat_0070_190678.jpg</th>\n",
       "      <th>200.Common_Yellowthroat/Common_Yellowthroat_0040_190427.jpg</th>\n",
       "      <th>200.Common_Yellowthroat/Common_Yellowthroat_0063_190440.jpg</th>\n",
       "      <th>200.Common_Yellowthroat/Common_Yellowthroat_0058_190958.jpg</th>\n",
       "      <th>200.Common_Yellowthroat/Common_Yellowthroat_0008_190703.jpg</th>\n",
       "      <th>200.Common_Yellowthroat/Common_Yellowthroat_0055_190967.jpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_embedding</th>\n",
       "      <td>[0.012435913085937, 0.007781982421875001, 0.02...</td>\n",
       "      <td>[-0.012657165527343, -0.015228271484375002, 0....</td>\n",
       "      <td>[-0.007061004638671001, -0.007820129394531, -0...</td>\n",
       "      <td>[-0.000501632690429, -0.009048461914062, 0.025...</td>\n",
       "      <td>[-0.002298355102539, 0.008895874023437, 0.0137...</td>\n",
       "      <td>[-0.017959594726562, -0.0135498046875, 0.00348...</td>\n",
       "      <td>[-0.020599365234375, 0.003993988037109, -0.014...</td>\n",
       "      <td>[-0.020538330078125, -0.026107788085937, 0.023...</td>\n",
       "      <td>[-0.0031890869140620004, -0.013809204101562, 0...</td>\n",
       "      <td>[-0.01031494140625, 3.343820571899414e-05, 0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.01251220703125, 0.024337768554687, -0.00127...</td>\n",
       "      <td>[0.0169677734375, 0.020248413085937, -0.005756...</td>\n",
       "      <td>[-0.007366180419921001, 0.034454345703125, 0.0...</td>\n",
       "      <td>[-0.0035343170166010004, 0.004840850830078, -0...</td>\n",
       "      <td>[0.012901306152343, 0.024017333984375003, 0.01...</td>\n",
       "      <td>[-0.000723361968994, -0.010108947753906, -0.02...</td>\n",
       "      <td>[0.005821228027343001, 0.00714111328125, -0.00...</td>\n",
       "      <td>[-0.007404327392578001, 0.020523071289062, 0.0...</td>\n",
       "      <td>[0.014686584472656002, 0.001265525817871, 0.01...</td>\n",
       "      <td>[0.012840270996093, 0.01300048828125, 0.013381...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 11788 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                001.Black_footed_Albatross/Black_Footed_Albatross_0009_34.jpg   \n",
       "y                                                                1             \\\n",
       "place                                                            1              \n",
       "group                                                            3              \n",
       "split                                                            0              \n",
       "image_embedding  [0.012435913085937, 0.007781982421875001, 0.02...              \n",
       "y_pred                                                           0              \n",
       "\n",
       "                001.Black_footed_Albatross/Black_Footed_Albatross_0074_59.jpg   \n",
       "y                                                                1             \\\n",
       "place                                                            1              \n",
       "group                                                            3              \n",
       "split                                                            0              \n",
       "image_embedding  [-0.012657165527343, -0.015228271484375002, 0....              \n",
       "y_pred                                                           1              \n",
       "\n",
       "                001.Black_footed_Albatross/Black_Footed_Albatross_0014_89.jpg   \n",
       "y                                                                1             \\\n",
       "place                                                            1              \n",
       "group                                                            3              \n",
       "split                                                            0              \n",
       "image_embedding  [-0.007061004638671001, -0.007820129394531, -0...              \n",
       "y_pred                                                           1              \n",
       "\n",
       "                001.Black_footed_Albatross/Black_Footed_Albatross_0031_100.jpg   \n",
       "y                                                                1              \\\n",
       "place                                                            1               \n",
       "group                                                            3               \n",
       "split                                                            0               \n",
       "image_embedding  [-0.000501632690429, -0.009048461914062, 0.025...               \n",
       "y_pred                                                           1               \n",
       "\n",
       "                001.Black_footed_Albatross/Black_Footed_Albatross_0010_796097.jpg   \n",
       "y                                                                1                 \\\n",
       "place                                                            1                  \n",
       "group                                                            3                  \n",
       "split                                                            0                  \n",
       "image_embedding  [-0.002298355102539, 0.008895874023437, 0.0137...                  \n",
       "y_pred                                                           0                  \n",
       "\n",
       "                001.Black_footed_Albatross/Black_Footed_Albatross_0023_796059.jpg   \n",
       "y                                                                1                 \\\n",
       "place                                                            1                  \n",
       "group                                                            3                  \n",
       "split                                                            0                  \n",
       "image_embedding  [-0.017959594726562, -0.0135498046875, 0.00348...                  \n",
       "y_pred                                                           1                  \n",
       "\n",
       "                001.Black_footed_Albatross/Black_Footed_Albatross_0040_796066.jpg   \n",
       "y                                                                1                 \\\n",
       "place                                                            1                  \n",
       "group                                                            3                  \n",
       "split                                                            0                  \n",
       "image_embedding  [-0.020599365234375, 0.003993988037109, -0.014...                  \n",
       "y_pred                                                           0                  \n",
       "\n",
       "                001.Black_footed_Albatross/Black_Footed_Albatross_0089_796069.jpg   \n",
       "y                                                                1                 \\\n",
       "place                                                            1                  \n",
       "group                                                            3                  \n",
       "split                                                            0                  \n",
       "image_embedding  [-0.020538330078125, -0.026107788085937, 0.023...                  \n",
       "y_pred                                                           1                  \n",
       "\n",
       "                001.Black_footed_Albatross/Black_Footed_Albatross_0067_170.jpg   \n",
       "y                                                                1              \\\n",
       "place                                                            1               \n",
       "group                                                            3               \n",
       "split                                                            0               \n",
       "image_embedding  [-0.0031890869140620004, -0.013809204101562, 0...               \n",
       "y_pred                                                           1               \n",
       "\n",
       "                001.Black_footed_Albatross/Black_Footed_Albatross_0060_796076.jpg   \n",
       "y                                                                1                 \\\n",
       "place                                                            1                  \n",
       "group                                                            3                  \n",
       "split                                                            0                  \n",
       "image_embedding  [-0.01031494140625, 3.343820571899414e-05, 0.0...                  \n",
       "y_pred                                                           1                  \n",
       "\n",
       "                 ...   \n",
       "y                ...  \\\n",
       "place            ...   \n",
       "group            ...   \n",
       "split            ...   \n",
       "image_embedding  ...   \n",
       "y_pred           ...   \n",
       "\n",
       "                200.Common_Yellowthroat/Common_Yellowthroat_0021_190655.jpg   \n",
       "y                                                                0           \\\n",
       "place                                                            1            \n",
       "group                                                            1            \n",
       "split                                                            2            \n",
       "image_embedding  [0.01251220703125, 0.024337768554687, -0.00127...            \n",
       "y_pred                                                           0            \n",
       "\n",
       "                200.Common_Yellowthroat/Common_Yellowthroat_0011_190401.jpg   \n",
       "y                                                                0           \\\n",
       "place                                                            0            \n",
       "group                                                            0            \n",
       "split                                                            2            \n",
       "image_embedding  [0.0169677734375, 0.020248413085937, -0.005756...            \n",
       "y_pred                                                           0            \n",
       "\n",
       "                200.Common_Yellowthroat/Common_Yellowthroat_0029_190403.jpg   \n",
       "y                                                                0           \\\n",
       "place                                                            0            \n",
       "group                                                            0            \n",
       "split                                                            2            \n",
       "image_embedding  [-0.007366180419921001, 0.034454345703125, 0.0...            \n",
       "y_pred                                                           0            \n",
       "\n",
       "                200.Common_Yellowthroat/Common_Yellowthroat_0071_190665.jpg   \n",
       "y                                                                0           \\\n",
       "place                                                            1            \n",
       "group                                                            1            \n",
       "split                                                            2            \n",
       "image_embedding  [-0.0035343170166010004, 0.004840850830078, -0...            \n",
       "y_pred                                                           0            \n",
       "\n",
       "                200.Common_Yellowthroat/Common_Yellowthroat_0070_190678.jpg   \n",
       "y                                                                0           \\\n",
       "place                                                            0            \n",
       "group                                                            0            \n",
       "split                                                            2            \n",
       "image_embedding  [0.012901306152343, 0.024017333984375003, 0.01...            \n",
       "y_pred                                                           0            \n",
       "\n",
       "                200.Common_Yellowthroat/Common_Yellowthroat_0040_190427.jpg   \n",
       "y                                                                0           \\\n",
       "place                                                            1            \n",
       "group                                                            1            \n",
       "split                                                            2            \n",
       "image_embedding  [-0.000723361968994, -0.010108947753906, -0.02...            \n",
       "y_pred                                                           0            \n",
       "\n",
       "                200.Common_Yellowthroat/Common_Yellowthroat_0063_190440.jpg   \n",
       "y                                                                0           \\\n",
       "place                                                            1            \n",
       "group                                                            1            \n",
       "split                                                            2            \n",
       "image_embedding  [0.005821228027343001, 0.00714111328125, -0.00...            \n",
       "y_pred                                                           0            \n",
       "\n",
       "                200.Common_Yellowthroat/Common_Yellowthroat_0058_190958.jpg   \n",
       "y                                                                0           \\\n",
       "place                                                            0            \n",
       "group                                                            0            \n",
       "split                                                            2            \n",
       "image_embedding  [-0.007404327392578001, 0.020523071289062, 0.0...            \n",
       "y_pred                                                           0            \n",
       "\n",
       "                200.Common_Yellowthroat/Common_Yellowthroat_0008_190703.jpg   \n",
       "y                                                                0           \\\n",
       "place                                                            0            \n",
       "group                                                            0            \n",
       "split                                                            2            \n",
       "image_embedding  [0.014686584472656002, 0.001265525817871, 0.01...            \n",
       "y_pred                                                           0            \n",
       "\n",
       "                200.Common_Yellowthroat/Common_Yellowthroat_0055_190967.jpg  \n",
       "y                                                                0           \n",
       "place                                                            1           \n",
       "group                                                            1           \n",
       "split                                                            2           \n",
       "image_embedding  [0.012840270996093, 0.01300048828125, 0.013381...           \n",
       "y_pred                                                           0           \n",
       "\n",
       "[6 rows x 11788 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zs_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jinsu/anaconda3/envs/cuda_test/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from util import AverageMeter\n",
    "from util import adjust_learning_rate, warmup_learning_rate, accuracy, accuracy_zs\n",
    "from util import set_optimizer\n",
    "# from networks.resnet_big import SupConResNet, LinearClassifier\n",
    "\n",
    "try:\n",
    "    import apex\n",
    "    from apex import amp, optimizers\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "from resnet import resnet50\n",
    "from data.waterbirds_embeddings import Embeddings, load_embeddings\n",
    "model_dict = {'resnet50': [resnet50, 1024]}\n",
    "new_order_for_print = [\n",
    "    'weighted_mean_acc',\n",
    "    'worst_acc',\n",
    "    'acc_0_0',\n",
    "    'acc_0_1',\n",
    "    'acc_1_0',\n",
    "    'acc_1_1',\n",
    "    'mean_acc'\n",
    "]\n",
    "from functools import partial\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, name='resnet50', num_classes=2):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        _, feat_dim = model_dict[name]\n",
    "        self.fc = nn.Linear(feat_dim, num_classes)\n",
    "\n",
    "    def forward(self, features):\n",
    "        return self.fc(features)\n",
    "\n",
    "def parse_option():\n",
    "    parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "    parser.add_argument('--print_freq', type=int, default=10,\n",
    "                        help='print frequency')\n",
    "    parser.add_argument('--save_freq', type=int, default=50,\n",
    "                        help='save frequency')\n",
    "    parser.add_argument('--batch_size', type=int, default=256,\n",
    "                        help='batch_size')\n",
    "    parser.add_argument('--num_workers', type=int, default=16,\n",
    "                        help='num of workers to use')\n",
    "    parser.add_argument('--epochs', type=int, default=5,\n",
    "                        help='number of training epochs')\n",
    "\n",
    "    # optimization\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.1,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--lr_decay_epochs', type=str, default='60,75,90',\n",
    "                        help='where to decay lr, can be a list')\n",
    "    parser.add_argument('--lr_decay_rate', type=float, default=0.2,\n",
    "                        help='decay rate for learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=0,\n",
    "                        help='weight decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "\n",
    "    # model dataset\n",
    "    parser.add_argument('--model', type=str, default='resnet50')\n",
    "    parser.add_argument('--dataset', type=str, default='waterbirds',\n",
    "                        choices=['celebA', 'waterbirds'], help='dataset')\n",
    "\n",
    "    # other setting\n",
    "    parser.add_argument('--cosine', action='store_true',\n",
    "                        help='using cosine annealing')\n",
    "    parser.add_argument('--warm', action='store_true',\n",
    "                        help='warm-up for large batch training')\n",
    "\n",
    "    parser.add_argument('--embedding_dir', type=str,\n",
    "                        help='extracted embedding')\n",
    "    parser.add_argument('--target', type=str, default=\"class\", choices=[\"class\", \"group\", \"spurious\"])\n",
    "    parser.add_argument('--data_dir', type=str,\n",
    "                        help='metadata.csv')\n",
    "\n",
    "    opt = parser.parse_args(args=[])\n",
    "\n",
    "    # set the path according to the environment\n",
    "\n",
    "    iterations = opt.lr_decay_epochs.split(',')\n",
    "    opt.lr_decay_epochs = list([])\n",
    "    for it in iterations:\n",
    "        opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "    opt.model_name = '{}_{}_lr_{}_decay_{}_bsz_{}'.\\\n",
    "        format(opt.dataset, opt.model, opt.learning_rate, opt.weight_decay,\n",
    "               opt.batch_size)\n",
    "\n",
    "    if opt.cosine:\n",
    "        opt.model_name = '{}_cosine'.format(opt.model_name)\n",
    "\n",
    "    # warm-up for large-batch training,\n",
    "    if opt.warm:\n",
    "        opt.model_name = '{}_warm'.format(opt.model_name)\n",
    "        opt.warmup_from = 0.01\n",
    "        opt.warm_epochs = 10\n",
    "        if opt.cosine:\n",
    "            eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "            opt.warmup_to = eta_min + (opt.learning_rate - eta_min) * (\n",
    "                    1 + math.cos(math.pi * opt.warm_epochs / opt.epochs)) / 2\n",
    "        else:\n",
    "            opt.warmup_to = opt.learning_rate\n",
    "            \n",
    "    if opt.dataset == 'celebA':\n",
    "        opt.n_cls = 2\n",
    "    elif opt.dataset == 'waterbirds':\n",
    "        opt.n_cls = 2\n",
    "    else:\n",
    "        raise ValueError('dataset not supported: {}'.format(opt.dataset))\n",
    "\n",
    "    return opt\n",
    "\n",
    "\n",
    "def set_model(opt):\n",
    "    # model = SupConResNet(name=opt.model)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    classifier = LinearClassifier(name=opt.model, num_classes=opt.n_cls)\n",
    "\n",
    "    # ckpt = torch.load(opt.ckpt, map_location='cpu')\n",
    "    # state_dict = ckpt['model']\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # if torch.cuda.device_count() > 1:\n",
    "        #     model.encoder = torch.nn.DataParallel(model.encoder)\n",
    "        # else:\n",
    "            # new_state_dict = {}\n",
    "            # for k, v in state_dict.items():\n",
    "            #     k = k.replace(\"module.\", \"\")\n",
    "            #     new_state_dict[k] = v\n",
    "            # state_dict = new_state_dict\n",
    "        \n",
    "        # model = model.cuda()\n",
    "        classifier = classifier.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "        # model.load_state_dict(state_dict)\n",
    "\n",
    "    return classifier, criterion # model, \n",
    "\n",
    "def update_dict(acc_groups, y, g, logits):\n",
    "    preds = torch.argmax(logits, axis=1)\n",
    "    correct_batch = (preds == y)\n",
    "    g = g.cpu()\n",
    "    for g_val in np.unique(g):\n",
    "        mask = g == g_val\n",
    "        n = mask.sum().item()\n",
    "        corr = correct_batch[mask].sum().item()\n",
    "        acc_groups[g_val].update(corr / n, n) # AverageMeter Updater. \n",
    "\n",
    "def get_results(acc_groups, get_yp_func, ): # Input 중 acc_groups : AverageMeter()를 담고있는 dict. get_yp_func : 미리 partial을 이용해 n_groups를 저장해놓음. \n",
    "    groups = acc_groups.keys() # 0, 1, 2, 3\n",
    "    results = {\n",
    "            f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\": acc_groups[g].avg\n",
    "            for g in groups\n",
    "    }\n",
    "    all_correct = sum([acc_groups[g].sum for g in groups])\n",
    "    all_total = sum([acc_groups[g].count for g in groups])\n",
    "    results.update({\"mean_acc\" : all_correct / all_total})\n",
    "    results.update({\"worst_acc\" : min(results.values())})\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_y_p(g, n_places):\n",
    "    y = g // n_places\n",
    "    p = g % n_places\n",
    "    return y, p\n",
    "\n",
    "\n",
    "def train(train_loader, classifier, criterion, optimizer, epoch, get_yp_func, target, label='Train'): # model,\n",
    "    \"\"\"one epoch training\"\"\"\n",
    "    # model.eval()\n",
    "    classifier.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(train_loader.dataset.n_groups)}\n",
    "\n",
    "    end = time.time()\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        if opt.dataset == 'waterbirds':\n",
    "            embeddings, all_labels, _ = data\n",
    "            labels = all_labels[target] # (y, y_group, y_spurious)\n",
    "            groups = all_labels['group']\n",
    "        else:\n",
    "            embeddings, all_labels = data\n",
    "            labels = all_labels[target] # (y, y_group, y_spurious)\n",
    "            groups = all_labels['group']\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        embeddings = embeddings.cuda(non_blocking=True)\n",
    "        labels = labels.cuda(non_blocking=True)\n",
    "        bsz = labels.shape[0]\n",
    "\n",
    "        # warm-up learning rate\n",
    "        warmup_learning_rate(opt, epoch, idx, len(train_loader), optimizer)\n",
    "\n",
    "        # compute loss\n",
    "        # with torch.no_grad():\n",
    "        #     features = model.encoder(embeddings)\n",
    "        output = classifier(embeddings.detach())\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # update metric\n",
    "        losses.update(loss.item(), bsz)\n",
    "        acc1 = accuracy(output, labels, bsz)\n",
    "        acc.update(acc1, bsz)\n",
    "\n",
    "        # SGD\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        # Update acc dict\n",
    "        update_dict(acc_groups, labels, groups, output)\n",
    "        \n",
    "        # print info\n",
    "        if (idx + 1) % opt.print_freq == 0:\n",
    "            print(f'{label}: [{0}][{1}/{2}]\\t'\n",
    "                  'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n",
    "                  'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                   epoch, idx + 1, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, acc=acc))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "    group_acc = get_results(acc_groups, get_yp_func) # NOTE declared in [def main]\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print[1:]}\n",
    "    print(f\"{label}:\", str(group_acc))\n",
    "    \n",
    "    return losses.avg, acc.avg, group_acc\n",
    "\n",
    "\n",
    "def validate(val_loader, classifier, criterion, get_yp_func, train_group_ratio, target, label='Test', watch=True):\n",
    "    \"\"\"validation\"\"\"\n",
    "    \n",
    "    # model.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(val_loader.dataset.n_groups)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            if opt.dataset == 'waterbirds':\n",
    "                embeddings, all_labels, _ = data\n",
    "                labels = all_labels[target] # (y, y_group, y_spurious)\n",
    "                groups = all_labels['group']\n",
    "            else:\n",
    "                embeddings, all_labels = data\n",
    "                labels = all_labels[target] # (y, y_group, y_spurious)\n",
    "                groups = all_labels['group']\n",
    "            \n",
    "            embeddings = embeddings.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "            bsz = labels.shape[0]\n",
    "\n",
    "            # forward\n",
    "            output = classifier(embeddings)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # update metric\n",
    "            losses.update(loss.item(), bsz)\n",
    "            acc1 = accuracy(output, labels, bsz)\n",
    "            acc.update(acc1, bsz)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            # Update acc dict\n",
    "            update_dict(acc_groups, labels, groups, output)\n",
    "        \n",
    "            if (idx+1) % opt.print_freq == 0:\n",
    "                if watch:\n",
    "                    print(f'{label}: [{0}/{1}]\\t'\n",
    "                        'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                        'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                        'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                        idx, len(val_loader), batch_time=batch_time,\n",
    "                        loss=losses, acc=acc))\n",
    "                    \n",
    "                    \n",
    "    group_acc = get_results(acc_groups, get_yp_func)\n",
    "    \n",
    "    #NOTE add Weighted mean acc.\n",
    "    groups = range(val_loader.dataset.n_groups) # 0, 1, 2, 3\n",
    "    group_acc_indiv =  [group_acc[f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\"] for g in groups]\n",
    "    weighted_mean_acc = (np.array(group_acc_indiv) * np.array(train_group_ratio)).sum() # Weighted Sum \\\n",
    "    \n",
    "    group_acc[\"weighted_mean_acc\"] = weighted_mean_acc\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print}\n",
    "    \n",
    "    if watch:\n",
    "        print(f\"{label}:\", str(group_acc))\n",
    "        print(' * Acc@1 {acc.avg:.3f}'.format(acc=acc))\n",
    "    return losses.avg, acc.avg, group_acc\n",
    "\n",
    "\n",
    "def main(opt):\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    # opt = parse_option()\n",
    "\n",
    "    # build dataset example.\n",
    "    trainset = Embeddings(opt.data_dir, 'train', opt.embedding_dir, None, None)\n",
    "    get_yp_func = partial(get_y_p, n_places=trainset.n_places)\n",
    "    train_group_ratio = trainset.group_ratio\n",
    "    \n",
    "    # build data loader\n",
    "    print(\"Load Data Loader (train, validation, test)\")\n",
    "    train_loader, val_loader, test_loader = load_embeddings(opt.data_dir, opt.embedding_dir, opt.batch_size, opt.batch_size)\n",
    "    \n",
    "    # build model and criterion\n",
    "    print(\"Set Linear Classifier\")\n",
    "    classifier, criterion = set_model(opt) # model, \n",
    "\n",
    "    # build optimizer\n",
    "    print(\"Set Optimizer\")\n",
    "    optimizer = set_optimizer(opt, classifier)\n",
    "\n",
    "    # training routine\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    train_group_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    val_group_accs = []\n",
    "    \n",
    "    test_losses_y = [] # NOTE: Don't peek ! \n",
    "    test_accs_y = [] # NOTE: Don't peek ! \n",
    "    test_group_accs_y = [] # NOTE: Don't peek ! \n",
    "    test_losses_spurious = [] # NOTE: Don't peek ! \n",
    "    test_accs_spurious = [] # NOTE: Don't peek ! \n",
    "    test_group_accs_spurious = [] # NOTE: Don't peek ! \n",
    "    \n",
    "    for epoch in range(1, opt.epochs + 1):\n",
    "        adjust_learning_rate(opt, optimizer, epoch)\n",
    "\n",
    "\n",
    "        print(f'--- Epoch {epoch} ---')\n",
    "        # train for one epoch\n",
    "        loss, acc, group_acc = train(train_loader, classifier, criterion,\n",
    "                          optimizer, epoch, get_yp_func, target='y', label='Train(y)')\n",
    "        \n",
    "        train_losses.append(loss)\n",
    "        train_accs.append(acc)\n",
    "        train_group_accs.append(group_acc)\n",
    "        # eval for one epoch\n",
    "        val_loss, val_acc, val_group_acc = validate(val_loader, classifier, criterion, get_yp_func, train_group_ratio, target='y', label='Val(y)')\n",
    "        if val_group_acc['worst_acc'] > best_acc:\n",
    "            best_acc = val_group_acc['worst_acc']\n",
    "            best_epoch = epoch\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        val_group_accs.append(val_group_acc)\n",
    "            \n",
    "        test_loss_y, test_acc_y, test_group_acc_y = validate(test_loader, classifier, criterion, get_yp_func, train_group_ratio, target='y', label='Test(y)', watch=True)\n",
    "        test_losses_y.append(test_loss_y)\n",
    "        test_accs_y.append(test_acc_y)\n",
    "        test_group_accs_y.append(test_group_acc_y)\n",
    "        \n",
    "        test_loss_spurious, test_acc_spurious, test_group_acc_spurious= validate(test_loader, classifier, criterion, get_yp_func, train_group_ratio, target='spurious', label='Test(spurious)', watch=True)\n",
    "        test_losses_spurious.append(test_loss_spurious)\n",
    "        test_accs_spurious.append(test_acc_spurious)\n",
    "        test_group_accs_spurious.append(test_group_acc_spurious)\n",
    "    \n",
    "    \n",
    "    print('==================================================================')\n",
    "    print('best epoch : {}'.format(best_epoch))\n",
    "    print('best (worst-)validation accuracy: {} '.format(val_group_accs[best_epoch-1]))\n",
    "    \n",
    "    print('best test accuracy (class): {}'.format(test_group_accs_y[best_epoch-1]))\n",
    "    print('best test accuracy (spurious): {}'.format(test_group_accs_spurious[best_epoch-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "parser.add_argument('--print_freq', type=int, default=20,\n",
    "                    help='print frequency')\n",
    "parser.add_argument('--save_freq', type=int, default=50,\n",
    "                    help='save frequency')\n",
    "parser.add_argument('--batch_size', type=int, default=512,\n",
    "                    help='batch_size')\n",
    "parser.add_argument('--num_workers', type=int, default=16,\n",
    "                    help='num of workers to use')\n",
    "parser.add_argument('--epochs', type=int, default=10,\n",
    "                    help='number of training epochs')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--learning_rate', type=float, default=5,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--lr_decay_epochs', type=str, default='60,75,90',\n",
    "                    help='where to decay lr, can be a list')\n",
    "parser.add_argument('--lr_decay_rate', type=float, default=0.2,\n",
    "                    help='decay rate for learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=0,\n",
    "                    help='weight decay')\n",
    "parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                    help='momentum')\n",
    "\n",
    "# model dataset\n",
    "parser.add_argument('--model', type=str, default='resnet50')\n",
    "parser.add_argument('--dataset', type=str, default='waterbirds',\n",
    "                    choices=['celebA', 'waterbirds'], help='dataset')\n",
    "\n",
    "# other setting\n",
    "parser.add_argument('--cosine', action='store_true',\n",
    "                    help='using cosine annealing')\n",
    "parser.add_argument('--warm', action='store_true',\n",
    "                    help='warm-up for large batch training')\n",
    "\n",
    "parser.add_argument('--embedding_dir', type=str, \n",
    "                    help='extracted embedding')\n",
    "parser.add_argument('--target', type=str, default=\"class\", choices=[\"class\", \"group\", \"spurious\"]) # Label for linear proving\n",
    "parser.add_argument('--data_dir', type=str,\n",
    "                    help='folder, in which [metadata.csv] exists')\n",
    "\n",
    "opt = parser.parse_args(args=[])   \n",
    "\n",
    "iterations = opt.lr_decay_epochs.split(',')\n",
    "opt.lr_decay_epochs = list([])\n",
    "for it in iterations:\n",
    "    opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "opt.model_name = '{}_{}_lr_{}_decay_{}_bsz_{}'.\\\n",
    "    format(opt.dataset, opt.model, opt.learning_rate, opt.weight_decay,\n",
    "            opt.batch_size)\n",
    "\n",
    "if opt.cosine:\n",
    "    opt.model_name = '{}_cosine'.format(opt.model_name)\n",
    "\n",
    "# warm-up for large-batch training,\n",
    "if opt.warm:\n",
    "    opt.model_name = '{}_warm'.format(opt.model_name)\n",
    "    opt.warmup_from = 0.01\n",
    "    opt.warm_epochs = 10\n",
    "    if opt.cosine:\n",
    "        eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "        opt.warmup_to = eta_min + (opt.learning_rate - eta_min) * (\n",
    "                1 + math.cos(math.pi * opt.warm_epochs / opt.epochs)) / 2\n",
    "    else:\n",
    "        opt.warmup_to = opt.learning_rate\n",
    "        \n",
    "if opt.dataset == 'celebA':\n",
    "    opt.n_cls = 2\n",
    "elif opt.dataset == 'waterbirds':\n",
    "    opt.n_cls = 2\n",
    "else:\n",
    "    raise ValueError('dataset not supported: {}'.format(opt.dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Proving  \n",
    "- (Epoch default : 100)\n",
    "- Test 성능 모니터링하면 안 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Loader (train, validation, test)\n",
      "Set Linear Classifier\n",
      "Set Optimizer\n",
      "--- Epoch 1 ---\n",
      "Train(y): {'worst_acc': 0.16071428571428573, 'acc_0_0': 0.8850771869639794, 'acc_0_1': 0.8369565217391305, 'acc_1_0': 0.16071428571428573, 'acc_1_1': 0.30179754020813626, 'mean_acc': 0.7461939520333681}\n",
      "Val(y): {'weighted_mean_acc': 0.7685754887177203, 'worst_acc': 0.05150214592274678, 'acc_0_0': 0.7366167023554604, 'acc_0_1': 0.05150214592274678, 'acc_1_0': 0.8947368421052632, 'acc_1_1': 0.9924812030075187, 'mean_acc': 0.5162635529608006}\n",
      " * Acc@1 0.516\n",
      "Test(y): {'weighted_mean_acc': 0.7550782425464763, 'worst_acc': 0.04567627494456763, 'acc_0_0': 0.7170731707317073, 'acc_0_1': 0.04567627494456763, 'acc_1_0': 0.9252336448598131, 'acc_1_1': 0.9953271028037384, 'mean_acc': 0.5096651708664135}\n",
      " * Acc@1 0.510\n",
      "Test(spurious): {'weighted_mean_acc': 0.7800135852513611, 'worst_acc': 0.07476635514018691, 'acc_0_0': 0.7170731707317073, 'acc_0_1': 0.9543237250554324, 'acc_1_0': 0.07476635514018691, 'acc_1_1': 0.9953271028037384, 'mean_acc': 0.7690714532274767}\n",
      " * Acc@1 0.769\n",
      "--- Epoch 2 ---\n",
      "Train(y): {'worst_acc': 0.2857142857142857, 'acc_0_0': 0.9611206403659234, 'acc_0_1': 0.5271739130434783, 'acc_1_0': 0.2857142857142857, 'acc_1_1': 0.8249763481551561, 'mean_acc': 0.9065693430656935}\n",
      "Val(y): {'weighted_mean_acc': 0.924469628896797, 'worst_acc': 0.2296137339055794, 'acc_0_0': 0.9464668094218416, 'acc_0_1': 0.2296137339055794, 'acc_1_0': 0.6917293233082706, 'acc_1_1': 0.9849624060150376, 'mean_acc': 0.6438698915763136}\n",
      " * Acc@1 0.644\n",
      "Test(y): {'weighted_mean_acc': 0.9273426682862188, 'worst_acc': 0.21241685144124167, 'acc_0_0': 0.9543237250554324, 'acc_0_1': 0.21241685144124167, 'acc_1_0': 0.6900311526479751, 'acc_1_1': 0.9750778816199377, 'mean_acc': 0.6385916465308941}\n",
      " * Acc@1 0.639\n",
      "Test(spurious): {'weighted_mean_acc': 0.944975017152046, 'worst_acc': 0.3099688473520249, 'acc_0_0': 0.9543237250554324, 'acc_0_1': 0.7875831485587583, 'acc_1_0': 0.3099688473520249, 'acc_1_1': 0.9750778816199377, 'mean_acc': 0.8203313772868485}\n",
      " * Acc@1 0.820\n",
      "--- Epoch 3 ---\n",
      "Train(y): {'worst_acc': 0.19642857142857142, 'acc_0_0': 0.9925671812464265, 'acc_0_1': 0.5380434782608695, 'acc_1_0': 0.19642857142857142, 'acc_1_1': 0.9167455061494797, 'mean_acc': 0.9491136600625651}\n",
      "Val(y): {'weighted_mean_acc': 0.9587789778888438, 'worst_acc': 0.3308270676691729, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.5107296137339056, 'acc_1_0': 0.3308270676691729, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.7281067556296914}\n",
      " * Acc@1 0.728\n",
      "Test(y): {'weighted_mean_acc': 0.9574648209069655, 'worst_acc': 0.35514018691588783, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.4926829268292683, 'acc_1_0': 0.35514018691588783, 'acc_1_1': 0.9485981308411215, 'mean_acc': 0.7231618916120124}\n",
      " * Acc@1 0.723\n",
      "Test(spurious): {'weighted_mean_acc': 0.9614099682285787, 'worst_acc': 0.5073170731707317, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.5073170731707317, 'acc_1_0': 0.6448598130841121, 'acc_1_1': 0.9485981308411215, 'mean_acc': 0.7609596133931653}\n",
      " * Acc@1 0.761\n",
      "--- Epoch 4 ---\n",
      "Train(y): {'worst_acc': 0.3392857142857143, 'acc_0_0': 0.9914236706689536, 'acc_0_1': 0.44565217391304346, 'acc_1_0': 0.3392857142857143, 'acc_1_1': 0.9498580889309366, 'mean_acc': 0.9537017726798749}\n",
      "Val(y): {'weighted_mean_acc': 0.9639248436545198, 'worst_acc': 0.19548872180451127, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.6909871244635193, 'acc_1_0': 0.19548872180451127, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.7831526271893244}\n",
      " * Acc@1 0.783\n",
      "Test(y): {'weighted_mean_acc': 0.9566997560389323, 'worst_acc': 0.2398753894080997, 'acc_0_0': 0.9991130820399113, 'acc_0_1': 0.6656319290465632, 'acc_1_0': 0.2398753894080997, 'acc_1_1': 0.9049844236760125, 'mean_acc': 0.7747670003451846}\n",
      " * Acc@1 0.775\n",
      "Test(spurious): {'weighted_mean_acc': 0.9500639695863802, 'worst_acc': 0.3343680709534368, 'acc_0_0': 0.9991130820399113, 'acc_0_1': 0.3343680709534368, 'acc_1_0': 0.7601246105919003, 'acc_1_1': 0.9049844236760125, 'mean_acc': 0.7034863652053849}\n",
      " * Acc@1 0.703\n",
      "--- Epoch 5 ---\n",
      "Train(y): {'worst_acc': 0.375, 'acc_0_0': 0.9948542024013722, 'acc_0_1': 0.5652173913043478, 'acc_1_0': 0.375, 'acc_1_1': 0.9394512771996215, 'mean_acc': 0.9589155370177268}\n",
      "Val(y): {'weighted_mean_acc': 0.9659289056751702, 'worst_acc': 0.41353383458646614, 'acc_0_0': 0.9957173447537473, 'acc_0_1': 0.5879828326180258, 'acc_1_0': 0.41353383458646614, 'acc_1_1': 0.9624060150375939, 'mean_acc': 0.7689741451209341}\n",
      " * Acc@1 0.769\n",
      "Test(y): {'weighted_mean_acc': 0.959753994318037, 'worst_acc': 0.4657320872274143, 'acc_0_0': 0.9933481152993349, 'acc_0_1': 0.5534368070953437, 'acc_1_0': 0.4657320872274143, 'acc_1_1': 0.9454828660436138, 'mean_acc': 0.7583707283396617}\n",
      " * Acc@1 0.758\n",
      "Test(spurious): {'weighted_mean_acc': 0.9564533187439636, 'worst_acc': 0.4465631929046563, 'acc_0_0': 0.9933481152993349, 'acc_0_1': 0.4465631929046563, 'acc_1_0': 0.5342679127725857, 'acc_1_1': 0.9454828660436138, 'mean_acc': 0.7243700379703141}\n",
      " * Acc@1 0.724\n",
      "--- Epoch 6 ---\n",
      "Train(y): {'worst_acc': 0.375, 'acc_0_0': 0.9959977129788451, 'acc_0_1': 0.6141304347826086, 'acc_1_0': 0.375, 'acc_1_1': 0.9432355723746452, 'mean_acc': 0.9624608967674662}\n",
      "Val(y): {'weighted_mean_acc': 0.966476396446703, 'worst_acc': 0.40601503759398494, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.6502145922746781, 'acc_1_0': 0.40601503759398494, 'acc_1_1': 0.9473684210526315, 'mean_acc': 0.7914929107589658}\n",
      " * Acc@1 0.791\n",
      "Test(y): {'weighted_mean_acc': 0.9606347088156556, 'worst_acc': 0.4797507788161994, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.6, 'acc_1_0': 0.4797507788161994, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.7775284777355885}\n",
      " * Acc@1 0.778\n",
      "Test(spurious): {'weighted_mean_acc': 0.9534330220275026, 'worst_acc': 0.4, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.4, 'acc_1_0': 0.5202492211838006, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.7041767345529858}\n",
      " * Acc@1 0.704\n",
      "--- Epoch 7 ---\n",
      "Train(y): {'worst_acc': 0.48214285714285715, 'acc_0_0': 0.9948542024013722, 'acc_0_1': 0.6630434782608695, 'acc_1_0': 0.48214285714285715, 'acc_1_1': 0.9403973509933775, 'mean_acc': 0.9641293013555787}\n",
      "Val(y): {'weighted_mean_acc': 0.9664620828456792, 'worst_acc': 0.49624060150375937, 'acc_0_0': 0.9957173447537473, 'acc_0_1': 0.6630901287553648, 'acc_1_0': 0.49624060150375937, 'acc_1_1': 0.9473684210526315, 'mean_acc': 0.8056713928273561}\n",
      " * Acc@1 0.806\n",
      "Test(y): {'weighted_mean_acc': 0.9602542469081821, 'worst_acc': 0.5218068535825545, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.6199556541019956, 'acc_1_0': 0.5218068535825545, 'acc_1_1': 0.9361370716510904, 'mean_acc': 0.7890921643079047}\n",
      " * Acc@1 0.789\n",
      "Test(spurious): {'weighted_mean_acc': 0.9505386996274827, 'worst_acc': 0.38004434589800445, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.38004434589800445, 'acc_1_0': 0.4781931464174455, 'acc_1_1': 0.9361370716510904, 'mean_acc': 0.6908871246116672}\n",
      " * Acc@1 0.691\n",
      "--- Epoch 8 ---\n",
      "Train(y): {'worst_acc': 0.5178571428571429, 'acc_0_0': 0.994568324757004, 'acc_0_1': 0.7065217391304348, 'acc_1_0': 0.5178571428571429, 'acc_1_1': 0.9385052034058656, 'mean_acc': 0.9655891553701773}\n",
      "Val(y): {'weighted_mean_acc': 0.9676972751115684, 'worst_acc': 0.49624060150375937, 'acc_0_0': 0.9957173447537473, 'acc_0_1': 0.6952789699570815, 'acc_1_0': 0.49624060150375937, 'acc_1_1': 0.9473684210526315, 'mean_acc': 0.8181818181818182}\n",
      " * Acc@1 0.818\n",
      "Test(y): {'weighted_mean_acc': 0.9603688135426082, 'worst_acc': 0.5280373831775701, 'acc_0_0': 0.9920177383592018, 'acc_0_1': 0.656319290465632, 'acc_1_0': 0.5280373831775701, 'acc_1_1': 0.9314641744548287, 'mean_acc': 0.8032447359337246}\n",
      " * Acc@1 0.803\n",
      "Test(spurious): {'weighted_mean_acc': 0.9477169497298891, 'worst_acc': 0.3436807095343681, 'acc_0_0': 0.9920177383592018, 'acc_0_1': 0.3436807095343681, 'acc_1_0': 0.4719626168224299, 'acc_1_1': 0.9314641744548287, 'mean_acc': 0.6753538142906454}\n",
      " * Acc@1 0.675\n",
      "--- Epoch 9 ---\n",
      "Train(y): {'worst_acc': 0.5357142857142857, 'acc_0_0': 0.994568324757004, 'acc_0_1': 0.7282608695652174, 'acc_1_0': 0.5357142857142857, 'acc_1_1': 0.935666982024598, 'mean_acc': 0.9660062565172054}\n",
      "Val(y): {'weighted_mean_acc': 0.9673128674224721, 'worst_acc': 0.5338345864661654, 'acc_0_0': 0.9957173447537473, 'acc_0_1': 0.6738197424892703, 'acc_1_0': 0.5338345864661654, 'acc_1_1': 0.9473684210526315, 'mean_acc': 0.8140116763969975}\n",
      " * Acc@1 0.814\n",
      "Test(y): {'weighted_mean_acc': 0.9607967666634459, 'worst_acc': 0.5607476635514018, 'acc_0_0': 0.9915742793791574, 'acc_0_1': 0.6301552106430155, 'acc_1_0': 0.5607476635514018, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.797204004142216}\n",
      " * Acc@1 0.797\n",
      "Test(spurious): {'weighted_mean_acc': 0.9493888716382691, 'worst_acc': 0.3698447893569845, 'acc_0_0': 0.9915742793791574, 'acc_0_1': 0.3698447893569845, 'acc_1_0': 0.4392523364485981, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.6824301001035554}\n",
      " * Acc@1 0.682\n",
      "--- Epoch 10 ---\n",
      "Train(y): {'worst_acc': 0.5357142857142857, 'acc_0_0': 0.9948542024013722, 'acc_0_1': 0.7282608695652174, 'acc_1_0': 0.5357142857142857, 'acc_1_1': 0.935666982024598, 'mean_acc': 0.9662148070907195}\n",
      "Val(y): {'weighted_mean_acc': 0.968022851355525, 'worst_acc': 0.5864661654135338, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.6738197424892703, 'acc_1_0': 0.5864661654135338, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.8198498748957465}\n",
      " * Acc@1 0.820\n",
      "Test(y): {'weighted_mean_acc': 0.9598282009215264, 'worst_acc': 0.5856697819314641, 'acc_0_0': 0.9906873614190688, 'acc_0_1': 0.614190687361419, 'acc_1_0': 0.5856697819314641, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.7934069727304107}\n",
      " * Acc@1 0.793\n",
      "Test(spurious): {'weighted_mean_acc': 0.949063406533041, 'worst_acc': 0.3858093126385809, 'acc_0_0': 0.9906873614190688, 'acc_0_1': 0.3858093126385809, 'acc_1_0': 0.4143302180685358, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.6855367621677597}\n",
      " * Acc@1 0.686\n",
      "==================================================================\n",
      "best epoch : 10\n",
      "best (worst-)validation accuracy: {'weighted_mean_acc': 0.968022851355525, 'worst_acc': 0.5864661654135338, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.6738197424892703, 'acc_1_0': 0.5864661654135338, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.8198498748957465} \n",
      "best test accuracy (class): {'weighted_mean_acc': 0.9598282009215264, 'worst_acc': 0.5856697819314641, 'acc_0_0': 0.9906873614190688, 'acc_0_1': 0.614190687361419, 'acc_1_0': 0.5856697819314641, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.7934069727304107}\n",
      "best test accuracy (spurious): {'weighted_mean_acc': 0.949063406533041, 'worst_acc': 0.3858093126385809, 'acc_0_0': 0.9906873614190688, 'acc_0_1': 0.3858093126385809, 'acc_1_0': 0.4143302180685358, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.6855367621677597}\n"
     ]
    }
   ],
   "source": [
    "opt.embedding_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/waterbirds/RN50/embedding_prediction.json\"\n",
    "opt.data_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/waterbirds/waterbird_complete95_forest2water2\"\n",
    "if __name__ == '__main__':    \n",
    "    main(opt)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dict_zs(acc_groups, y, g, preds):\n",
    "    # preds = torch.argmax(logits, axis=1)\n",
    "    correct_batch = (preds == y)\n",
    "    g = g.cpu()\n",
    "    for g_val in np.unique(g):\n",
    "        mask = g == g_val\n",
    "        n = mask.sum().item()\n",
    "        corr = correct_batch[mask].sum().item()\n",
    "        acc_groups[g_val].update(corr / n, n) # AverageMeter Updater. \n",
    "\n",
    "def validate_zs(val_loader, get_yp_func, train_group_ratio, target, label='Test', watch=True):\n",
    "    \"\"\"validation\"\"\"\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(val_loader.dataset.n_groups)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            if opt.dataset == 'waterbirds':\n",
    "                _, all_labels, _ = data\n",
    "                labels = all_labels[target] # (y, y_group, y_spurious)\n",
    "                groups = all_labels['group']\n",
    "                preds = all_labels['ebd_y_pred']\n",
    "            else:\n",
    "                _,  all_labels, _ = data\n",
    "                labels = all_labels[target] # (y, y_group, y_spurious)\n",
    "                groups = all_labels['group']\n",
    "                preds = all_labels['ebd_y_pred']\n",
    "              \n",
    "              \n",
    "            preds = preds.float().cuda()  \n",
    "            # embeddings = embeddings.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "            bsz = labels.shape[0]\n",
    "\n",
    "            # forward\n",
    "            # output = classifier(embeddings)\n",
    "            # loss = criterion(output, labels)\n",
    "\n",
    "            # update metric\n",
    "            # losses.update(loss.item(), bsz)\n",
    "            acc1 = accuracy_zs(preds, labels, bsz)\n",
    "            acc.update(acc1, bsz)\n",
    "            \n",
    "            # Update acc dict\n",
    "            update_dict_zs(acc_groups, labels, groups, preds)\n",
    "                    \n",
    "                    \n",
    "    group_acc = get_results(acc_groups, get_yp_func)\n",
    "    \n",
    "    #NOTE add Weighted mean acc.\n",
    "    groups = range(val_loader.dataset.n_groups) # 0, 1, 2, 3\n",
    "    group_acc_indiv =  [group_acc[f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\"] for g in groups]\n",
    "    weighted_mean_acc = (np.array(group_acc_indiv) * np.array(train_group_ratio)).sum() # Weighted Sum \\\n",
    "    \n",
    "    group_acc[\"weighted_mean_acc\"] = weighted_mean_acc\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print}\n",
    "    \n",
    "    if watch:\n",
    "        print(f\"{label}:\", str(group_acc))\n",
    "        print(' * Acc@1 {acc.avg:.3f}'.format(acc=acc))\n",
    "        \n",
    "    return  acc.avg, group_acc\n",
    "\n",
    "\n",
    "def main_zs(opt):\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    # opt = parse_option()\n",
    "\n",
    "    # build dataset example.\n",
    "    trainset = Embeddings(opt.data_dir, 'train', opt.embedding_dir, None, None)\n",
    "    get_yp_func = partial(get_y_p, n_places=trainset.n_places)\n",
    "    train_group_ratio = trainset.group_ratio\n",
    "    \n",
    "    # build data loader\n",
    "    print(\"Load Data Loader (train, validation, test)\")\n",
    "    train_loader, val_loader, test_loader = load_embeddings(opt.data_dir, opt.embedding_dir, opt.batch_size, opt.batch_size)\n",
    "\n",
    "    # train for one epoch\n",
    "\n",
    "    # eval for one epoch\n",
    "    val_acc, val_group_acc = validate_zs(val_loader, get_yp_func, train_group_ratio, target='y', label='Val(y)')\n",
    "        \n",
    "    test_acc_y, test_group_acc_y = validate_zs(test_loader, get_yp_func, train_group_ratio, target='y', label='Test(y)', watch=True)\n",
    "\n",
    "    \n",
    "    print('===============================Final Results===============================')\n",
    "    print('Zero-shot (worst-)validation accuracy: {} '.format(val_group_acc))\n",
    "    \n",
    "    print('Zero-shot test accuracy (class): {}'.format(test_group_acc_y))\n",
    "    # print('best test accuracy (spurious): {}'.format(test_group_accs_spurious[best_epoch-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Loader (train, validation, test)\n",
      "Val(y): {'weighted_mean_acc': 0.9450627926530569, 'worst_acc': 0.3233082706766917, 'acc_0_0': 0.9914346895074947, 'acc_0_1': 0.7145922746781116, 'acc_1_0': 0.3233082706766917, 'acc_1_1': 0.8646616541353384, 'mean_acc': 0.7956630525437864}\n",
      " * Acc@1 0.796\n",
      "Test(y): {'weighted_mean_acc': 0.9289761348579215, 'worst_acc': 0.3909657320872274, 'acc_0_0': 0.9804878048780488, 'acc_0_1': 0.7254988913525499, 'acc_1_0': 0.3909657320872274, 'acc_1_1': 0.822429906542056, 'mean_acc': 0.7984121505005177}\n",
      " * Acc@1 0.798\n",
      "===============================Final Results===============================\n",
      "Zero-shot (worst-)validation accuracy: {'weighted_mean_acc': 0.9450627926530569, 'worst_acc': 0.3233082706766917, 'acc_0_0': 0.9914346895074947, 'acc_0_1': 0.7145922746781116, 'acc_1_0': 0.3233082706766917, 'acc_1_1': 0.8646616541353384, 'mean_acc': 0.7956630525437864} \n",
      "Zero-shot test accuracy (class): {'weighted_mean_acc': 0.9289761348579215, 'worst_acc': 0.3909657320872274, 'acc_0_0': 0.9804878048780488, 'acc_0_1': 0.7254988913525499, 'acc_1_0': 0.3909657320872274, 'acc_1_1': 0.822429906542056, 'mean_acc': 0.7984121505005177}\n"
     ]
    }
   ],
   "source": [
    "opt.embedding_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/waterbirds/RN50/embedding_prediction.json\"\n",
    "opt.data_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/waterbirds/waterbird_complete95_forest2water2\"\n",
    "if __name__ == '__main__':    \n",
    "    main_zs(opt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

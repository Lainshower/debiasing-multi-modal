{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/jinsu/workstation/project/debiasing-multi-modal\")\n",
    "\n",
    "\n",
    "df_zs_embeddings = pd.read_json(\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/waterbirds/RN50/embedding_prediction.json\")\n",
    "df_meta = pd.read_csv(\"/home/jinsu/workstation/project/debiasing-multi-modal/data/waterbirds/waterbird_complete95_forest2water2/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from util import AverageMeter\n",
    "from util import adjust_learning_rate, warmup_learning_rate, accuracy, accuracy_zs\n",
    "from util import set_optimizer\n",
    "# from networks.resnet_big import SupConResNet, LinearClassifier\n",
    "\n",
    "try:\n",
    "    import apex\n",
    "    from apex import amp, optimizers\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "from resnet import resnet50\n",
    "from data.waterbirds_embeddings import WaterbirdsEmbeddings, load_waterbirds_embeddings\n",
    "from data.celeba_embeddings import CelebaEmbeddings, load_celeba_embeddings\n",
    "model_dict = {'resnet50': [resnet50, 1024]}\n",
    "new_order_for_print = [\n",
    "    'weighted_mean_acc',\n",
    "    'worst_acc',\n",
    "    'acc_0_0',\n",
    "    'acc_0_1',\n",
    "    'acc_1_0',\n",
    "    'acc_1_1',\n",
    "    'mean_acc'\n",
    "]\n",
    "from functools import partial\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, name='resnet50', num_classes=2):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        _, feat_dim = model_dict[name]\n",
    "        self.fc = nn.Linear(feat_dim, num_classes)\n",
    "\n",
    "    def forward(self, features):\n",
    "        return self.fc(features)\n",
    "\n",
    "def parse_option():\n",
    "    parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "    parser.add_argument('--print_freq', type=int, default=10,\n",
    "                        help='print frequency')\n",
    "    parser.add_argument('--save_freq', type=int, default=50,\n",
    "                        help='save frequency')\n",
    "    parser.add_argument('--batch_size', type=int, default=256,\n",
    "                        help='batch_size')\n",
    "    parser.add_argument('--num_workers', type=int, default=16,\n",
    "                        help='num of workers to use')\n",
    "    parser.add_argument('--epochs', type=int, default=100,\n",
    "                        help='number of training epochs')\n",
    "\n",
    "    # optimization\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.1,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--lr_decay_epochs', type=str, default='60,75,90',\n",
    "                        help='where to decay lr, can be a list')\n",
    "    parser.add_argument('--lr_decay_rate', type=float, default=0.2,\n",
    "                        help='decay rate for learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=0,\n",
    "                        help='weight decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "\n",
    "    # model dataset\n",
    "    parser.add_argument('--model', type=str, default='resnet50')\n",
    "    parser.add_argument('--dataset', type=str, default='waterbirds',\n",
    "                        choices=['celeba', 'waterbirds'], help='dataset')\n",
    "\n",
    "    # other setting\n",
    "    parser.add_argument('--cosine', action='store_true',\n",
    "                        help='using cosine annealing')\n",
    "    parser.add_argument('--warm', action='store_true',\n",
    "                        help='warm-up for large batch training')\n",
    "\n",
    "    parser.add_argument('--embedding_dir', type=str,\n",
    "                        help='extracted embedding')\n",
    "    parser.add_argument('--target', type=str, default=\"class\", choices=[\"class\", \"group\", \"spurious\"])\n",
    "    parser.add_argument('--data_dir', type=str,\n",
    "                        help='metadata.csv')\n",
    "\n",
    "    opt = parser.parse_args(args=[])\n",
    "\n",
    "    # set the path according to the environment\n",
    "\n",
    "    iterations = opt.lr_decay_epochs.split(',')\n",
    "    opt.lr_decay_epochs = list([])\n",
    "    for it in iterations:\n",
    "        opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "    opt.model_name = '{}_{}_lr_{}_decay_{}_bsz_{}'.\\\n",
    "        format(opt.dataset, opt.model, opt.learning_rate, opt.weight_decay,\n",
    "               opt.batch_size)\n",
    "\n",
    "    if opt.cosine:\n",
    "        opt.model_name = '{}_cosine'.format(opt.model_name)\n",
    "\n",
    "    # warm-up for large-batch training,\n",
    "    if opt.warm:\n",
    "        opt.model_name = '{}_warm'.format(opt.model_name)\n",
    "        opt.warmup_from = 0.01\n",
    "        opt.warm_epochs = 10\n",
    "        if opt.cosine:\n",
    "            eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "            opt.warmup_to = eta_min + (opt.learning_rate - eta_min) * (\n",
    "                    1 + math.cos(math.pi * opt.warm_epochs / opt.epochs)) / 2\n",
    "        else:\n",
    "            opt.warmup_to = opt.learning_rate\n",
    "            \n",
    "    if opt.dataset == 'celeba':\n",
    "        opt.n_cls = 2\n",
    "    elif opt.dataset == 'waterbirds':\n",
    "        opt.n_cls = 2\n",
    "    else:\n",
    "        raise ValueError('dataset not supported: {}'.format(opt.dataset))\n",
    "\n",
    "    return opt\n",
    "\n",
    "\n",
    "def set_model(opt):\n",
    "    # model = SupConResNet(name=opt.model)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    classifier = LinearClassifier(name=opt.model, num_classes=opt.n_cls)\n",
    "\n",
    "    # ckpt = torch.load(opt.ckpt, map_location='cpu')\n",
    "    # state_dict = ckpt['model']\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # if torch.cuda.device_count() > 1:\n",
    "        #     model.encoder = torch.nn.DataParallel(model.encoder)\n",
    "        # else:\n",
    "            # new_state_dict = {}\n",
    "            # for k, v in state_dict.items():\n",
    "            #     k = k.replace(\"module.\", \"\")\n",
    "            #     new_state_dict[k] = v\n",
    "            # state_dict = new_state_dict\n",
    "        \n",
    "        # model = model.cuda()\n",
    "        classifier = classifier.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "        # model.load_state_dict(state_dict)\n",
    "\n",
    "    return classifier, criterion # model, \n",
    "\n",
    "def update_dict(acc_groups, y, g, logits):\n",
    "    preds = torch.argmax(logits, axis=1)\n",
    "    correct_batch = (preds == y)\n",
    "    g = g.cpu()\n",
    "    for g_val in np.unique(g):\n",
    "        mask = g == g_val\n",
    "        n = mask.sum().item()\n",
    "        corr = correct_batch[mask].sum().item()\n",
    "        acc_groups[g_val].update(corr / n, n) # AverageMeter Updater. \n",
    "\n",
    "def get_results(acc_groups, get_yp_func, ): # Input 중 acc_groups : AverageMeter()를 담고있는 dict. get_yp_func : 미리 partial을 이용해 n_groups를 저장해놓음. \n",
    "    groups = acc_groups.keys() # 0, 1, 2, 3\n",
    "    results = {\n",
    "            f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\": acc_groups[g].avg\n",
    "            for g in groups\n",
    "    }\n",
    "    all_correct = sum([acc_groups[g].sum for g in groups])\n",
    "    all_total = sum([acc_groups[g].count for g in groups])\n",
    "    results.update({\"mean_acc\" : all_correct / all_total})\n",
    "    results.update({\"worst_acc\" : min(results.values())})\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_y_p(g, n_places):\n",
    "    y = g // n_places\n",
    "    p = g % n_places\n",
    "    return y, p\n",
    "\n",
    "\n",
    "def train(train_loader, classifier, criterion, optimizer, epoch, get_yp_func, target, label='Train'): # model,\n",
    "    \"\"\"one epoch training\"\"\"\n",
    "    # model.eval()\n",
    "    classifier.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(train_loader.dataset.n_groups)}\n",
    "\n",
    "    end = time.time()\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        if opt.dataset == 'waterbirds':\n",
    "            embeddings, all_labels, _ = data\n",
    "            labels = all_labels[target] # (y, group, spurious)\n",
    "            groups = all_labels['group']\n",
    "        else:\n",
    "            embeddings, all_labels = data\n",
    "            labels = all_labels[target] # (y, group, ypurious)\n",
    "            groups = all_labels['group']\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        embeddings = embeddings.cuda(non_blocking=True)\n",
    "        labels = labels.cuda(non_blocking=True)\n",
    "        bsz = labels.shape[0]\n",
    "\n",
    "        # warm-up learning rate\n",
    "        warmup_learning_rate(opt, epoch, idx, len(train_loader), optimizer)\n",
    "\n",
    "        # compute loss\n",
    "        # with torch.no_grad():\n",
    "        #     features = model.encoder(embeddings)\n",
    "        output = classifier(embeddings.detach())\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # update metric\n",
    "        losses.update(loss.item(), bsz)\n",
    "        acc1 = accuracy(output, labels, bsz)\n",
    "        acc.update(acc1, bsz)\n",
    "\n",
    "        # SGD\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        # Update acc dict\n",
    "        update_dict(acc_groups, labels, groups, output)\n",
    "        \n",
    "        # print info\n",
    "        if (idx + 1) % opt.print_freq == 0:\n",
    "            print(f'{label}: [{0}][{1}/{2}]\\t'\n",
    "                  'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n",
    "                  'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                   epoch, idx + 1, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, acc=acc))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "    group_acc = get_results(acc_groups, get_yp_func) # NOTE declared in [def main]\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print[1:]}\n",
    "    print(f\"{label}:\", str(group_acc))\n",
    "    \n",
    "    return losses.avg, acc.avg, group_acc\n",
    "\n",
    "\n",
    "def validate(val_loader, classifier, criterion, get_yp_func, train_group_ratio, target, label='Test', watch=True):\n",
    "    \"\"\"validation\"\"\"\n",
    "    \n",
    "    # model.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(val_loader.dataset.n_groups)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            if opt.dataset == 'waterbirds':\n",
    "                embeddings, all_labels, _ = data\n",
    "                labels = all_labels[target] # (y, group, spurious)\n",
    "                groups = all_labels['group']\n",
    "            elif opt.dataset == 'celeba':\n",
    "                embeddings, all_labels = data\n",
    "                labels = all_labels[target] # (y, group, spurious)\n",
    "                groups = all_labels['group']\n",
    "            \n",
    "            embeddings = embeddings.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "            bsz = labels.shape[0]\n",
    "\n",
    "            # forward\n",
    "            output = classifier(embeddings)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # update metric\n",
    "            losses.update(loss.item(), bsz)\n",
    "            acc1 = accuracy(output, labels, bsz)\n",
    "            acc.update(acc1, bsz)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            # Update acc dict\n",
    "            update_dict(acc_groups, labels, groups, output)\n",
    "        \n",
    "            if (idx+1) % opt.print_freq == 0:\n",
    "                if watch:\n",
    "                    print(f'{label}: [{0}/{1}]\\t'\n",
    "                        'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                        'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                        'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                        idx, len(val_loader), batch_time=batch_time,\n",
    "                        loss=losses, acc=acc))\n",
    "                    \n",
    "                    \n",
    "    group_acc = get_results(acc_groups, get_yp_func)\n",
    "    \n",
    "    #NOTE add Weighted mean acc.\n",
    "    groups = range(val_loader.dataset.n_groups) # 0, 1, 2, 3\n",
    "    group_acc_indiv =  [group_acc[f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\"] for g in groups]\n",
    "    weighted_mean_acc = (np.array(group_acc_indiv) * np.array(train_group_ratio)).sum() # Weighted Sum \\\n",
    "    \n",
    "    group_acc[\"weighted_mean_acc\"] = weighted_mean_acc\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print}\n",
    "    \n",
    "    if watch:\n",
    "        print(f\"{label}:\", str(group_acc))\n",
    "        # print(' * Acc@1 {acc.avg:.3f}'.format(acc=acc))\n",
    "    return losses.avg, acc.avg, group_acc\n",
    "\n",
    "\n",
    "def main(opt):\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    # opt = parse_option()\n",
    "    \n",
    "    if opt.dataset == 'waterbirds':\n",
    "        # build dataset example.\n",
    "        trainset = WaterbirdsEmbeddings(opt.data_dir, 'train', opt.embedding_dir, None, None)\n",
    "        # build data loader\n",
    "        print(\"Load Data Loader (train, validation, test)\")\n",
    "        train_loader, val_loader, test_loader = load_waterbirds_embeddings(opt.data_dir, opt.embedding_dir, opt.batch_size, opt.batch_size)\n",
    "    elif opt.dataset == 'celeba':\n",
    "        # build dataset example.\n",
    "        trainset = CelebaEmbeddings(opt.data_dir, 'train', opt.embedding_dir, None)\n",
    "        # build data loader\n",
    "        print(\"Load Data Loader (train, validation, test)\")\n",
    "        train_loader, val_loader, test_loader = load_celeba_embeddings(opt.data_dir, opt.embedding_dir, opt.batch_size, opt.batch_size)\n",
    "        \n",
    "    get_yp_func = partial(get_y_p, n_places=trainset.n_places)\n",
    "    train_group_ratio = trainset.group_ratio\n",
    "    \n",
    "    # build model and criterion\n",
    "    print(\"Set Linear Classifier\")\n",
    "    classifier, criterion = set_model(opt) # model, \n",
    "\n",
    "    # build optimizer\n",
    "    print(\"Set Optimizer\")\n",
    "    optimizer = set_optimizer(opt, classifier)\n",
    "\n",
    "    # training routine\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    train_group_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    val_group_accs = []\n",
    "    \n",
    "    test_losses_y = [] # NOTE: Don't peek ! \n",
    "    test_accs_y = [] # NOTE: Don't peek ! \n",
    "    test_group_accs_y = [] # NOTE: Don't peek ! \n",
    "    test_losses_spurious = [] # NOTE: Don't peek ! \n",
    "    test_accs_spurious = [] # NOTE: Don't peek ! \n",
    "    test_group_accs_spurious = [] # NOTE: Don't peek ! \n",
    "    \n",
    "    for epoch in range(1, opt.epochs + 1):\n",
    "        adjust_learning_rate(opt, optimizer, epoch)\n",
    "\n",
    "\n",
    "        print(f'--- Epoch {epoch} ---')\n",
    "        # train for one epoch\n",
    "        loss, acc, group_acc = train(train_loader, classifier, criterion,\n",
    "                          optimizer, epoch, get_yp_func, target='y', label='Train(y)')\n",
    "        \n",
    "        train_losses.append(loss)\n",
    "        train_accs.append(acc)\n",
    "        train_group_accs.append(group_acc)\n",
    "        # eval for one epoch\n",
    "        val_loss, val_acc, val_group_acc = validate(val_loader, classifier, criterion, get_yp_func, train_group_ratio, target='y', label='Val(y)')\n",
    "        if val_group_acc['worst_acc'] > best_acc:\n",
    "            best_acc = val_group_acc['worst_acc']\n",
    "            best_epoch = epoch\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        val_group_accs.append(val_group_acc)\n",
    "            \n",
    "        test_loss_y, test_acc_y, test_group_acc_y = validate(test_loader, classifier, criterion, get_yp_func, train_group_ratio, target='y', label='Test(y)', watch=True)\n",
    "        test_losses_y.append(test_loss_y)\n",
    "        test_accs_y.append(test_acc_y)\n",
    "        test_group_accs_y.append(test_group_acc_y)\n",
    "        \n",
    "        test_loss_spurious, test_acc_spurious, test_group_acc_spurious= validate(test_loader, classifier, criterion, get_yp_func, train_group_ratio, target='spurious', label='Test(spurious)', watch=True)\n",
    "        test_losses_spurious.append(test_loss_spurious)\n",
    "        test_accs_spurious.append(test_acc_spurious)\n",
    "        test_group_accs_spurious.append(test_group_acc_spurious)\n",
    "    \n",
    "    \n",
    "    print('==================================================================')\n",
    "    print('best epoch : {}'.format(best_epoch))\n",
    "    print('best (worst-)validation accuracy: {} '.format(val_group_accs[best_epoch-1]))\n",
    "    \n",
    "    print('best test accuracy (class): {}'.format(test_group_accs_y[best_epoch-1]))\n",
    "    print('best test accuracy (spurious): {}'.format(test_group_accs_spurious[best_epoch-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "parser.add_argument('--print_freq', type=int, default=20,\n",
    "                    help='print frequency')\n",
    "parser.add_argument('--save_freq', type=int, default=50,\n",
    "                    help='save frequency')\n",
    "parser.add_argument('--batch_size', type=int, default=512,\n",
    "                    help='batch_size')\n",
    "parser.add_argument('--num_workers', type=int, default=16,\n",
    "                    help='num of workers to use')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='number of training epochs')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--learning_rate', type=float, default=5,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--lr_decay_epochs', type=str, default='60,75,90',\n",
    "                    help='where to decay lr, can be a list')\n",
    "parser.add_argument('--lr_decay_rate', type=float, default=0.2,\n",
    "                    help='decay rate for learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=0,\n",
    "                    help='weight decay')\n",
    "parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                    help='momentum')\n",
    "\n",
    "# model dataset\n",
    "parser.add_argument('--model', type=str, default='resnet50')\n",
    "parser.add_argument('--dataset', type=str, default='waterbirds',\n",
    "                    choices=['celeba', 'waterbirds'], help='dataset')\n",
    "\n",
    "# other setting\n",
    "parser.add_argument('--cosine', action='store_true',\n",
    "                    help='using cosine annealing')\n",
    "parser.add_argument('--warm', action='store_true',\n",
    "                    help='warm-up for large batch training')\n",
    "\n",
    "parser.add_argument('--embedding_dir', type=str, \n",
    "                    help='extracted embedding')\n",
    "parser.add_argument('--target', type=str, default=\"y\", choices=[\"y\", \"group\", \"spurious\"]) # Label for linear proving\n",
    "parser.add_argument('--data_dir', type=str,\n",
    "                    help='folder, in which [metadata.csv] exists')\n",
    "\n",
    "opt = parser.parse_args(args=[])   \n",
    "\n",
    "iterations = opt.lr_decay_epochs.split(',')\n",
    "opt.lr_decay_epochs = list([])\n",
    "for it in iterations:\n",
    "    opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "opt.model_name = '{}_{}_lr_{}_decay_{}_bsz_{}'.\\\n",
    "    format(opt.dataset, opt.model, opt.learning_rate, opt.weight_decay,\n",
    "            opt.batch_size)\n",
    "\n",
    "if opt.cosine:\n",
    "    opt.model_name = '{}_cosine'.format(opt.model_name)\n",
    "\n",
    "# warm-up for large-batch training,\n",
    "if opt.warm:\n",
    "    opt.model_name = '{}_warm'.format(opt.model_name)\n",
    "    opt.warmup_from = 0.01\n",
    "    opt.warm_epochs = 10\n",
    "    if opt.cosine:\n",
    "        eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "        opt.warmup_to = eta_min + (opt.learning_rate - eta_min) * (\n",
    "                1 + math.cos(math.pi * opt.warm_epochs / opt.epochs)) / 2\n",
    "    else:\n",
    "        opt.warmup_to = opt.learning_rate\n",
    "        \n",
    "if opt.dataset == 'celeba':\n",
    "    opt.n_cls = 2\n",
    "elif opt.dataset == 'waterbirds':\n",
    "    opt.n_cls = 2\n",
    "else:\n",
    "    raise ValueError('dataset not supported: {}'.format(opt.dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Proving  \n",
    "- (Epoch default : 100)\n",
    "- Test 성능 모니터링하면 안 됨."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waterbirds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Loader (train, validation, test)\n",
      "Set Linear Classifier\n",
      "Set Optimizer\n",
      "--- Epoch 1 ---\n",
      "Train(y): {'worst_acc': 0.30357142857142855, 'acc_0_0': 0.8776443682104059, 'acc_0_1': 0.5054347826086957, 'acc_1_0': 0.30357142857142855, 'acc_1_1': 0.5534531693472091, 'mean_acc': 0.7851929092805006}\n",
      "Val(y): {'weighted_mean_acc': 0.9556073321666032, 'worst_acc': 0.18796992481203006, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.5579399141630901, 'acc_1_0': 0.18796992481203006, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.7289407839866555}\n",
      " * Acc@1 0.729\n",
      "Test(y): {'weighted_mean_acc': 0.9490767917756933, 'worst_acc': 0.19003115264797507, 'acc_0_0': 0.9973392461197339, 'acc_0_1': 0.5516629711751663, 'acc_1_0': 0.19003115264797507, 'acc_1_1': 0.8987538940809969, 'mean_acc': 0.7235070762858129}\n",
      " * Acc@1 0.724\n",
      "Test(spurious): {'weighted_mean_acc': 0.9523519817025319, 'worst_acc': 0.4483370288248337, 'acc_0_0': 0.9973392461197339, 'acc_0_1': 0.4483370288248337, 'acc_1_0': 0.8099688473520249, 'acc_1_1': 0.8987538940809969, 'mean_acc': 0.7519848118743527}\n",
      " * Acc@1 0.752\n",
      "--- Epoch 2 ---\n",
      "Train(y): {'worst_acc': 0.23214285714285715, 'acc_0_0': 0.9919954259576901, 'acc_0_1': 0.5108695652173914, 'acc_1_0': 0.23214285714285715, 'acc_1_1': 0.9053926206244087, 'mean_acc': 0.9455683003128259}\n",
      "Val(y): {'weighted_mean_acc': 0.9625484267591543, 'worst_acc': 0.19548872180451127, 'acc_0_0': 0.9957173447537473, 'acc_0_1': 0.6094420600858369, 'acc_1_0': 0.19548872180451127, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.7522935779816514}\n",
      " * Acc@1 0.752\n",
      "Test(y): {'weighted_mean_acc': 0.9540004894616466, 'worst_acc': 0.21806853582554517, 'acc_0_0': 0.998669623059867, 'acc_0_1': 0.5924611973392461, 'acc_1_0': 0.21806853582554517, 'acc_1_1': 0.9080996884735203, 'mean_acc': 0.7440455643769417}\n",
      " * Acc@1 0.744\n",
      "Test(spurious): {'weighted_mean_acc': 0.9534896659664881, 'worst_acc': 0.4075388026607539, 'acc_0_0': 0.998669623059867, 'acc_0_1': 0.4075388026607539, 'acc_1_0': 0.7819314641744548, 'acc_1_1': 0.9080996884735203, 'mean_acc': 0.7345529858474283}\n",
      " * Acc@1 0.735\n",
      "--- Epoch 3 ---\n",
      "Train(y): {'worst_acc': 0.2857142857142857, 'acc_0_0': 0.9937106918238994, 'acc_0_1': 0.5597826086956522, 'acc_1_0': 0.2857142857142857, 'acc_1_1': 0.9186376537369915, 'mean_acc': 0.9522419186652763}\n",
      "Val(y): {'weighted_mean_acc': 0.9637723128461045, 'worst_acc': 0.2932330827067669, 'acc_0_0': 0.9957173447537473, 'acc_0_1': 0.6115879828326181, 'acc_1_0': 0.2932330827067669, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.7639699749791493}\n",
      " * Acc@1 0.764\n",
      "Test(y): {'weighted_mean_acc': 0.9577598474066333, 'worst_acc': 0.32710280373831774, 'acc_0_0': 0.9968957871396896, 'acc_0_1': 0.5835920177383592, 'acc_1_0': 0.32710280373831774, 'acc_1_1': 0.926791277258567, 'mean_acc': 0.7540559199171557}\n",
      " * Acc@1 0.754\n",
      "Test(spurious): {'weighted_mean_acc': 0.9553829176855821, 'worst_acc': 0.4164079822616408, 'acc_0_0': 0.9968957871396896, 'acc_0_1': 0.4164079822616408, 'acc_1_0': 0.6728971962616822, 'acc_1_1': 0.926791277258567, 'mean_acc': 0.7273041076976182}\n",
      " * Acc@1 0.727\n",
      "--- Epoch 4 ---\n",
      "Train(y): {'worst_acc': 0.42857142857142855, 'acc_0_0': 0.9957118353344768, 'acc_0_1': 0.6304347826086957, 'acc_1_0': 0.42857142857142855, 'acc_1_1': 0.9252601702932829, 'mean_acc': 0.959541188738269}\n",
      "Val(y): {'weighted_mean_acc': 0.9662851893598707, 'worst_acc': 0.43609022556390975, 'acc_0_0': 0.9957173447537473, 'acc_0_1': 0.5472103004291845, 'acc_1_0': 0.43609022556390975, 'acc_1_1': 0.9699248120300752, 'mean_acc': 0.7564637197664721}\n",
      " * Acc@1 0.756\n",
      "Test(y): {'weighted_mean_acc': 0.9584877292709089, 'worst_acc': 0.5093457943925234, 'acc_0_0': 0.991130820399113, 'acc_0_1': 0.5135254988913526, 'acc_1_0': 0.5093457943925234, 'acc_1_1': 0.9517133956386293, 'mean_acc': 0.7474974111149465}\n",
      " * Acc@1 0.747\n",
      "Test(spurious): {'weighted_mean_acc': 0.9572313971260145, 'worst_acc': 0.48647450110864743, 'acc_0_0': 0.991130820399113, 'acc_0_1': 0.48647450110864743, 'acc_1_0': 0.49065420560747663, 'acc_1_1': 0.9517133956386293, 'mean_acc': 0.7348981705212289}\n",
      " * Acc@1 0.735\n",
      "--- Epoch 5 ---\n",
      "Train(y): {'worst_acc': 0.30357142857142855, 'acc_0_0': 0.9959977129788451, 'acc_0_1': 0.6630434782608695, 'acc_1_0': 0.30357142857142855, 'acc_1_1': 0.9318826868495743, 'mean_acc': 0.9610010427528676}\n",
      "Val(y): {'weighted_mean_acc': 0.9665418058704036, 'worst_acc': 0.5413533834586467, 'acc_0_0': 0.9914346895074947, 'acc_0_1': 0.5600858369098712, 'acc_1_0': 0.5413533834586467, 'acc_1_1': 0.9774436090225563, 'mean_acc': 0.7723102585487907}\n",
      " * Acc@1 0.772\n",
      "Test(y): {'weighted_mean_acc': 0.9581741693085383, 'worst_acc': 0.5148558758314856, 'acc_0_0': 0.9889135254988913, 'acc_0_1': 0.5148558758314856, 'acc_1_0': 0.5872274143302181, 'acc_1_1': 0.9532710280373832, 'mean_acc': 0.7559544356230583}\n",
      " * Acc@1 0.756\n",
      "Test(spurious): {'weighted_mean_acc': 0.9549966025837139, 'worst_acc': 0.4127725856697819, 'acc_0_0': 0.9889135254988913, 'acc_0_1': 0.48514412416851443, 'acc_1_0': 0.4127725856697819, 'acc_1_1': 0.9532710280373832, 'mean_acc': 0.7250604073179151}\n",
      " * Acc@1 0.725\n",
      "--- Epoch 6 ---\n",
      "Train(y): {'worst_acc': 0.5, 'acc_0_0': 0.9951400800457404, 'acc_0_1': 0.6739130434782609, 'acc_1_0': 0.5, 'acc_1_1': 0.9328287606433302, 'mean_acc': 0.9632950990615224}\n",
      "Val(y): {'weighted_mean_acc': 0.965437591043804, 'worst_acc': 0.5944206008583691, 'acc_0_0': 0.987152034261242, 'acc_0_1': 0.5944206008583691, 'acc_1_0': 0.6015037593984962, 'acc_1_1': 0.9774436090225563, 'mean_acc': 0.7906588824020017}\n",
      " * Acc@1 0.791\n",
      "Test(y): {'weighted_mean_acc': 0.9584121473976785, 'worst_acc': 0.5303769401330377, 'acc_0_0': 0.9884700665188471, 'acc_0_1': 0.5303769401330377, 'acc_1_0': 0.6137071651090342, 'acc_1_1': 0.9517133956386293, 'mean_acc': 0.7645840524680704}\n",
      " * Acc@1 0.765\n",
      "Test(spurious): {'weighted_mean_acc': 0.9534248864578019, 'worst_acc': 0.3862928348909657, 'acc_0_0': 0.9884700665188471, 'acc_0_1': 0.4696230598669623, 'acc_1_0': 0.3862928348909657, 'acc_1_1': 0.9517133956386293, 'mean_acc': 0.715740421125302}\n",
      " * Acc@1 0.716\n",
      "--- Epoch 7 ---\n",
      "Train(y): {'worst_acc': 0.5, 'acc_0_0': 0.9948542024013722, 'acc_0_1': 0.6956521739130435, 'acc_1_0': 0.5, 'acc_1_1': 0.9366130558183539, 'mean_acc': 0.9647549530761209}\n",
      "Val(y): {'weighted_mean_acc': 0.9642157851955502, 'worst_acc': 0.5987124463519313, 'acc_0_0': 0.9850107066381156, 'acc_0_1': 0.5987124463519313, 'acc_1_0': 0.6165413533834586, 'acc_1_1': 0.9774436090225563, 'mean_acc': 0.7931609674728941}\n",
      " * Acc@1 0.793\n",
      "Test(y): {'weighted_mean_acc': 0.9586683032849602, 'worst_acc': 0.5388026607538803, 'acc_0_0': 0.9875831485587583, 'acc_0_1': 0.5388026607538803, 'acc_1_0': 0.6339563862928349, 'acc_1_1': 0.9532710280373832, 'mean_acc': 0.7699344149119779}\n",
      " * Acc@1 0.770\n",
      "Test(spurious): {'weighted_mean_acc': 0.9525614223365703, 'worst_acc': 0.3660436137071651, 'acc_0_0': 0.9875831485587583, 'acc_0_1': 0.4611973392461197, 'acc_1_0': 0.3660436137071651, 'acc_1_1': 0.9532710280373832, 'mean_acc': 0.7100448740075941}\n",
      " * Acc@1 0.710\n",
      "--- Epoch 8 ---\n",
      "Train(y): {'worst_acc': 0.5178571428571429, 'acc_0_0': 0.9957118353344768, 'acc_0_1': 0.7228260869565217, 'acc_1_0': 0.5178571428571429, 'acc_1_1': 0.9328287606433302, 'mean_acc': 0.9657977059436913}\n",
      "Val(y): {'weighted_mean_acc': 0.9607016735352716, 'worst_acc': 0.5793991416309013, 'acc_0_0': 0.9807280513918629, 'acc_0_1': 0.5793991416309013, 'acc_1_0': 0.6466165413533834, 'acc_1_1': 0.9774436090225563, 'mean_acc': 0.7873227689741451}\n",
      " * Acc@1 0.787\n",
      "Test(y): {'weighted_mean_acc': 0.9566494997099152, 'worst_acc': 0.5108647450110865, 'acc_0_0': 0.9853658536585366, 'acc_0_1': 0.5108647450110865, 'acc_1_0': 0.661993769470405, 'acc_1_1': 0.9548286604361371, 'mean_acc': 0.7614773904038661}\n",
      " * Acc@1 0.761\n",
      "Test(spurious): {'weighted_mean_acc': 0.9520318714069441, 'worst_acc': 0.338006230529595, 'acc_0_0': 0.9853658536585366, 'acc_0_1': 0.4891352549889135, 'acc_1_0': 0.338006230529595, 'acc_1_1': 0.9548286604361371, 'mean_acc': 0.717121159820504}\n",
      " * Acc@1 0.717\n",
      "--- Epoch 9 ---\n",
      "Train(y): {'worst_acc': 0.5535714285714286, 'acc_0_0': 0.9948542024013722, 'acc_0_1': 0.7119565217391305, 'acc_1_0': 0.5535714285714286, 'acc_1_1': 0.9413434247871334, 'mean_acc': 0.9670490093847758}\n",
      "Val(y): {'weighted_mean_acc': 0.9662100037649979, 'worst_acc': 0.5037593984962406, 'acc_0_0': 0.9957173447537473, 'acc_0_1': 0.6974248927038627, 'acc_1_0': 0.5037593984962406, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8190158465387823}\n",
      " * Acc@1 0.819\n",
      "Test(y): {'weighted_mean_acc': 0.9618914973520424, 'worst_acc': 0.5451713395638629, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.6465631929046564, 'acc_1_0': 0.5451713395638629, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.802209181912323}\n",
      " * Acc@1 0.802\n",
      "Test(spurious): {'weighted_mean_acc': 0.9495881717968203, 'worst_acc': 0.3534368070953437, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.3534368070953437, 'acc_1_0': 0.45482866043613707, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.6781152916810493}\n",
      " * Acc@1 0.678\n",
      "--- Epoch 10 ---\n",
      "Train(y): {'worst_acc': 0.5892857142857143, 'acc_0_0': 0.9957118353344768, 'acc_0_1': 0.7336956521739131, 'acc_1_0': 0.5892857142857143, 'acc_1_1': 0.9375591296121097, 'mean_acc': 0.9680917622523462}\n",
      "Val(y): {'weighted_mean_acc': 0.9670591320888311, 'worst_acc': 0.44360902255639095, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.740343347639485, 'acc_1_0': 0.44360902255639095, 'acc_1_1': 0.9323308270676691, 'mean_acc': 0.8290241868223519}\n",
      " * Acc@1 0.829\n",
      "Test(y): {'weighted_mean_acc': 0.9637698912068049, 'worst_acc': 0.4750778816199377, 'acc_0_0': 0.9960088691796009, 'acc_0_1': 0.7299334811529934, 'acc_1_0': 0.4750778816199377, 'acc_1_1': 0.9236760124610592, 'mean_acc': 0.8267172937521574}\n",
      " * Acc@1 0.827\n",
      "Test(spurious): {'weighted_mean_acc': 0.9467053978118667, 'worst_acc': 0.27006651884700666, 'acc_0_0': 0.9960088691796009, 'acc_0_1': 0.27006651884700666, 'acc_1_0': 0.5249221183800623, 'acc_1_1': 0.9236760124610592, 'mean_acc': 0.6532619951674146}\n",
      " * Acc@1 0.653\n",
      "--- Epoch 11 ---\n",
      "Train(y): {'worst_acc': 0.5535714285714286, 'acc_0_0': 0.9951400800457404, 'acc_0_1': 0.7336956521739131, 'acc_1_0': 0.5535714285714286, 'acc_1_1': 0.9403973509933775, 'mean_acc': 0.9678832116788321}\n",
      "Val(y): {'weighted_mean_acc': 0.968035555736867, 'worst_acc': 0.5263157894736842, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.6974248927038627, 'acc_1_0': 0.5263157894736842, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8223519599666389}\n",
      " * Acc@1 0.822\n",
      "Test(y): {'weighted_mean_acc': 0.9628265253834312, 'worst_acc': 0.5545171339563862, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.6412416851441242, 'acc_1_0': 0.5545171339563862, 'acc_1_1': 0.942367601246106, 'mean_acc': 0.8016914049016224}\n",
      " * Acc@1 0.802\n",
      "Test(spurious): {'weighted_mean_acc': 0.9507133116050257, 'worst_acc': 0.35875831485587584, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.35875831485587584, 'acc_1_0': 0.4454828660436137, 'acc_1_1': 0.942367601246106, 'mean_acc': 0.6796686227131515}\n",
      " * Acc@1 0.680\n",
      "--- Epoch 12 ---\n",
      "Train(y): {'worst_acc': 0.5714285714285714, 'acc_0_0': 0.9962835906232133, 'acc_0_1': 0.717391304347826, 'acc_1_0': 0.5714285714285714, 'acc_1_1': 0.9422894985808893, 'mean_acc': 0.9687174139728885}\n",
      "Val(y): {'weighted_mean_acc': 0.9679696034255276, 'worst_acc': 0.5488721804511278, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.6888412017167382, 'acc_1_0': 0.5488721804511278, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8215179316096747}\n",
      " * Acc@1 0.822\n",
      "Test(y): {'weighted_mean_acc': 0.9626622272065197, 'worst_acc': 0.5623052959501558, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.634589800443459, 'acc_1_0': 0.5623052959501558, 'acc_1_1': 0.942367601246106, 'mean_acc': 0.7999654815326199}\n",
      " * Acc@1 0.800\n",
      "Test(spurious): {'weighted_mean_acc': 0.9508776097819371, 'worst_acc': 0.365410199556541, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.365410199556541, 'acc_1_0': 0.43769470404984423, 'acc_1_1': 0.942367601246106, 'mean_acc': 0.681394546082154}\n",
      " * Acc@1 0.681\n",
      "--- Epoch 13 ---\n",
      "Train(y): {'worst_acc': 0.6071428571428571, 'acc_0_0': 0.9968553459119497, 'acc_0_1': 0.75, 'acc_1_0': 0.6071428571428571, 'acc_1_1': 0.9413434247871334, 'mean_acc': 0.9705943691345151}\n",
      "Val(y): {'weighted_mean_acc': 0.969815615647954, 'worst_acc': 0.5639097744360902, 'acc_0_0': 0.9957173447537473, 'acc_0_1': 0.6866952789699571, 'acc_1_0': 0.5639097744360902, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.823185988323603}\n",
      " * Acc@1 0.823\n",
      "Test(y): {'weighted_mean_acc': 0.9621306013441719, 'worst_acc': 0.5794392523364486, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.6155210643015521, 'acc_1_0': 0.5794392523364486, 'acc_1_1': 0.942367601246106, 'mean_acc': 0.7944425267518123}\n",
      " * Acc@1 0.794\n",
      "Test(spurious): {'weighted_mean_acc': 0.9514092356442847, 'worst_acc': 0.3844789356984479, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.3844789356984479, 'acc_1_0': 0.4205607476635514, 'acc_1_1': 0.942367601246106, 'mean_acc': 0.6869175008629617}\n",
      " * Acc@1 0.687\n",
      "--- Epoch 14 ---\n",
      "Train(y): {'worst_acc': 0.5357142857142857, 'acc_0_0': 0.9965694682675815, 'acc_0_1': 0.7663043478260869, 'acc_1_0': 0.5357142857142857, 'acc_1_1': 0.9413434247871334, 'mean_acc': 0.9701772679874869}\n",
      "Val(y): {'weighted_mean_acc': 0.9700420279153947, 'worst_acc': 0.6165413533834586, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.630901287553648, 'acc_1_0': 0.6165413533834586, 'acc_1_1': 0.9699248120300752, 'mean_acc': 0.8081734778982486}\n",
      " * Acc@1 0.808\n",
      "Test(y): {'weighted_mean_acc': 0.9603744549915314, 'worst_acc': 0.5676274944567627, 'acc_0_0': 0.9906873614190688, 'acc_0_1': 0.5676274944567627, 'acc_1_0': 0.6090342679127726, 'acc_1_1': 0.9470404984423676, 'mean_acc': 0.7789092164307905}\n",
      " * Acc@1 0.779\n",
      "Test(spurious): {'weighted_mean_acc': 0.9526374881422242, 'worst_acc': 0.3909657320872274, 'acc_0_0': 0.9906873614190688, 'acc_0_1': 0.43237250554323725, 'acc_1_0': 0.3909657320872274, 'acc_1_1': 0.9470404984423676, 'mean_acc': 0.7021056265101829}\n",
      " * Acc@1 0.702\n",
      "--- Epoch 15 ---\n",
      "Train(y): {'worst_acc': 0.5892857142857143, 'acc_0_0': 0.9954259576901087, 'acc_0_1': 0.7010869565217391, 'acc_1_0': 0.5892857142857143, 'acc_1_1': 0.9318826868495743, 'mean_acc': 0.9653806047966632}\n",
      "Val(y): {'weighted_mean_acc': 0.9678668891392881, 'worst_acc': 0.5987124463519313, 'acc_0_0': 0.9892933618843683, 'acc_0_1': 0.5987124463519313, 'acc_1_0': 0.6616541353383458, 'acc_1_1': 0.9774436090225563, 'mean_acc': 0.7998331943286072}\n",
      " * Acc@1 0.800\n",
      "Test(y): {'weighted_mean_acc': 0.9577997640501119, 'worst_acc': 0.5241685144124169, 'acc_0_0': 0.9875831485587583, 'acc_0_1': 0.5241685144124169, 'acc_1_0': 0.6370716510903427, 'acc_1_1': 0.9517133956386293, 'mean_acc': 0.7644114601311702}\n",
      " * Acc@1 0.764\n",
      "Test(spurious): {'weighted_mean_acc': 0.9527432389582204, 'worst_acc': 0.3629283489096573, 'acc_0_0': 0.9875831485587583, 'acc_0_1': 0.47583148558758315, 'acc_1_0': 0.3629283489096573, 'acc_1_1': 0.9517133956386293, 'mean_acc': 0.7152226441146013}\n",
      " * Acc@1 0.715\n",
      "--- Epoch 16 ---\n",
      "Train(y): {'worst_acc': 0.5714285714285714, 'acc_0_0': 0.9962835906232133, 'acc_0_1': 0.717391304347826, 'acc_1_0': 0.5714285714285714, 'acc_1_1': 0.9403973509933775, 'mean_acc': 0.9683003128258603}\n",
      "Val(y): {'weighted_mean_acc': 0.9684669458045251, 'worst_acc': 0.6165413533834586, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.6330472103004292, 'acc_1_0': 0.6165413533834586, 'acc_1_1': 0.9624060150375939, 'mean_acc': 0.8081734778982486}\n",
      " * Acc@1 0.808\n",
      "Test(y): {'weighted_mean_acc': 0.9611035202629433, 'worst_acc': 0.5716186252771619, 'acc_0_0': 0.991130820399113, 'acc_0_1': 0.5716186252771619, 'acc_1_0': 0.6012461059190031, 'acc_1_1': 0.9485981308411215, 'mean_acc': 0.7799447704521919}\n",
      " * Acc@1 0.780\n",
      "Test(spurious): {'weighted_mean_acc': 0.9532421609075841, 'worst_acc': 0.3987538940809969, 'acc_0_0': 0.991130820399113, 'acc_0_1': 0.42838137472283816, 'acc_1_0': 0.3987538940809969, 'acc_1_1': 0.9485981308411215, 'mean_acc': 0.7017604418363824}\n",
      " * Acc@1 0.702\n",
      "--- Epoch 17 ---\n",
      "Train(y): {'worst_acc': 0.5714285714285714, 'acc_0_0': 0.9965694682675815, 'acc_0_1': 0.7010869565217391, 'acc_1_0': 0.5714285714285714, 'acc_1_1': 0.9432355723746452, 'mean_acc': 0.9685088633993744}\n",
      "Val(y): {'weighted_mean_acc': 0.9688808757004199, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7103004291845494, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8306922435362802}\n",
      " * Acc@1 0.831\n",
      "Test(y): {'weighted_mean_acc': 0.963861237073097, 'worst_acc': 0.557632398753894, 'acc_0_0': 0.9933481152993349, 'acc_0_1': 0.6682926829268293, 'acc_1_0': 0.557632398753894, 'acc_1_1': 0.9392523364485982, 'mean_acc': 0.8125647221263376}\n",
      " * Acc@1 0.813\n",
      "Test(spurious): {'weighted_mean_acc': 0.9495991855361117, 'worst_acc': 0.33170731707317075, 'acc_0_0': 0.9933481152993349, 'acc_0_1': 0.33170731707317075, 'acc_1_0': 0.4423676012461059, 'acc_1_1': 0.9392523364485982, 'mean_acc': 0.6687953054884364}\n",
      " * Acc@1 0.669\n",
      "--- Epoch 18 ---\n",
      "Train(y): {'worst_acc': 0.5714285714285714, 'acc_0_0': 0.9974271012006861, 'acc_0_1': 0.75, 'acc_1_0': 0.5714285714285714, 'acc_1_1': 0.9422894985808893, 'mean_acc': 0.9708029197080292}\n",
      "Val(y): {'weighted_mean_acc': 0.9691257150129993, 'worst_acc': 0.6165413533834586, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.6502145922746781, 'acc_1_0': 0.6165413533834586, 'acc_1_1': 0.9624060150375939, 'mean_acc': 0.8148457047539617}\n",
      " * Acc@1 0.815\n",
      "Test(y): {'weighted_mean_acc': 0.9616868970258936, 'worst_acc': 0.5965732087227414, 'acc_0_0': 0.9920177383592018, 'acc_0_1': 0.5982261640798227, 'acc_1_0': 0.5965732087227414, 'acc_1_1': 0.9439252336448598, 'mean_acc': 0.7896099413186054}\n",
      " * Acc@1 0.790\n",
      "Test(spurious): {'weighted_mean_acc': 0.9518926471521876, 'worst_acc': 0.4017738359201774, 'acc_0_0': 0.9920177383592018, 'acc_0_1': 0.4017738359201774, 'acc_1_0': 0.40342679127725856, 'acc_1_1': 0.9439252336448598, 'mean_acc': 0.6917500862961684}\n",
      " * Acc@1 0.692\n",
      "--- Epoch 19 ---\n",
      "Train(y): {'worst_acc': 0.5892857142857143, 'acc_0_0': 0.9954259576901087, 'acc_0_1': 0.7445652173913043, 'acc_1_0': 0.5892857142857143, 'acc_1_1': 0.9479659413434248, 'mean_acc': 0.9705943691345151}\n",
      "Val(y): {'weighted_mean_acc': 0.9688072596352422, 'worst_acc': 0.631578947368421, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.6373390557939914, 'acc_1_0': 0.631578947368421, 'acc_1_1': 0.9624060150375939, 'mean_acc': 0.8115095913261051}\n",
      " * Acc@1 0.812\n",
      "Test(y): {'weighted_mean_acc': 0.9599909147523946, 'worst_acc': 0.5711751662971175, 'acc_0_0': 0.98980044345898, 'acc_0_1': 0.5711751662971175, 'acc_1_0': 0.6199376947040498, 'acc_1_1': 0.9470404984423676, 'mean_acc': 0.7811529168104936}\n",
      " * Acc@1 0.781\n",
      "Test(spurious): {'weighted_mean_acc': 0.9517269975342131, 'worst_acc': 0.38006230529595014, 'acc_0_0': 0.98980044345898, 'acc_0_1': 0.4288248337028825, 'acc_1_0': 0.38006230529595014, 'acc_1_1': 0.9470404984423676, 'mean_acc': 0.6991715567828788}\n",
      " * Acc@1 0.699\n",
      "--- Epoch 20 ---\n",
      "Train(y): {'worst_acc': 0.5892857142857143, 'acc_0_0': 0.9971412235563178, 'acc_0_1': 0.75, 'acc_1_0': 0.5892857142857143, 'acc_1_1': 0.9460737937559129, 'mean_acc': 0.9716371220020855}\n",
      "Val(y): {'weighted_mean_acc': 0.9704832808774896, 'worst_acc': 0.5939849624060151, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.6974248927038627, 'acc_1_0': 0.5939849624060151, 'acc_1_1': 0.9473684210526315, 'mean_acc': 0.8306922435362802}\n",
      " * Acc@1 0.831\n",
      "Test(y): {'weighted_mean_acc': 0.9633834987801899, 'worst_acc': 0.5747663551401869, 'acc_0_0': 0.9929046563192905, 'acc_0_1': 0.6501108647450111, 'acc_1_0': 0.5747663551401869, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.8073869520193303}\n",
      " * Acc@1 0.807\n",
      "Test(spurious): {'weighted_mean_acc': 0.9501166310186429, 'worst_acc': 0.34988913525498894, 'acc_0_0': 0.9929046563192905, 'acc_0_1': 0.34988913525498894, 'acc_1_0': 0.4252336448598131, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.6739730755954436}\n",
      " * Acc@1 0.674\n",
      "--- Epoch 21 ---\n",
      "Train(y): {'worst_acc': 0.5892857142857143, 'acc_0_0': 0.9962835906232133, 'acc_0_1': 0.7391304347826086, 'acc_1_0': 0.5892857142857143, 'acc_1_1': 0.9432355723746452, 'mean_acc': 0.9699687174139728}\n",
      "Val(y): {'weighted_mean_acc': 0.9708126654817267, 'worst_acc': 0.5939849624060151, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7060085836909872, 'acc_1_0': 0.5939849624060151, 'acc_1_1': 0.9473684210526315, 'mean_acc': 0.8340283569641368}\n",
      " * Acc@1 0.834\n",
      "Test(y): {'weighted_mean_acc': 0.9633781285413834, 'worst_acc': 0.5716510903426791, 'acc_0_0': 0.9929046563192905, 'acc_0_1': 0.6598669623059867, 'acc_1_0': 0.5716510903426791, 'acc_1_1': 0.9392523364485982, 'mean_acc': 0.810666206420435}\n",
      " * Acc@1 0.811\n",
      "Test(spurious): {'weighted_mean_acc': 0.9494352786442515, 'worst_acc': 0.3401330376940133, 'acc_0_0': 0.9929046563192905, 'acc_0_1': 0.3401330376940133, 'acc_1_0': 0.42834890965732086, 'acc_1_1': 0.9392523364485982, 'mean_acc': 0.6703486365205384}\n",
      " * Acc@1 0.670\n",
      "--- Epoch 22 ---\n",
      "Train(y): {'worst_acc': 0.6071428571428571, 'acc_0_0': 0.9974271012006861, 'acc_0_1': 0.7391304347826086, 'acc_1_0': 0.6071428571428571, 'acc_1_1': 0.9394512771996215, 'mean_acc': 0.9701772679874869}\n",
      "Val(y): {'weighted_mean_acc': 0.9704009347264303, 'worst_acc': 0.5939849624060151, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.6952789699570815, 'acc_1_0': 0.5939849624060151, 'acc_1_1': 0.9473684210526315, 'mean_acc': 0.8298582151793161}\n",
      " * Acc@1 0.830\n",
      "Test(y): {'weighted_mean_acc': 0.9629093718138834, 'worst_acc': 0.5778816199376947, 'acc_0_0': 0.9929046563192905, 'acc_0_1': 0.6368070953436807, 'acc_1_0': 0.5778816199376947, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.8025543665861236}\n",
      " * Acc@1 0.803\n",
      "Test(spurious): {'weighted_mean_acc': 0.9505907579849494, 'worst_acc': 0.3631929046563193, 'acc_0_0': 0.9929046563192905, 'acc_0_1': 0.3631929046563193, 'acc_1_0': 0.4221183800623053, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.6788056610286504}\n",
      " * Acc@1 0.679\n",
      "--- Epoch 23 ---\n",
      "Train(y): {'worst_acc': 0.6071428571428571, 'acc_0_0': 0.9977129788450543, 'acc_0_1': 0.7663043478260869, 'acc_1_0': 0.6071428571428571, 'acc_1_1': 0.9413434247871334, 'mean_acc': 0.9718456725755996}\n",
      "Val(y): {'weighted_mean_acc': 0.9696782464120355, 'worst_acc': 0.6015037593984962, 'acc_0_0': 0.9957173447537473, 'acc_0_1': 0.6716738197424893, 'acc_1_0': 0.6015037593984962, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.8215179316096747}\n",
      " * Acc@1 0.822\n",
      "Test(y): {'weighted_mean_acc': 0.9614296100422957, 'worst_acc': 0.5981308411214953, 'acc_0_0': 0.9915742793791574, 'acc_0_1': 0.6084257206208425, 'acc_1_0': 0.5981308411214953, 'acc_1_1': 0.942367601246106, 'mean_acc': 0.7934069727304107}\n",
      " * Acc@1 0.793\n",
      "Test(spurious): {'weighted_mean_acc': 0.9508161960990134, 'worst_acc': 0.39157427937915745, 'acc_0_0': 0.9915742793791574, 'acc_0_1': 0.39157427937915745, 'acc_1_0': 0.40186915887850466, 'acc_1_1': 0.942367601246106, 'mean_acc': 0.6872626855367622}\n",
      " * Acc@1 0.687\n",
      "--- Epoch 24 ---\n",
      "Train(y): {'worst_acc': 0.5892857142857143, 'acc_0_0': 0.9959977129788451, 'acc_0_1': 0.75, 'acc_1_0': 0.5892857142857143, 'acc_1_1': 0.9489120151371807, 'mean_acc': 0.9714285714285714}\n",
      "Val(y): {'weighted_mean_acc': 0.9705656270285489, 'worst_acc': 0.5939849624060151, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.6995708154506438, 'acc_1_0': 0.5939849624060151, 'acc_1_1': 0.9473684210526315, 'mean_acc': 0.8315262718932444}\n",
      " * Acc@1 0.832\n",
      "Test(y): {'weighted_mean_acc': 0.9630781823949632, 'worst_acc': 0.5763239875389408, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.6501108647450111, 'acc_1_0': 0.5763239875389408, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.8073869520193303}\n",
      " * Acc@1 0.807\n",
      "Test(spurious): {'weighted_mean_acc': 0.9497749319802955, 'worst_acc': 0.34988913525498894, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.34988913525498894, 'acc_1_0': 0.4236760124610592, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.6736278909216431}\n",
      " * Acc@1 0.674\n",
      "--- Epoch 25 ---\n",
      "Train(y): {'worst_acc': 0.6071428571428571, 'acc_0_0': 0.9974271012006861, 'acc_0_1': 0.7880434782608695, 'acc_1_0': 0.6071428571428571, 'acc_1_1': 0.945127719962157, 'mean_acc': 0.9733055265901981}\n",
      "Val(y): {'weighted_mean_acc': 0.9707303193306674, 'worst_acc': 0.5939849624060151, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.703862660944206, 'acc_1_0': 0.5939849624060151, 'acc_1_1': 0.9473684210526315, 'mean_acc': 0.8331943286071727}\n",
      " * Acc@1 0.833\n",
      "Test(y): {'weighted_mean_acc': 0.9639100360005015, 'worst_acc': 0.573208722741433, 'acc_0_0': 0.9933481152993349, 'acc_0_1': 0.6558758314855876, 'acc_1_0': 0.573208722741433, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.8096306523990335}\n",
      " * Acc@1 0.810\n",
      "Test(spurious): {'weighted_mean_acc': 0.9502371092219051, 'worst_acc': 0.3441241685144124, 'acc_0_0': 0.9933481152993349, 'acc_0_1': 0.3441241685144124, 'acc_1_0': 0.42679127725856697, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.6720745598895409}\n",
      " * Acc@1 0.672\n",
      "--- Epoch 26 ---\n",
      "Train(y): {'worst_acc': 0.6071428571428571, 'acc_0_0': 0.9971412235563178, 'acc_0_1': 0.7608695652173914, 'acc_1_0': 0.6071428571428571, 'acc_1_1': 0.9508041627246925, 'mean_acc': 0.9733055265901981}\n",
      "Val(y): {'weighted_mean_acc': 0.9698484033273941, 'worst_acc': 0.6090225563909775, 'acc_0_0': 0.9957173447537473, 'acc_0_1': 0.6738197424892703, 'acc_1_0': 0.6090225563909775, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.823185988323603}\n",
      " * Acc@1 0.823\n",
      "Test(y): {'weighted_mean_acc': 0.9617970343716861, 'worst_acc': 0.6062084257206208, 'acc_0_0': 0.9915742793791574, 'acc_0_1': 0.6062084257206208, 'acc_1_0': 0.6074766355140186, 'acc_1_1': 0.9439252336448598, 'mean_acc': 0.7937521574042112}\n",
      " * Acc@1 0.794\n",
      "Test(spurious): {'weighted_mean_acc': 0.951135494382821, 'worst_acc': 0.3925233644859813, 'acc_0_0': 0.9915742793791574, 'acc_0_1': 0.39379157427937916, 'acc_1_0': 0.3925233644859813, 'acc_1_1': 0.9439252336448598, 'mean_acc': 0.6872626855367622}\n",
      " * Acc@1 0.687\n",
      "--- Epoch 27 ---\n",
      "Train(y): {'worst_acc': 0.6071428571428571, 'acc_0_0': 0.9974271012006861, 'acc_0_1': 0.7771739130434783, 'acc_1_0': 0.6071428571428571, 'acc_1_1': 0.9460737937559129, 'mean_acc': 0.9730969760166841}\n",
      "Val(y): {'weighted_mean_acc': 0.9712003386434647, 'worst_acc': 0.6240601503759399, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.6587982832618026, 'acc_1_0': 0.6240601503759399, 'acc_1_1': 0.9699248120300752, 'mean_acc': 0.8198498748957465}\n",
      " * Acc@1 0.820\n",
      "Test(y): {'weighted_mean_acc': 0.9611572499364057, 'worst_acc': 0.5951219512195122, 'acc_0_0': 0.991130820399113, 'acc_0_1': 0.5951219512195122, 'acc_1_0': 0.616822429906542, 'acc_1_1': 0.9439252336448598, 'mean_acc': 0.7903003106662064}\n",
      " * Acc@1 0.790\n",
      "Test(spurious): {'weighted_mean_acc': 0.9511282633945276, 'worst_acc': 0.38317757009345793, 'acc_0_0': 0.991130820399113, 'acc_0_1': 0.40487804878048783, 'acc_1_0': 0.38317757009345793, 'acc_1_1': 0.9439252336448598, 'mean_acc': 0.6903693476009665}\n",
      " * Acc@1 0.690\n",
      "--- Epoch 28 ---\n",
      "Train(y): {'worst_acc': 0.625, 'acc_0_0': 0.9971412235563178, 'acc_0_1': 0.7771739130434783, 'acc_1_0': 0.625, 'acc_1_1': 0.9479659413434248, 'mean_acc': 0.9735140771637122}\n",
      "Val(y): {'weighted_mean_acc': 0.9700584217551147, 'worst_acc': 0.6244635193133047, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.6244635193133047, 'acc_1_0': 0.6390977443609023, 'acc_1_1': 0.9699248120300752, 'mean_acc': 0.8081734778982486}\n",
      " * Acc@1 0.808\n",
      "Test(y): {'weighted_mean_acc': 0.9603241201543404, 'worst_acc': 0.5764966740576497, 'acc_0_0': 0.9893569844789357, 'acc_0_1': 0.5764966740576497, 'acc_1_0': 0.6292834890965732, 'acc_1_1': 0.9485981308411215, 'mean_acc': 0.784259578874698}\n",
      " * Acc@1 0.784\n",
      "Test(spurious): {'weighted_mean_acc': 0.9514334993218916, 'worst_acc': 0.3707165109034268, 'acc_0_0': 0.9893569844789357, 'acc_0_1': 0.42350332594235035, 'acc_1_0': 0.3707165109034268, 'acc_1_1': 0.9485981308411215, 'mean_acc': 0.6960648947186745}\n",
      " * Acc@1 0.696\n",
      "--- Epoch 29 ---\n",
      "Train(y): {'worst_acc': 0.5892857142857143, 'acc_0_0': 0.9974271012006861, 'acc_0_1': 0.7391304347826086, 'acc_1_0': 0.5892857142857143, 'acc_1_1': 0.9441816461684012, 'mean_acc': 0.9710114702815432}\n",
      "Val(y): {'weighted_mean_acc': 0.9708072008684867, 'worst_acc': 0.5864661654135338, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7081545064377682, 'acc_1_0': 0.5864661654135338, 'acc_1_1': 0.9473684210526315, 'mean_acc': 0.8340283569641368}\n",
      " * Acc@1 0.834\n",
      "Test(y): {'weighted_mean_acc': 0.964296241422739, 'worst_acc': 0.5700934579439252, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.6674057649667405, 'acc_1_0': 0.5700934579439252, 'acc_1_1': 0.9392523364485982, 'mean_acc': 0.8137728684846393}\n",
      " * Acc@1 0.814\n",
      "Test(spurious): {'weighted_mean_acc': 0.9498111966100435, 'worst_acc': 0.3325942350332594, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.3325942350332594, 'acc_1_0': 0.42990654205607476, 'acc_1_1': 0.9392523364485982, 'mean_acc': 0.6679323438039351}\n",
      " * Acc@1 0.668\n",
      "--- Epoch 30 ---\n",
      "Train(y): {'worst_acc': 0.5535714285714286, 'acc_0_0': 0.9968553459119497, 'acc_0_1': 0.782608695652174, 'acc_1_0': 0.5535714285714286, 'acc_1_1': 0.9413434247871334, 'mean_acc': 0.9712200208550573}\n",
      "Val(y): {'weighted_mean_acc': 0.9697345017641176, 'worst_acc': 0.6137339055793991, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.6137339055793991, 'acc_1_0': 0.6466165413533834, 'acc_1_1': 0.9699248120300752, 'mean_acc': 0.804837364470392}\n",
      " * Acc@1 0.805\n",
      "Test(y): {'weighted_mean_acc': 0.9596238017342857, 'worst_acc': 0.5614190687361419, 'acc_0_0': 0.9884700665188471, 'acc_0_1': 0.5614190687361419, 'acc_1_0': 0.6448598130841121, 'acc_1_1': 0.9501557632398754, 'mean_acc': 0.7799447704521919}\n",
      " * Acc@1 0.780\n",
      "Test(spurious): {'weighted_mean_acc': 0.9515265095079966, 'worst_acc': 0.35514018691588783, 'acc_0_0': 0.9884700665188471, 'acc_0_1': 0.4385809312638581, 'acc_1_0': 0.35514018691588783, 'acc_1_1': 0.9501557632398754, 'mean_acc': 0.7000345184673801}\n",
      " * Acc@1 0.700\n",
      "--- Epoch 31 ---\n",
      "Train(y): {'worst_acc': 0.6071428571428571, 'acc_0_0': 0.9968553459119497, 'acc_0_1': 0.7608695652173914, 'acc_1_0': 0.6071428571428571, 'acc_1_1': 0.9498580889309366, 'mean_acc': 0.97288842544317}\n",
      "Val(y): {'weighted_mean_acc': 0.9700899771673319, 'worst_acc': 0.6015037593984962, 'acc_0_0': 0.9957173447537473, 'acc_0_1': 0.6824034334763949, 'acc_1_0': 0.6015037593984962, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.8256880733944955}\n",
      " * Acc@1 0.826\n",
      "Test(y): {'weighted_mean_acc': 0.9623323682045887, 'worst_acc': 0.5950155763239875, 'acc_0_0': 0.9920177383592018, 'acc_0_1': 0.6155210643015521, 'acc_1_0': 0.5950155763239875, 'acc_1_1': 0.9439252336448598, 'mean_acc': 0.7961684501208146}\n",
      " * Acc@1 0.796\n",
      "Test(spurious): {'weighted_mean_acc': 0.9512471759734925, 'worst_acc': 0.3844789356984479, 'acc_0_0': 0.9920177383592018, 'acc_0_1': 0.3844789356984479, 'acc_1_0': 0.40498442367601245, 'acc_1_1': 0.9439252336448598, 'mean_acc': 0.6851915774939593}\n",
      " * Acc@1 0.685\n",
      "--- Epoch 32 ---\n",
      "Train(y): {'worst_acc': 0.5892857142857143, 'acc_0_0': 0.9977129788450543, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.5892857142857143, 'acc_1_1': 0.9489120151371807, 'mean_acc': 0.9758081334723671}\n",
      "Val(y): {'weighted_mean_acc': 0.9655061738247692, 'worst_acc': 0.5257510729613734, 'acc_0_0': 0.9892933618843683, 'acc_0_1': 0.5257510729613734, 'acc_1_0': 0.6992481203007519, 'acc_1_1': 0.9774436090225563, 'mean_acc': 0.7756463719766472}\n",
      " * Acc@1 0.776\n",
      "Test(y): {'weighted_mean_acc': 0.9548214891286007, 'worst_acc': 0.4647450110864745, 'acc_0_0': 0.9827050997782705, 'acc_0_1': 0.4647450110864745, 'acc_1_0': 0.705607476635514, 'acc_1_1': 0.9610591900311527, 'mean_acc': 0.7480151881256473}\n",
      " * Acc@1 0.748\n",
      "Test(spurious): {'weighted_mean_acc': 0.9527246798996076, 'worst_acc': 0.29439252336448596, 'acc_0_0': 0.9827050997782705, 'acc_0_1': 0.5352549889135255, 'acc_1_0': 0.29439252336448596, 'acc_1_1': 0.9610591900311527, 'mean_acc': 0.7298929927511218}\n",
      " * Acc@1 0.730\n",
      "--- Epoch 33 ---\n",
      "Train(y): {'worst_acc': 0.5892857142857143, 'acc_0_0': 0.9954259576901087, 'acc_0_1': 0.8097826086956522, 'acc_1_0': 0.5892857142857143, 'acc_1_1': 0.9470198675496688, 'mean_acc': 0.97288842544317}\n",
      "Val(y): {'weighted_mean_acc': 0.9666749897935826, 'worst_acc': 0.5107296137339056, 'acc_0_0': 0.9892933618843683, 'acc_0_1': 0.5107296137339056, 'acc_1_0': 0.706766917293233, 'acc_1_1': 0.9849624060150376, 'mean_acc': 0.7714762301918265}\n",
      " * Acc@1 0.771\n",
      "Test(y): {'weighted_mean_acc': 0.9541417990224609, 'worst_acc': 0.4549889135254989, 'acc_0_0': 0.9822616407982262, 'acc_0_1': 0.4549889135254989, 'acc_1_0': 0.7071651090342679, 'acc_1_1': 0.9610591900311527, 'mean_acc': 0.744218156713842}\n",
      " * Acc@1 0.744\n",
      "Test(spurious): {'weighted_mean_acc': 0.9527573545821738, 'worst_acc': 0.29283489096573206, 'acc_0_0': 0.9822616407982262, 'acc_0_1': 0.5450110864745011, 'acc_1_0': 0.29283489096573206, 'acc_1_1': 0.9610591900311527, 'mean_acc': 0.7333448394891267}\n",
      " * Acc@1 0.733\n",
      "--- Epoch 34 ---\n",
      "Train(y): {'worst_acc': 0.5714285714285714, 'acc_0_0': 0.9968553459119497, 'acc_0_1': 0.7717391304347826, 'acc_1_0': 0.5714285714285714, 'acc_1_1': 0.9413434247871334, 'mean_acc': 0.9710114702815432}\n",
      "Val(y): {'weighted_mean_acc': 0.9627327535382877, 'worst_acc': 0.4871244635193133, 'acc_0_0': 0.9850107066381156, 'acc_0_1': 0.4871244635193133, 'acc_1_0': 0.7142857142857143, 'acc_1_1': 0.9849624060150376, 'mean_acc': 0.7614678899082569}\n",
      " * Acc@1 0.761\n",
      "Test(y): {'weighted_mean_acc': 0.9536328633624229, 'worst_acc': 0.4354767184035477, 'acc_0_0': 0.9813747228381374, 'acc_0_1': 0.4354767184035477, 'acc_1_0': 0.7242990654205608, 'acc_1_1': 0.9641744548286605, 'mean_acc': 0.7385226095961339}\n",
      " * Acc@1 0.739\n",
      "Test(spurious): {'weighted_mean_acc': 0.9533457046214597, 'worst_acc': 0.2757009345794392, 'acc_0_0': 0.9813747228381374, 'acc_0_1': 0.5645232815964524, 'acc_1_0': 0.2757009345794392, 'acc_1_1': 0.9641744548286605, 'mean_acc': 0.7390403866068347}\n",
      " * Acc@1 0.739\n",
      "--- Epoch 35 ---\n",
      "Train(y): {'worst_acc': 0.48214285714285715, 'acc_0_0': 0.9954259576901087, 'acc_0_1': 0.7608695652173914, 'acc_1_0': 0.48214285714285715, 'acc_1_1': 0.9470198675496688, 'mean_acc': 0.9697601668404588}\n",
      "Val(y): {'weighted_mean_acc': 0.9642125270661994, 'worst_acc': 0.48497854077253216, 'acc_0_0': 0.987152034261242, 'acc_0_1': 0.48497854077253216, 'acc_1_0': 0.7142857142857143, 'acc_1_1': 0.9849624060150376, 'mean_acc': 0.7614678899082569}\n",
      " * Acc@1 0.761\n",
      "Test(y): {'weighted_mean_acc': 0.953199719762268, 'worst_acc': 0.43503325942350335, 'acc_0_0': 0.9813747228381374, 'acc_0_1': 0.43503325942350335, 'acc_1_0': 0.7180685358255452, 'acc_1_1': 0.9626168224299065, 'mean_acc': 0.7374870555747325}\n",
      " * Acc@1 0.737\n",
      "Test(spurious): {'weighted_mean_acc': 0.9530921256084167, 'worst_acc': 0.2819314641744548, 'acc_0_0': 0.9813747228381374, 'acc_0_1': 0.5649667405764967, 'acc_1_0': 0.2819314641744548, 'acc_1_1': 0.9626168224299065, 'mean_acc': 0.7397307559544356}\n",
      " * Acc@1 0.740\n",
      "--- Epoch 36 ---\n",
      "Train(y): {'worst_acc': 0.5357142857142857, 'acc_0_0': 0.9951400800457404, 'acc_0_1': 0.7282608695652174, 'acc_1_0': 0.5357142857142857, 'acc_1_1': 0.9318826868495743, 'mean_acc': 0.9655891553701773}\n",
      "Val(y): {'weighted_mean_acc': 0.9665048328782241, 'worst_acc': 0.5085836909871244, 'acc_0_0': 0.9892933618843683, 'acc_0_1': 0.5085836909871244, 'acc_1_0': 0.6992481203007519, 'acc_1_1': 0.9849624060150376, 'mean_acc': 0.7698081734778982}\n",
      " * Acc@1 0.770\n",
      "Test(y): {'weighted_mean_acc': 0.9564754103406562, 'worst_acc': 0.4647450110864745, 'acc_0_0': 0.9849223946784922, 'acc_0_1': 0.4647450110864745, 'acc_1_0': 0.7087227414330218, 'acc_1_1': 0.9610591900311527, 'mean_acc': 0.749223334483949}\n",
      " * Acc@1 0.749\n",
      "Test(spurious): {'weighted_mean_acc': 0.9543058358054214, 'worst_acc': 0.29127725856697817, 'acc_0_0': 0.9849223946784922, 'acc_0_1': 0.5352549889135255, 'acc_1_0': 0.29127725856697817, 'acc_1_1': 0.9610591900311527, 'mean_acc': 0.7304107697618226}\n",
      " * Acc@1 0.730\n",
      "--- Epoch 37 ---\n",
      "Train(y): {'worst_acc': 0.6428571428571429, 'acc_0_0': 0.9962835906232133, 'acc_0_1': 0.7608695652173914, 'acc_1_0': 0.6428571428571429, 'acc_1_1': 0.9460737937559129, 'mean_acc': 0.9720542231491136}\n",
      "Val(y): {'weighted_mean_acc': 0.9658086593485429, 'worst_acc': 0.5836909871244635, 'acc_0_0': 0.9892933618843683, 'acc_0_1': 0.5836909871244635, 'acc_1_0': 0.6766917293233082, 'acc_1_1': 0.9699248120300752, 'mean_acc': 0.7948290241868223}\n",
      " * Acc@1 0.795\n",
      "Test(y): {'weighted_mean_acc': 0.9574875415162926, 'worst_acc': 0.5303769401330377, 'acc_0_0': 0.985809312638581, 'acc_0_1': 0.5303769401330377, 'acc_1_0': 0.6713395638629284, 'acc_1_1': 0.9532710280373832, 'mean_acc': 0.7701070072488782}\n",
      " * Acc@1 0.770\n",
      "Test(spurious): {'weighted_mean_acc': 0.9511541224109427, 'worst_acc': 0.32866043613707163, 'acc_0_0': 0.985809312638581, 'acc_0_1': 0.4696230598669623, 'acc_1_0': 0.32866043613707163, 'acc_1_1': 0.9532710280373832, 'mean_acc': 0.7084915429754919}\n",
      " * Acc@1 0.708\n",
      "--- Epoch 38 ---\n",
      "Train(y): {'worst_acc': 0.6071428571428571, 'acc_0_0': 0.9977129788450543, 'acc_0_1': 0.7663043478260869, 'acc_1_0': 0.6071428571428571, 'acc_1_1': 0.9526963103122044, 'mean_acc': 0.9743482794577685}\n",
      "Val(y): {'weighted_mean_acc': 0.9705710916417889, 'worst_acc': 0.6015037593984962, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.6974248927038627, 'acc_1_0': 0.6015037593984962, 'acc_1_1': 0.9473684210526315, 'mean_acc': 0.8315262718932444}\n",
      " * Acc@1 0.832\n",
      "Test(y): {'weighted_mean_acc': 0.9645327151396057, 'worst_acc': 0.5825545171339563, 'acc_0_0': 0.9933481152993349, 'acc_0_1': 0.660310421286031, 'acc_1_0': 0.5825545171339563, 'acc_1_1': 0.942367601246106, 'mean_acc': 0.8125647221263376}\n",
      " * Acc@1 0.813\n",
      "Test(spurious): {'weighted_mean_acc': 0.950301152695999, 'worst_acc': 0.33968957871396893, 'acc_0_0': 0.9933481152993349, 'acc_0_1': 0.33968957871396893, 'acc_1_0': 0.4174454828660436, 'acc_1_1': 0.942367601246106, 'mean_acc': 0.6694856748360373}\n",
      " * Acc@1 0.669\n",
      "--- Epoch 39 ---\n",
      "Train(y): {'worst_acc': 0.6428571428571429, 'acc_0_0': 0.9977129788450543, 'acc_0_1': 0.7608695652173914, 'acc_1_0': 0.6428571428571429, 'acc_1_1': 0.9517502365184485, 'mean_acc': 0.9743482794577685}\n",
      "Val(y): {'weighted_mean_acc': 0.9709231356371817, 'worst_acc': 0.5338345864661654, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7703862660944206, 'acc_1_0': 0.5338345864661654, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8515429524603837}\n",
      " * Acc@1 0.852\n",
      "Test(y): {'weighted_mean_acc': 0.9660256061684633, 'worst_acc': 0.5280373831775701, 'acc_0_0': 0.9946784922394678, 'acc_0_1': 0.7352549889135255, 'acc_1_0': 0.5280373831775701, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8353469105971695}\n",
      " * Acc@1 0.835\n",
      "Test(spurious): {'weighted_mean_acc': 0.9473156948718728, 'worst_acc': 0.2647450110864745, 'acc_0_0': 0.9946784922394678, 'acc_0_1': 0.2647450110864745, 'acc_1_0': 0.4719626168224299, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6460131170176044}\n",
      " * Acc@1 0.646\n",
      "--- Epoch 40 ---\n",
      "Train(y): {'worst_acc': 0.625, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8043478260869565, 'acc_1_0': 0.625, 'acc_1_1': 0.9460737937559129, 'mean_acc': 0.9751824817518249}\n",
      "Val(y): {'weighted_mean_acc': 0.9716142685393595, 'worst_acc': 0.5639097744360902, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7360515021459227, 'acc_1_0': 0.5639097744360902, 'acc_1_1': 0.9473684210526315, 'mean_acc': 0.8423686405337781}\n",
      " * Acc@1 0.842\n",
      "Test(y): {'weighted_mean_acc': 0.9663426607528249, 'worst_acc': 0.5716510903426791, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7028824833702882, 'acc_1_0': 0.5716510903426791, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.8280980324473594}\n",
      " * Acc@1 0.828\n",
      "Test(spurious): {'weighted_mean_acc': 0.9490985153167293, 'worst_acc': 0.29711751662971175, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.29711751662971175, 'acc_1_0': 0.42834890965732086, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.654297549188816}\n",
      " * Acc@1 0.654\n",
      "--- Epoch 41 ---\n",
      "Train(y): {'worst_acc': 0.6428571428571429, 'acc_0_0': 0.9979988564894225, 'acc_0_1': 0.7880434782608695, 'acc_1_0': 0.6428571428571429, 'acc_1_1': 0.9489120151371807, 'mean_acc': 0.9749739311783108}\n",
      "Val(y): {'weighted_mean_acc': 0.9709059408592661, 'worst_acc': 0.6090225563909775, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.703862660944206, 'acc_1_0': 0.6090225563909775, 'acc_1_1': 0.9473684210526315, 'mean_acc': 0.8348623853211009}\n",
      " * Acc@1 0.835\n",
      "Test(y): {'weighted_mean_acc': 0.9637817505710784, 'worst_acc': 0.5841121495327103, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.6660753880266075, 'acc_1_0': 0.5841121495327103, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.8144632378322403}\n",
      " * Acc@1 0.814\n",
      "Test(spurious): {'weighted_mean_acc': 0.9490713638041803, 'worst_acc': 0.33392461197339246, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.33392461197339246, 'acc_1_0': 0.4158878504672897, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.6665516051087331}\n",
      " * Acc@1 0.667\n",
      "--- Epoch 42 ---\n",
      "Train(y): {'worst_acc': 0.6428571428571429, 'acc_0_0': 0.9974271012006861, 'acc_0_1': 0.782608695652174, 'acc_1_0': 0.6428571428571429, 'acc_1_1': 0.9508041627246925, 'mean_acc': 0.9747653806047967}\n",
      "Val(y): {'weighted_mean_acc': 0.9710714340995801, 'worst_acc': 0.5112781954887218, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7811158798283262, 'acc_1_0': 0.5112781954887218, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8532110091743119}\n",
      " * Acc@1 0.853\n",
      "Test(y): {'weighted_mean_acc': 0.9661516744711859, 'worst_acc': 0.5186915887850467, 'acc_0_0': 0.9946784922394678, 'acc_0_1': 0.7503325942350333, 'acc_1_0': 0.5186915887850467, 'acc_1_1': 0.9330218068535826, 'mean_acc': 0.840006903693476}\n",
      " * Acc@1 0.840\n",
      "Test(spurious): {'weighted_mean_acc': 0.9465029039559522, 'worst_acc': 0.24966740576496674, 'acc_0_0': 0.9946784922394678, 'acc_0_1': 0.24966740576496674, 'acc_1_0': 0.48130841121495327, 'acc_1_1': 0.9330218068535826, 'mean_acc': 0.6410079392474974}\n",
      " * Acc@1 0.641\n",
      "--- Epoch 43 ---\n",
      "Train(y): {'worst_acc': 0.625, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.7771739130434783, 'acc_1_0': 0.625, 'acc_1_1': 0.9517502365184485, 'mean_acc': 0.9753910323253389}\n",
      "Val(y): {'weighted_mean_acc': 0.9710000171750008, 'worst_acc': 0.5263157894736842, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7746781115879828, 'acc_1_0': 0.5263157894736842, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8523769808173478}\n",
      " * Acc@1 0.852\n",
      "Test(y): {'weighted_mean_acc': 0.9654473451043871, 'worst_acc': 0.5327102803738317, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7361419068736141, 'acc_1_0': 0.5327102803738317, 'acc_1_1': 0.9330218068535826, 'mean_acc': 0.8358646876078702}\n",
      " * Acc@1 0.836\n",
      "Test(spurious): {'weighted_mean_acc': 0.9465602178991771, 'worst_acc': 0.2638580931263858, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2638580931263858, 'acc_1_0': 0.4672897196261682, 'acc_1_1': 0.9330218068535826, 'mean_acc': 0.6448049706593028}\n",
      " * Acc@1 0.645\n",
      "--- Epoch 44 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.9977129788450543, 'acc_0_1': 0.8043478260869565, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9470198675496688, 'mean_acc': 0.9751824817518249}\n",
      "Val(y): {'weighted_mean_acc': 0.970895011632786, 'worst_acc': 0.5939849624060151, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7081545064377682, 'acc_1_0': 0.5939849624060151, 'acc_1_1': 0.9473684210526315, 'mean_acc': 0.8348623853211009}\n",
      " * Acc@1 0.835\n",
      "Test(y): {'weighted_mean_acc': 0.9645306829657215, 'worst_acc': 0.5841121495327103, 'acc_0_0': 0.9929046563192905, 'acc_0_1': 0.6771618625277162, 'acc_1_0': 0.5841121495327103, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.8189506385916465}\n",
      " * Acc@1 0.819\n",
      "Test(spurious): {'weighted_mean_acc': 0.9489694468331112, 'worst_acc': 0.3228381374722838, 'acc_0_0': 0.9929046563192905, 'acc_0_1': 0.3228381374722838, 'acc_1_0': 0.4158878504672897, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.6624093890231274}\n",
      " * Acc@1 0.662\n",
      "--- Epoch 45 ---\n",
      "Train(y): {'worst_acc': 0.6071428571428571, 'acc_0_0': 0.9979988564894225, 'acc_0_1': 0.8152173913043478, 'acc_1_0': 0.6071428571428571, 'acc_1_1': 0.9508041627246925, 'mean_acc': 0.9760166840458812}\n",
      "Val(y): {'weighted_mean_acc': 0.9697098018242527, 'worst_acc': 0.5639097744360902, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7296137339055794, 'acc_1_0': 0.5639097744360902, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8390325271059216}\n",
      " * Acc@1 0.839\n",
      "Test(y): {'weighted_mean_acc': 0.9654070429551497, 'worst_acc': 0.5763239875389408, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.6944567627494457, 'acc_1_0': 0.5763239875389408, 'acc_1_1': 0.9392523364485982, 'mean_acc': 0.824991370383155}\n",
      " * Acc@1 0.825\n",
      "Test(spurious): {'weighted_mean_acc': 0.9487003950776328, 'worst_acc': 0.3055432372505543, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.3055432372505543, 'acc_1_0': 0.4236760124610592, 'acc_1_1': 0.9392523364485982, 'mean_acc': 0.6567138419054194}\n",
      " * Acc@1 0.657\n",
      "--- Epoch 46 ---\n",
      "Train(y): {'worst_acc': 0.625, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8206521739130435, 'acc_1_0': 0.625, 'acc_1_1': 0.9508041627246925, 'mean_acc': 0.9768508863399374}\n",
      "Val(y): {'weighted_mean_acc': 0.9698854233528511, 'worst_acc': 0.5789473684210527, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7296137339055794, 'acc_1_0': 0.5789473684210527, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8407005838198499}\n",
      " * Acc@1 0.841\n",
      "Test(y): {'weighted_mean_acc': 0.9652345244035149, 'worst_acc': 0.573208722741433, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.6909090909090909, 'acc_1_0': 0.573208722741433, 'acc_1_1': 0.9392523364485982, 'mean_acc': 0.8232654470141526}\n",
      " * Acc@1 0.823\n",
      "Test(spurious): {'weighted_mean_acc': 0.9488729136292676, 'worst_acc': 0.3090909090909091, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.3090909090909091, 'acc_1_0': 0.42679127725856697, 'acc_1_1': 0.9392523364485982, 'mean_acc': 0.6584397652744218}\n",
      " * Acc@1 0.658\n",
      "--- Epoch 47 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.9982847341337907, 'acc_0_1': 0.7989130434782609, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9508041627246925, 'mean_acc': 0.9762252346193953}\n",
      "Val(y): {'weighted_mean_acc': 0.9687194488709429, 'worst_acc': 0.6240601503759399, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.6373390557939914, 'acc_1_0': 0.6240601503759399, 'acc_1_1': 0.9624060150375939, 'mean_acc': 0.810675562969141}\n",
      " * Acc@1 0.811\n",
      "Test(y): {'weighted_mean_acc': 0.9607283319503221, 'worst_acc': 0.5964523281596452, 'acc_0_0': 0.9893569844789357, 'acc_0_1': 0.5964523281596452, 'acc_1_0': 0.6277258566978193, 'acc_1_1': 0.9470404984423676, 'mean_acc': 0.7916810493614084}\n",
      " * Acc@1 0.792\n",
      "Test(spurious): {'weighted_mean_acc': 0.950342564912712, 'worst_acc': 0.37227414330218067, 'acc_0_0': 0.9893569844789357, 'acc_0_1': 0.4035476718403548, 'acc_1_0': 0.37227414330218067, 'acc_1_1': 0.9470404984423676, 'mean_acc': 0.6882982395581636}\n",
      " * Acc@1 0.688\n",
      "--- Epoch 48 ---\n",
      "Train(y): {'worst_acc': 0.6428571428571429, 'acc_0_0': 0.9982847341337907, 'acc_0_1': 0.7989130434782609, 'acc_1_0': 0.6428571428571429, 'acc_1_1': 0.9526963103122044, 'mean_acc': 0.9764337851929092}\n",
      "Val(y): {'weighted_mean_acc': 0.9681064297738075, 'worst_acc': 0.6051502145922747, 'acc_0_0': 0.9914346895074947, 'acc_0_1': 0.6051502145922747, 'acc_1_0': 0.6691729323308271, 'acc_1_1': 0.9699248120300752, 'mean_acc': 0.8031693077564637}\n",
      " * Acc@1 0.803\n",
      "Test(y): {'weighted_mean_acc': 0.9590030961747146, 'worst_acc': 0.5450110864745011, 'acc_0_0': 0.9866962305986696, 'acc_0_1': 0.5450110864745011, 'acc_1_0': 0.6682242990654206, 'acc_1_1': 0.9548286604361371, 'mean_acc': 0.7759751467034863}\n",
      " * Acc@1 0.776\n",
      "Test(spurious): {'weighted_mean_acc': 0.9516193212128662, 'worst_acc': 0.3317757009345794, 'acc_0_0': 0.9866962305986696, 'acc_0_1': 0.4549889135254989, 'acc_1_0': 0.3317757009345794, 'acc_1_1': 0.9548286604361371, 'mean_acc': 0.7036589575422851}\n",
      " * Acc@1 0.704\n",
      "--- Epoch 49 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.9971412235563178, 'acc_0_1': 0.7663043478260869, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9498580889309366, 'mean_acc': 0.9739311783107404}\n",
      "Val(y): {'weighted_mean_acc': 0.9695374457682957, 'worst_acc': 0.6165413533834586, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.6609442060085837, 'acc_1_0': 0.6165413533834586, 'acc_1_1': 0.9624060150375939, 'mean_acc': 0.8190158465387823}\n",
      " * Acc@1 0.819\n",
      "Test(y): {'weighted_mean_acc': 0.9619573513163644, 'worst_acc': 0.6137071651090342, 'acc_0_0': 0.9902439024390244, 'acc_0_1': 0.6248337028824834, 'acc_1_0': 0.6137071651090342, 'acc_1_1': 0.9454828660436138, 'mean_acc': 0.8013462202278219}\n",
      " * Acc@1 0.801\n",
      "Test(spurious): {'weighted_mean_acc': 0.9497208537806192, 'worst_acc': 0.37516629711751664, 'acc_0_0': 0.9902439024390244, 'acc_0_1': 0.37516629711751664, 'acc_1_0': 0.3862928348909657, 'acc_1_1': 0.9454828660436138, 'mean_acc': 0.6789782533655506}\n",
      " * Acc@1 0.679\n",
      "--- Epoch 50 ---\n",
      "Train(y): {'worst_acc': 0.6428571428571429, 'acc_0_0': 0.9974271012006861, 'acc_0_1': 0.7771739130434783, 'acc_1_0': 0.6428571428571429, 'acc_1_1': 0.9545884578997161, 'mean_acc': 0.9753910323253389}\n",
      "Val(y): {'weighted_mean_acc': 0.970889547019546, 'worst_acc': 0.5864661654135338, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7103004291845494, 'acc_1_0': 0.5864661654135338, 'acc_1_1': 0.9473684210526315, 'mean_acc': 0.8348623853211009}\n",
      " * Acc@1 0.835\n",
      "Test(y): {'weighted_mean_acc': 0.9645465256137895, 'worst_acc': 0.5825545171339563, 'acc_0_0': 0.9929046563192905, 'acc_0_1': 0.6780487804878049, 'acc_1_0': 0.5825545171339563, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.8191232309285468}\n",
      " * Acc@1 0.819\n",
      "Test(spurious): {'weighted_mean_acc': 0.9489536041850433, 'worst_acc': 0.32195121951219513, 'acc_0_0': 0.9929046563192905, 'acc_0_1': 0.32195121951219513, 'acc_1_0': 0.4174454828660436, 'acc_1_1': 0.940809968847352, 'mean_acc': 0.6622367966862271}\n",
      " * Acc@1 0.662\n",
      "--- Epoch 51 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.9982847341337907, 'acc_0_1': 0.8152173913043478, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9517502365184485, 'mean_acc': 0.9770594369134515}\n",
      "Val(y): {'weighted_mean_acc': 0.9698008780611935, 'worst_acc': 0.6390977443609023, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.6609442060085837, 'acc_1_0': 0.6390977443609023, 'acc_1_1': 0.9624060150375939, 'mean_acc': 0.8215179316096747}\n",
      " * Acc@1 0.822\n",
      "Test(y): {'weighted_mean_acc': 0.9612540113359958, 'worst_acc': 0.6186252771618626, 'acc_0_0': 0.9893569844789357, 'acc_0_1': 0.6186252771618626, 'acc_1_0': 0.6292834890965732, 'acc_1_1': 0.9454828660436138, 'mean_acc': 0.8003106662064204}\n",
      " * Acc@1 0.800\n",
      "Test(spurious): {'weighted_mean_acc': 0.9491301629138402, 'worst_acc': 0.3707165109034268, 'acc_0_0': 0.9893569844789357, 'acc_0_1': 0.38137472283813745, 'acc_1_0': 0.3707165109034268, 'acc_1_1': 0.9454828660436138, 'mean_acc': 0.679323438039351}\n",
      " * Acc@1 0.679\n",
      "--- Epoch 52 ---\n",
      "Train(y): {'worst_acc': 0.625, 'acc_0_0': 0.9977129788450543, 'acc_0_1': 0.8097826086956522, 'acc_1_0': 0.625, 'acc_1_1': 0.9545884578997161, 'mean_acc': 0.9766423357664233}\n",
      "Val(y): {'weighted_mean_acc': 0.9706210740991446, 'worst_acc': 0.5714285714285714, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7510729613733905, 'acc_1_0': 0.5714285714285714, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8482068390325271}\n",
      " * Acc@1 0.848\n",
      "Test(y): {'weighted_mean_acc': 0.9658748102962197, 'worst_acc': 0.5685358255451713, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7095343680709535, 'acc_1_0': 0.5685358255451713, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.829996548153262}\n",
      " * Acc@1 0.830\n",
      "Test(spurious): {'weighted_mean_acc': 0.9481929205469385, 'worst_acc': 0.29046563192904656, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.29046563192904656, 'acc_1_0': 0.43146417445482865, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.6517086641353124}\n",
      " * Acc@1 0.652\n",
      "--- Epoch 53 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.9982847341337907, 'acc_0_1': 0.8152173913043478, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9778936392075078}\n",
      "Val(y): {'weighted_mean_acc': 0.9709176710239416, 'worst_acc': 0.5263157894736842, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7725321888412017, 'acc_1_0': 0.5263157894736842, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8515429524603837}\n",
      " * Acc@1 0.852\n",
      "Test(y): {'weighted_mean_acc': 0.9659497309930454, 'worst_acc': 0.5404984423676013, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7379157427937916, 'acc_1_0': 0.5404984423676013, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8375906109768726}\n",
      " * Acc@1 0.838\n",
      "Test(spurious): {'weighted_mean_acc': 0.946744554623717, 'worst_acc': 0.2620842572062084, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2620842572062084, 'acc_1_0': 0.45950155763239875, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6434242319641008}\n",
      " * Acc@1 0.643\n",
      "--- Epoch 54 ---\n",
      "Train(y): {'worst_acc': 0.6785714285714286, 'acc_0_0': 0.9982847341337907, 'acc_0_1': 0.8043478260869565, 'acc_1_0': 0.6785714285714286, 'acc_1_1': 0.9536423841059603, 'mean_acc': 0.9772679874869656}\n",
      "Val(y): {'weighted_mean_acc': 0.9708462540993623, 'worst_acc': 0.5413533834586466, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7660944206008584, 'acc_1_0': 0.5413533834586466, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8507089241034195}\n",
      " * Acc@1 0.851\n",
      "Test(y): {'weighted_mean_acc': 0.9657467014845207, 'worst_acc': 0.5420560747663551, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7321507760532151, 'acc_1_0': 0.5420560747663551, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8355195029340697}\n",
      " * Acc@1 0.836\n",
      "Test(spurious): {'weighted_mean_acc': 0.9469475841322417, 'worst_acc': 0.2678492239467849, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2678492239467849, 'acc_1_0': 0.45794392523364486, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6454953400069037}\n",
      " * Acc@1 0.645\n",
      "--- Epoch 55 ---\n",
      "Train(y): {'worst_acc': 0.6785714285714286, 'acc_0_0': 0.9971412235563178, 'acc_0_1': 0.7934782608695652, 'acc_1_0': 0.6785714285714286, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9764337851929092}\n",
      "Val(y): {'weighted_mean_acc': 0.9712415910149388, 'worst_acc': 0.518796992481203, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7832618025751072, 'acc_1_0': 0.518796992481203, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8548790658882403}\n",
      " * Acc@1 0.855\n",
      "Test(y): {'weighted_mean_acc': 0.9664215092808595, 'worst_acc': 0.5342679127725857, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7521064301552106, 'acc_1_0': 0.5342679127725857, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8424231964100793}\n",
      " * Acc@1 0.842\n",
      "Test(spurious): {'weighted_mean_acc': 0.9462727763359029, 'worst_acc': 0.24789356984478936, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.24789356984478936, 'acc_1_0': 0.4657320872274143, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6385916465308941}\n",
      " * Acc@1 0.639\n",
      "--- Epoch 56 ---\n",
      "Train(y): {'worst_acc': 0.6428571428571429, 'acc_0_0': 0.9977129788450543, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6428571428571429, 'acc_1_1': 0.9517502365184485, 'mean_acc': 0.9770594369134515}\n",
      "Val(y): {'weighted_mean_acc': 0.9713953540905771, 'worst_acc': 0.5037593984962406, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7918454935622318, 'acc_1_0': 0.5037593984962406, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8565471226021685}\n",
      " * Acc@1 0.857\n",
      "Test(y): {'weighted_mean_acc': 0.9657358643629534, 'worst_acc': 0.5171339563862928, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7662971175166298, 'acc_1_0': 0.5171339563862928, 'acc_1_1': 0.9299065420560748, 'mean_acc': 0.8455298584742837}\n",
      " * Acc@1 0.846\n",
      "Test(spurious): {'weighted_mean_acc': 0.944898253414215, 'worst_acc': 0.2337028824833703, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2337028824833703, 'acc_1_0': 0.48286604361370716, 'acc_1_1': 0.9299065420560748, 'mean_acc': 0.6344494304452882}\n",
      " * Acc@1 0.634\n",
      "--- Epoch 57 ---\n",
      "Train(y): {'worst_acc': 0.6428571428571429, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8152173913043478, 'acc_1_0': 0.6428571428571429, 'acc_1_1': 0.9536423841059603, 'mean_acc': 0.9774765380604796}\n",
      "Val(y): {'weighted_mean_acc': 0.970763907948303, 'worst_acc': 0.5413533834586466, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7639484978540773, 'acc_1_0': 0.5413533834586466, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8498748957464554}\n",
      " * Acc@1 0.850\n",
      "Test(y): {'weighted_mean_acc': 0.9656358029480443, 'worst_acc': 0.5529595015576324, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7259423503325942, 'acc_1_0': 0.5529595015576324, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.834311356575768}\n",
      " * Acc@1 0.834\n",
      "Test(spurious): {'weighted_mean_acc': 0.9470584826687178, 'worst_acc': 0.27405764966740576, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.27405764966740576, 'acc_1_0': 0.4470404984423676, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6467034863652054}\n",
      " * Acc@1 0.647\n",
      "--- Epoch 58 ---\n",
      "Train(y): {'worst_acc': 0.6785714285714286, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8097826086956522, 'acc_1_0': 0.6785714285714286, 'acc_1_1': 0.9545884578997161, 'mean_acc': 0.9778936392075078}\n",
      "Val(y): {'weighted_mean_acc': 0.9708571833258424, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7618025751072961, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8507089241034195}\n",
      " * Acc@1 0.851\n",
      "Test(y): {'weighted_mean_acc': 0.9653318458548803, 'worst_acc': 0.5560747663551402, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7170731707317073, 'acc_1_0': 0.5560747663551402, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8312046945115636}\n",
      " * Acc@1 0.831\n",
      "Test(spurious): {'weighted_mean_acc': 0.9473624397618818, 'worst_acc': 0.28292682926829266, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.28292682926829266, 'acc_1_0': 0.4439252336448598, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6498101484294098}\n",
      " * Acc@1 0.650\n",
      "--- Epoch 59 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8152173913043478, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9781021897810219}\n",
      "Val(y): {'weighted_mean_acc': 0.9706101448726647, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7553648068669528, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8482068390325271}\n",
      " * Acc@1 0.848\n",
      "Test(y): {'weighted_mean_acc': 0.965642347526097, 'worst_acc': 0.557632398753894, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7157427937915742, 'acc_1_0': 0.557632398753894, 'acc_1_1': 0.9361370716510904, 'mean_acc': 0.8310321021746634}\n",
      " * Acc@1 0.831\n",
      "Test(spurious): {'weighted_mean_acc': 0.9477386607038633, 'worst_acc': 0.2842572062084257, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2842572062084257, 'acc_1_0': 0.4423676012461059, 'acc_1_1': 0.9361370716510904, 'mean_acc': 0.6503279254401104}\n",
      " * Acc@1 0.650\n",
      "--- Epoch 60 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.9971412235563178, 'acc_0_1': 0.7989130434782609, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9545884578997161, 'mean_acc': 0.9762252346193953}\n",
      "Val(y): {'weighted_mean_acc': 0.9710714340995801, 'worst_acc': 0.5112781954887218, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7811158798283262, 'acc_1_0': 0.5112781954887218, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8532110091743119}\n",
      " * Acc@1 0.853\n",
      "Test(y): {'weighted_mean_acc': 0.9663997949365604, 'worst_acc': 0.5280373831775701, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7534368070953437, 'acc_1_0': 0.5280373831775701, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8422506040731792}\n",
      " * Acc@1 0.842\n",
      "Test(spurious): {'weighted_mean_acc': 0.9462944906802018, 'worst_acc': 0.2465631929046563, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2465631929046563, 'acc_1_0': 0.4719626168224299, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6387642388677943}\n",
      " * Acc@1 0.639\n",
      "--- Epoch 61 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.9988564894225271, 'acc_0_1': 0.842391304347826, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9517502365184485, 'mean_acc': 0.97851929092805}\n",
      "Val(y): {'weighted_mean_acc': 0.9700555802682098, 'worst_acc': 0.5864661654135338, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7317596566523605, 'acc_1_0': 0.5864661654135338, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8423686405337781}\n",
      " * Acc@1 0.842\n",
      "Test(y): {'weighted_mean_acc': 0.9642516816378246, 'worst_acc': 0.5794392523364486, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.6886917960088692, 'acc_1_0': 0.5794392523364486, 'acc_1_1': 0.9392523364485982, 'mean_acc': 0.8225750776665516}\n",
      " * Acc@1 0.823\n",
      "Test(spurious): {'weighted_mean_acc': 0.9479147101242362, 'worst_acc': 0.3113082039911308, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.3113082039911308, 'acc_1_0': 0.4205607476635514, 'acc_1_1': 0.9392523364485982, 'mean_acc': 0.6580945806006213}\n",
      " * Acc@1 0.658\n",
      "--- Epoch 62 ---\n",
      "Train(y): {'worst_acc': 0.6785714285714286, 'acc_0_0': 0.9979988564894225, 'acc_0_1': 0.7934782608695652, 'acc_1_0': 0.6785714285714286, 'acc_1_1': 0.9612109744560076, 'mean_acc': 0.978310740354536}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.965487347419201, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7201773835920178, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8327580255436658}\n",
      " * Acc@1 0.833\n",
      "Test(spurious): {'weighted_mean_acc': 0.9472069381975614, 'worst_acc': 0.2798226164079823, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2798226164079823, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6482568173973076}\n",
      " * Acc@1 0.648\n",
      "--- Epoch 63 ---\n",
      "Train(y): {'worst_acc': 0.6428571428571429, 'acc_0_0': 0.9988564894225271, 'acc_0_1': 0.8369565217391305, 'acc_1_0': 0.6428571428571429, 'acc_1_1': 0.9508041627246925, 'mean_acc': 0.9778936392075078}\n",
      "Val(y): {'weighted_mean_acc': 0.9708517187126025, 'worst_acc': 0.5488721804511278, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7639484978540773, 'acc_1_0': 0.5488721804511278, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8507089241034195}\n",
      " * Acc@1 0.851\n",
      "Test(y): {'weighted_mean_acc': 0.965701522218809, 'worst_acc': 0.5498442367601246, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7286031042128603, 'acc_1_0': 0.5498442367601246, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.835001725923369}\n",
      " * Acc@1 0.835\n",
      "Test(spurious): {'weighted_mean_acc': 0.9469927633979534, 'worst_acc': 0.2713968957871397, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2713968957871397, 'acc_1_0': 0.4501557632398754, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6460131170176044}\n",
      " * Acc@1 0.646\n",
      "--- Epoch 64 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8206521739130435, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.956480605487228, 'mean_acc': 0.97851929092805}\n",
      "Val(y): {'weighted_mean_acc': 0.970456381797026, 'worst_acc': 0.5714285714285714, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7467811158798283, 'acc_1_0': 0.5714285714285714, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8465387823185988}\n",
      " * Acc@1 0.847\n",
      "Test(y): {'weighted_mean_acc': 0.9653435757189232, 'worst_acc': 0.5638629283489096, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.7055432372505543, 'acc_1_0': 0.5638629283489096, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.8277528477735588}\n",
      " * Acc@1 0.828\n",
      "Test(spurious): {'weighted_mean_acc': 0.9480771397006612, 'worst_acc': 0.29445676274944566, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.29445676274944566, 'acc_1_0': 0.43613707165109034, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.6536071798412151}\n",
      " * Acc@1 0.654\n",
      "--- Epoch 65 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.9982847341337907, 'acc_0_1': 0.8043478260869565, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9612109744560076, 'mean_acc': 0.9787278415015641}\n",
      "Val(y): {'weighted_mean_acc': 0.9708517187126025, 'worst_acc': 0.5488721804511278, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7639484978540773, 'acc_1_0': 0.5488721804511278, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8507089241034195}\n",
      " * Acc@1 0.851\n",
      "Test(y): {'weighted_mean_acc': 0.9656698369226728, 'worst_acc': 0.5529595015576324, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7268292682926829, 'acc_1_0': 0.5529595015576324, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8346565412495686}\n",
      " * Acc@1 0.835\n",
      "Test(spurious): {'weighted_mean_acc': 0.9470244486940895, 'worst_acc': 0.2731707317073171, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2731707317073171, 'acc_1_0': 0.4470404984423676, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6463583016914048}\n",
      " * Acc@1 0.646\n",
      "--- Epoch 66 ---\n",
      "Train(y): {'worst_acc': 0.6428571428571429, 'acc_0_0': 0.9988564894225271, 'acc_0_1': 0.8695652173913043, 'acc_1_0': 0.6428571428571429, 'acc_1_1': 0.9422894985808893, 'mean_acc': 0.9772679874869656}\n",
      "Val(y): {'weighted_mean_acc': 0.9705277987216054, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7532188841201717, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8473728106755629}\n",
      " * Acc@1 0.847\n",
      "Test(y): {'weighted_mean_acc': 0.9659199895619314, 'worst_acc': 0.5607476635514018, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7130820399113083, 'acc_1_0': 0.5607476635514018, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.8305143251639627}\n",
      " * Acc@1 0.831\n",
      "Test(spurious): {'weighted_mean_acc': 0.9481477412812268, 'worst_acc': 0.2869179600886918, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2869179600886918, 'acc_1_0': 0.4392523364485981, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.6511908871246117}\n",
      " * Acc@1 0.651\n",
      "--- Epoch 67 ---\n",
      "Train(y): {'worst_acc': 0.6785714285714286, 'acc_0_0': 0.9974271012006861, 'acc_0_1': 0.7880434782608695, 'acc_1_0': 0.6785714285714286, 'acc_1_1': 0.9612109744560076, 'mean_acc': 0.9776850886339937}\n",
      "Val(y): {'weighted_mean_acc': 0.9702916894949074, 'worst_acc': 0.5714285714285714, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7424892703862661, 'acc_1_0': 0.5714285714285714, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8448707256046706}\n",
      " * Acc@1 0.845\n",
      "Test(y): {'weighted_mean_acc': 0.9644947051260708, 'worst_acc': 0.5669781931464174, 'acc_0_0': 0.9929046563192905, 'acc_0_1': 0.6993348115299335, 'acc_1_0': 0.5669781931464174, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.8253365550569555}\n",
      " * Acc@1 0.825\n",
      "Test(spurious): {'weighted_mean_acc': 0.9476319794463659, 'worst_acc': 0.3006651884700665, 'acc_0_0': 0.9929046563192905, 'acc_0_1': 0.3006651884700665, 'acc_1_0': 0.43302180685358255, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.6553331032102174}\n",
      " * Acc@1 0.655\n",
      "--- Epoch 68 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.9988564894225271, 'acc_0_1': 0.8369565217391305, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9498580889309366, 'mean_acc': 0.9778936392075078}\n",
      "Val(y): {'weighted_mean_acc': 0.9709340648636617, 'worst_acc': 0.5488721804511278, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7660944206008584, 'acc_1_0': 0.5488721804511278, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8515429524603837}\n",
      " * Acc@1 0.852\n",
      "Test(y): {'weighted_mean_acc': 0.9657830841376416, 'worst_acc': 0.5451713395638629, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7321507760532151, 'acc_1_0': 0.5451713395638629, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8358646876078702}\n",
      " * Acc@1 0.836\n",
      "Test(spurious): {'weighted_mean_acc': 0.9469112014791208, 'worst_acc': 0.2678492239467849, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2678492239467849, 'acc_1_0': 0.45482866043613707, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6451501553331032}\n",
      " * Acc@1 0.645\n",
      "--- Epoch 69 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.9982847341337907, 'acc_0_1': 0.8097826086956522, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9593188268684958, 'mean_acc': 0.97851929092805}\n",
      "Val(y): {'weighted_mean_acc': 0.9701379264192691, 'worst_acc': 0.5864661654135338, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7339055793991416, 'acc_1_0': 0.5864661654135338, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8432026688907422}\n",
      " * Acc@1 0.843\n",
      "Test(y): {'weighted_mean_acc': 0.9640239162246866, 'worst_acc': 0.5747663551401869, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.6931263858093126, 'acc_1_0': 0.5747663551401869, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.823610631687953}\n",
      " * Acc@1 0.824\n",
      "Test(spurious): {'weighted_mean_acc': 0.947455752924176, 'worst_acc': 0.30687361419068737, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.30687361419068737, 'acc_1_0': 0.4252336448598131, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.6567138419054194}\n",
      " * Acc@1 0.657\n",
      "--- Epoch 70 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8097826086956522, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9778936392075078}\n",
      "Val(y): {'weighted_mean_acc': 0.9707693725615432, 'worst_acc': 0.5488721804511278, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7618025751072961, 'acc_1_0': 0.5488721804511278, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8498748957464554}\n",
      " * Acc@1 0.850\n",
      "Test(y): {'weighted_mean_acc': 0.9657402535504223, 'worst_acc': 0.5560747663551402, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7277161862527716, 'acc_1_0': 0.5560747663551402, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8353469105971695}\n",
      " * Acc@1 0.835\n",
      "Test(spurious): {'weighted_mean_acc': 0.9469540320663401, 'worst_acc': 0.2722838137472284, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2722838137472284, 'acc_1_0': 0.4439252336448598, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6456679323438039}\n",
      " * Acc@1 0.646\n",
      "--- Epoch 71 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8369565217391305, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9536423841059603, 'mean_acc': 0.97851929092805}\n",
      "Val(y): {'weighted_mean_acc': 0.9706156094859046, 'worst_acc': 0.5639097744360902, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7532188841201717, 'acc_1_0': 0.5639097744360902, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8482068390325271}\n",
      " * Acc@1 0.848\n",
      "Test(y): {'weighted_mean_acc': 0.9651380125790898, 'worst_acc': 0.5623052959501558, 'acc_0_0': 0.9933481152993349, 'acc_0_1': 0.7090909090909091, 'acc_1_0': 0.5623052959501558, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.8287884017949603}\n",
      " * Acc@1 0.829\n",
      "Test(spurious): {'weighted_mean_acc': 0.9476356874169207, 'worst_acc': 0.2909090909090909, 'acc_0_0': 0.9933481152993349, 'acc_0_1': 0.2909090909090909, 'acc_1_0': 0.43769470404984423, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.6522264411460131}\n",
      " * Acc@1 0.652\n",
      "--- Epoch 72 ---\n",
      "Train(y): {'worst_acc': 0.6785714285714286, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8152173913043478, 'acc_1_0': 0.6785714285714286, 'acc_1_1': 0.9593188268684958, 'mean_acc': 0.9791449426485923}\n",
      "Val(y): {'weighted_mean_acc': 0.9706101448726647, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7553648068669528, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8482068390325271}\n",
      " * Acc@1 0.848\n",
      "Test(y): {'weighted_mean_acc': 0.9653864198345616, 'worst_acc': 0.5607476635514018, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7170731707317073, 'acc_1_0': 0.5607476635514018, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8317224715222644}\n",
      " * Acc@1 0.832\n",
      "Test(spurious): {'weighted_mean_acc': 0.9473078657822005, 'worst_acc': 0.28292682926829266, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.28292682926829266, 'acc_1_0': 0.4392523364485981, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.649292371418709}\n",
      " * Acc@1 0.649\n",
      "--- Epoch 73 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.9988564894225271, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9545884578997161, 'mean_acc': 0.9787278415015641}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.9655213813938295, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7210643015521064, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8331032102174664}\n",
      " * Acc@1 0.833\n",
      "Test(spurious): {'weighted_mean_acc': 0.9471729042229329, 'worst_acc': 0.27893569844789357, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.27893569844789357, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.647911632723507}\n",
      " * Acc@1 0.648\n",
      "--- Epoch 74 ---\n",
      "Train(y): {'worst_acc': 0.6785714285714286, 'acc_0_0': 0.9977129788450543, 'acc_0_1': 0.782608695652174, 'acc_1_0': 0.6785714285714286, 'acc_1_1': 0.9602649006622517, 'mean_acc': 0.9774765380604796}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.9655043644065151, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.720620842572062, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8329306178805661}\n",
      " * Acc@1 0.833\n",
      "Test(spurious): {'weighted_mean_acc': 0.947189921210247, 'worst_acc': 0.2793791574279379, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2793791574279379, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6480842250604073}\n",
      " * Acc@1 0.648\n",
      "--- Epoch 75 ---\n",
      "Train(y): {'worst_acc': 0.6428571428571429, 'acc_0_0': 0.9988564894225271, 'acc_0_1': 0.8478260869565217, 'acc_1_0': 0.6428571428571429, 'acc_1_1': 0.9508041627246925, 'mean_acc': 0.978310740354536}\n",
      "Val(y): {'weighted_mean_acc': 0.9708517187126025, 'worst_acc': 0.5488721804511278, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7639484978540773, 'acc_1_0': 0.5488721804511278, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8507089241034195}\n",
      " * Acc@1 0.851\n",
      "Test(y): {'weighted_mean_acc': 0.965791304512365, 'worst_acc': 0.5560747663551402, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7290465631929046, 'acc_1_0': 0.5560747663551402, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8358646876078702}\n",
      " * Acc@1 0.836\n",
      "Test(spurious): {'weighted_mean_acc': 0.9469029811043974, 'worst_acc': 0.2709534368070953, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2709534368070953, 'acc_1_0': 0.4439252336448598, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6451501553331032}\n",
      " * Acc@1 0.645\n",
      "--- Epoch 76 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9787278415015641}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.9654362964572583, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7188470066518847, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8322402485329652}\n",
      " * Acc@1 0.832\n",
      "Test(spurious): {'weighted_mean_acc': 0.9472579891595041, 'worst_acc': 0.2811529933481153, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2811529933481153, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6487745944080083}\n",
      " * Acc@1 0.649\n",
      "--- Epoch 77 ---\n",
      "Train(y): {'worst_acc': 0.6785714285714286, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8152173913043478, 'acc_1_0': 0.6785714285714286, 'acc_1_1': 0.9583727530747398, 'mean_acc': 0.9789363920750782}\n",
      "Val(y): {'weighted_mean_acc': 0.9705387279480853, 'worst_acc': 0.5714285714285714, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7489270386266095, 'acc_1_0': 0.5714285714285714, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8473728106755629}\n",
      " * Acc@1 0.847\n",
      "Test(y): {'weighted_mean_acc': 0.9647135772826636, 'worst_acc': 0.5638629283489096, 'acc_0_0': 0.9929046563192905, 'acc_0_1': 0.7059866962305986, 'acc_1_0': 0.5638629283489096, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.8275802554366586}\n",
      " * Acc@1 0.828\n",
      "Test(spurious): {'weighted_mean_acc': 0.9474131072897731, 'worst_acc': 0.2940133037694013, 'acc_0_0': 0.9929046563192905, 'acc_0_1': 0.2940133037694013, 'acc_1_0': 0.43613707165109034, 'acc_1_1': 0.9376947040498442, 'mean_acc': 0.6530894028305143}\n",
      " * Acc@1 0.653\n",
      "--- Epoch 78 ---\n",
      "Train(y): {'worst_acc': 0.6785714285714286, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8152173913043478, 'acc_1_0': 0.6785714285714286, 'acc_1_1': 0.9593188268684958, 'mean_acc': 0.9791449426485923}\n",
      "Val(y): {'weighted_mean_acc': 0.9706156094859046, 'worst_acc': 0.5639097744360902, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7532188841201717, 'acc_1_0': 0.5639097744360902, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8482068390325271}\n",
      " * Acc@1 0.848\n",
      "Test(y): {'weighted_mean_acc': 0.9649948441735177, 'worst_acc': 0.5607476635514018, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.71529933481153, 'acc_1_0': 0.5607476635514018, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8308595098377632}\n",
      " * Acc@1 0.831\n",
      "Test(spurious): {'weighted_mean_acc': 0.9470524260196707, 'worst_acc': 0.2847006651884701, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.2847006651884701, 'acc_1_0': 0.4392523364485981, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6498101484294098}\n",
      " * Acc@1 0.650\n",
      "--- Epoch 79 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9536423841059603, 'mean_acc': 0.978310740354536}\n",
      "Val(y): {'weighted_mean_acc': 0.9708517187126025, 'worst_acc': 0.5488721804511278, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7639484978540773, 'acc_1_0': 0.5488721804511278, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8507089241034195}\n",
      " * Acc@1 0.851\n",
      "Test(y): {'weighted_mean_acc': 0.9657073939150398, 'worst_acc': 0.557632398753894, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7263858093126386, 'acc_1_0': 0.557632398753894, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.835001725923369}\n",
      " * Acc@1 0.835\n",
      "Test(spurious): {'weighted_mean_acc': 0.9469868917017223, 'worst_acc': 0.2736141906873614, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2736141906873614, 'acc_1_0': 0.4423676012461059, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6460131170176044}\n",
      " * Acc@1 0.646\n",
      "--- Epoch 80 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9787278415015641}\n",
      "Val(y): {'weighted_mean_acc': 0.9707803017880232, 'worst_acc': 0.5639097744360902, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.5639097744360902, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8498748957464554}\n",
      " * Acc@1 0.850\n",
      "Test(y): {'weighted_mean_acc': 0.9650787547708428, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.7179600886917961, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8317224715222644}\n",
      " * Acc@1 0.832\n",
      "Test(spurious): {'weighted_mean_acc': 0.9469685154223457, 'worst_acc': 0.282039911308204, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.282039911308204, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6489471867449085}\n",
      " * Acc@1 0.649\n",
      "--- Epoch 81 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8206521739130435, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.956480605487228, 'mean_acc': 0.97851929092805}\n",
      "Val(y): {'weighted_mean_acc': 0.9706156094859046, 'worst_acc': 0.5639097744360902, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7532188841201717, 'acc_1_0': 0.5639097744360902, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8482068390325271}\n",
      " * Acc@1 0.848\n",
      "Test(y): {'weighted_mean_acc': 0.9649449675508213, 'worst_acc': 0.5623052959501558, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.7135254988913525, 'acc_1_0': 0.5623052959501558, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8303417328270625}\n",
      " * Acc@1 0.830\n",
      "Test(spurious): {'weighted_mean_acc': 0.9471023026423673, 'worst_acc': 0.2864745011086475, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.2864745011086475, 'acc_1_0': 0.43769470404984423, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6503279254401104}\n",
      " * Acc@1 0.650\n",
      "--- Epoch 82 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8260869565217391, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.97851929092805}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.9654703304318866, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7197339246119734, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8325854332067656}\n",
      " * Acc@1 0.833\n",
      "Test(spurious): {'weighted_mean_acc': 0.9472239551848756, 'worst_acc': 0.2802660753880266, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2802660753880266, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6484294097342078}\n",
      " * Acc@1 0.648\n",
      "--- Epoch 83 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8206521739130435, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.978310740354536}\n",
      "Val(y): {'weighted_mean_acc': 0.9706979556369639, 'worst_acc': 0.5639097744360902, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7553648068669528, 'acc_1_0': 0.5639097744360902, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.965011861160832, 'worst_acc': 0.5607476635514018, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.7157427937915742, 'acc_1_0': 0.5607476635514018, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8310321021746634}\n",
      " * Acc@1 0.831\n",
      "Test(spurious): {'weighted_mean_acc': 0.9470354090323565, 'worst_acc': 0.2842572062084257, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.2842572062084257, 'acc_1_0': 0.4392523364485981, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6496375560925095}\n",
      " * Acc@1 0.650\n",
      "--- Epoch 84 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8152173913043478, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9583727530747398, 'mean_acc': 0.9787278415015641}\n",
      "Val(y): {'weighted_mean_acc': 0.9706156094859046, 'worst_acc': 0.5639097744360902, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7532188841201717, 'acc_1_0': 0.5639097744360902, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8482068390325271}\n",
      " * Acc@1 0.848\n",
      "Test(y): {'weighted_mean_acc': 0.9649778271862035, 'worst_acc': 0.5607476635514018, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.7148558758314856, 'acc_1_0': 0.5607476635514018, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.830686917500863}\n",
      " * Acc@1 0.831\n",
      "Test(spurious): {'weighted_mean_acc': 0.947069443006985, 'worst_acc': 0.2851441241685144, 'acc_0_0': 0.9937915742793791, 'acc_0_1': 0.2851441241685144, 'acc_1_0': 0.4392523364485981, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.64998274076631}\n",
      " * Acc@1 0.650\n",
      "--- Epoch 85 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9787278415015641}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.9655213813938295, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7210643015521064, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8331032102174664}\n",
      " * Acc@1 0.833\n",
      "Test(spurious): {'weighted_mean_acc': 0.9471729042229329, 'worst_acc': 0.27893569844789357, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.27893569844789357, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.647911632723507}\n",
      " * Acc@1 0.648\n",
      "--- Epoch 86 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9787278415015641}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.9654533134445724, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.719290465631929, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8324128408698653}\n",
      " * Acc@1 0.832\n",
      "Test(spurious): {'weighted_mean_acc': 0.9472409721721897, 'worst_acc': 0.28070953436807095, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.28070953436807095, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6486020020711081}\n",
      " * Acc@1 0.649\n",
      "--- Epoch 87 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9787278415015641}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.9654533134445724, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.719290465631929, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8324128408698653}\n",
      " * Acc@1 0.832\n",
      "Test(spurious): {'weighted_mean_acc': 0.9472409721721897, 'worst_acc': 0.28070953436807095, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.28070953436807095, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6486020020711081}\n",
      " * Acc@1 0.649\n",
      "--- Epoch 88 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9787278415015641}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.9654533134445724, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.719290465631929, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8324128408698653}\n",
      " * Acc@1 0.832\n",
      "Test(spurious): {'weighted_mean_acc': 0.9472409721721897, 'worst_acc': 0.28070953436807095, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.28070953436807095, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6486020020711081}\n",
      " * Acc@1 0.649\n",
      "--- Epoch 89 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8260869565217391, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.97851929092805}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.9654362964572583, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7188470066518847, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8322402485329652}\n",
      " * Acc@1 0.832\n",
      "Test(spurious): {'weighted_mean_acc': 0.9472579891595041, 'worst_acc': 0.2811529933481153, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2811529933481153, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6487745944080083}\n",
      " * Acc@1 0.649\n",
      "--- Epoch 90 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9545884578997161, 'mean_acc': 0.97851929092805}\n",
      "Val(y): {'weighted_mean_acc': 0.9707693725615432, 'worst_acc': 0.5488721804511278, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7618025751072961, 'acc_1_0': 0.5488721804511278, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8498748957464554}\n",
      " * Acc@1 0.850\n",
      "Test(y): {'weighted_mean_acc': 0.965640500305029, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7241685144124168, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.834311356575768}\n",
      " * Acc@1 0.834\n",
      "Test(spurious): {'weighted_mean_acc': 0.9470537853117331, 'worst_acc': 0.27583148558758314, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.27583148558758314, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6467034863652054}\n",
      " * Acc@1 0.647\n",
      "--- Epoch 91 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9545884578997161, 'mean_acc': 0.97851929092805}\n",
      "Val(y): {'weighted_mean_acc': 0.9707693725615432, 'worst_acc': 0.5488721804511278, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7618025751072961, 'acc_1_0': 0.5488721804511278, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8498748957464554}\n",
      " * Acc@1 0.850\n",
      "Test(y): {'weighted_mean_acc': 0.965640500305029, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7241685144124168, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.834311356575768}\n",
      " * Acc@1 0.834\n",
      "Test(spurious): {'weighted_mean_acc': 0.9470537853117331, 'worst_acc': 0.27583148558758314, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.27583148558758314, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6467034863652054}\n",
      " * Acc@1 0.647\n",
      "--- Epoch 92 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9545884578997161, 'mean_acc': 0.97851929092805}\n",
      "Val(y): {'weighted_mean_acc': 0.9707748371747833, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.759656652360515, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8498748957464554}\n",
      " * Acc@1 0.850\n",
      "Test(y): {'weighted_mean_acc': 0.9655894493430863, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7228381374722838, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8337935795650673}\n",
      " * Acc@1 0.834\n",
      "Test(spurious): {'weighted_mean_acc': 0.9471048362736758, 'worst_acc': 0.2771618625277162, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2771618625277162, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6472212633759061}\n",
      " * Acc@1 0.647\n",
      "--- Epoch 93 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9545884578997161, 'mean_acc': 0.97851929092805}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.965487347419201, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7201773835920178, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8327580255436658}\n",
      " * Acc@1 0.833\n",
      "Test(spurious): {'weighted_mean_acc': 0.9472069381975614, 'worst_acc': 0.2798226164079823, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2798226164079823, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6482568173973076}\n",
      " * Acc@1 0.648\n",
      "--- Epoch 94 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9787278415015641}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.9654533134445724, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.719290465631929, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8324128408698653}\n",
      " * Acc@1 0.832\n",
      "Test(spurious): {'weighted_mean_acc': 0.9472409721721897, 'worst_acc': 0.28070953436807095, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.28070953436807095, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6486020020711081}\n",
      " * Acc@1 0.649\n",
      "--- Epoch 95 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9787278415015641}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.9654192794699439, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7184035476718403, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8320676561960649}\n",
      " * Acc@1 0.832\n",
      "Test(spurious): {'weighted_mean_acc': 0.9472750061468183, 'worst_acc': 0.28159645232815966, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.28159645232815966, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6489471867449085}\n",
      " * Acc@1 0.649\n",
      "--- Epoch 96 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8260869565217391, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.97851929092805}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.9654192794699439, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7184035476718403, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8320676561960649}\n",
      " * Acc@1 0.832\n",
      "Test(spurious): {'weighted_mean_acc': 0.9472750061468183, 'worst_acc': 0.28159645232815966, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.28159645232815966, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6489471867449085}\n",
      " * Acc@1 0.649\n",
      "--- Epoch 97 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9787278415015641}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.965487347419201, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7201773835920178, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8327580255436658}\n",
      " * Acc@1 0.833\n",
      "Test(spurious): {'weighted_mean_acc': 0.9472069381975614, 'worst_acc': 0.2798226164079823, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2798226164079823, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6482568173973076}\n",
      " * Acc@1 0.648\n",
      "--- Epoch 98 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9787278415015641}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.9655383983811436, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7215077605321508, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8332758025543666}\n",
      " * Acc@1 0.833\n",
      "Test(spurious): {'weighted_mean_acc': 0.9471558872356185, 'worst_acc': 0.27849223946784923, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.27849223946784923, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6477390403866068}\n",
      " * Acc@1 0.648\n",
      "--- Epoch 99 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9787278415015641}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.965487347419201, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7201773835920178, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8327580255436658}\n",
      " * Acc@1 0.833\n",
      "Test(spurious): {'weighted_mean_acc': 0.9472069381975614, 'worst_acc': 0.2798226164079823, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2798226164079823, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6482568173973076}\n",
      " * Acc@1 0.648\n",
      "--- Epoch 100 ---\n",
      "Train(y): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.998570611778159, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9555345316934721, 'mean_acc': 0.9787278415015641}\n",
      "Val(y): {'weighted_mean_acc': 0.970692491023724, 'worst_acc': 0.556390977443609, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7575107296137339, 'acc_1_0': 0.556390977443609, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.8490408673894912}\n",
      " * Acc@1 0.849\n",
      "Test(y): {'weighted_mean_acc': 0.9655383983811436, 'worst_acc': 0.559190031152648, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7215077605321508, 'acc_1_0': 0.559190031152648, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.8332758025543666}\n",
      " * Acc@1 0.833\n",
      "Test(spurious): {'weighted_mean_acc': 0.9471558872356185, 'worst_acc': 0.27849223946784923, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.27849223946784923, 'acc_1_0': 0.440809968847352, 'acc_1_1': 0.9345794392523364, 'mean_acc': 0.6477390403866068}\n",
      " * Acc@1 0.648\n",
      "==================================================================\n",
      "best epoch : 51\n",
      "best (worst-)validation accuracy: {'weighted_mean_acc': 0.9698008780611935, 'worst_acc': 0.6390977443609023, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.6609442060085837, 'acc_1_0': 0.6390977443609023, 'acc_1_1': 0.9624060150375939, 'mean_acc': 0.8215179316096747} \n",
      "best test accuracy (class): {'weighted_mean_acc': 0.9612540113359958, 'worst_acc': 0.6186252771618626, 'acc_0_0': 0.9893569844789357, 'acc_0_1': 0.6186252771618626, 'acc_1_0': 0.6292834890965732, 'acc_1_1': 0.9454828660436138, 'mean_acc': 0.8003106662064204}\n",
      "best test accuracy (spurious): {'weighted_mean_acc': 0.9491301629138402, 'worst_acc': 0.3707165109034268, 'acc_0_0': 0.9893569844789357, 'acc_0_1': 0.38137472283813745, 'acc_1_0': 0.3707165109034268, 'acc_1_1': 0.9454828660436138, 'mean_acc': 0.679323438039351}\n"
     ]
    }
   ],
   "source": [
    "opt.dataset = 'waterbird'\n",
    "opt.target = 'class'\n",
    "opt.embedding_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/waterbirds/RN50/embedding_prediction.json\"\n",
    "opt.data_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/waterbirds/waterbird_complete95_forest2water2\"\n",
    "if __name__ == '__main__':    \n",
    "    main(opt)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_zs_embeddings = pd.read_json(\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/celeba/RN50/embedding_prediction.json\")\n",
    "opt.dataset = 'celeba'\n",
    "opt.target = 'class'\n",
    "opt.embedding_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/celeba/RN50/embedding_prediction.json\"\n",
    "opt.data_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/celeba\"\n",
    "if __name__ == '__main__':    \n",
    "    main(opt)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dict_zs(acc_groups, y, g, preds):\n",
    "    # preds = torch.argmax(logits, axis=1)\n",
    "    correct_batch = (preds == y)\n",
    "    g = g.cpu()\n",
    "    for g_val in np.unique(g):\n",
    "        mask = g == g_val\n",
    "        n = mask.sum().item()\n",
    "        corr = correct_batch[mask].sum().item()\n",
    "        acc_groups[g_val].update(corr / n, n) # AverageMeter Updater. \n",
    "\n",
    "def validate_zs(val_loader, get_yp_func, train_group_ratio, target, label='Test', watch=True):\n",
    "    \"\"\"validation\"\"\"\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(val_loader.dataset.n_groups)}\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            if opt.dataset == 'waterbirds':\n",
    "                _, all_labels, _ = data\n",
    "                labels = all_labels[target] # (y, y_group, y_spurious)\n",
    "                groups = all_labels['group']\n",
    "                preds = all_labels['ebd_y_pred']\n",
    "            else:\n",
    "                _,  all_labels, _ = data\n",
    "                labels = all_labels[target] # (y, y_group, y_spurious)\n",
    "                groups = all_labels['group']\n",
    "                preds = all_labels['ebd_y_pred']\n",
    "              \n",
    "              \n",
    "            preds = preds.float().cuda()  \n",
    "            labels = labels.cuda()\n",
    "            bsz = labels.shape[0]\n",
    "            \n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            # update metric    \n",
    "            acc1 = accuracy_zs(preds, labels, bsz)\n",
    "            acc.update(acc1, bsz)\n",
    "            \n",
    "            # Update acc dict\n",
    "            update_dict_zs(acc_groups, labels, groups, preds)\n",
    "            \n",
    "            if (idx+1) % opt.print_freq == 0:\n",
    "                print(f'{label}: [{0}/{1}]\\t'\n",
    "                    'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                    'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                    'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                    idx, len(val_loader), batch_time=batch_time,\n",
    "                    loss=losses, acc=acc))\n",
    "                    \n",
    "                    \n",
    "    group_acc = get_results(acc_groups, get_yp_func)\n",
    "    \n",
    "    #NOTE add Weighted mean acc.\n",
    "    groups = range(val_loader.dataset.n_groups) # 0, 1, 2, 3\n",
    "    group_acc_indiv =  [group_acc[f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\"] for g in groups]\n",
    "    weighted_mean_acc = (np.array(group_acc_indiv) * np.array(train_group_ratio)).sum() # Weighted Sum \\\n",
    "    \n",
    "    group_acc[\"weighted_mean_acc\"] = weighted_mean_acc\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print}\n",
    "    \n",
    "    if watch:\n",
    "        print(f\"{label}:\", str(group_acc))\n",
    "        print(' * Acc@1 {acc.avg:.3f}'.format(acc=acc))\n",
    "        \n",
    "    return  acc.avg, group_acc\n",
    "\n",
    "\n",
    "def main_zs(opt):\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    # opt = parse_option()\n",
    "    \n",
    "    # build dataset example.\n",
    "    if opt.dataset == 'waterbirds':\n",
    "        # build dataset example.\n",
    "        trainset = WaterbirdsEmbeddings(opt.data_dir, 'train', opt.embedding_dir, None, None)\n",
    "        # build data loader\n",
    "        print(\"Load Data Loader (train, validation, test)\")\n",
    "        train_loader, val_loader, test_loader = load_waterbirds_embeddings(opt.data_dir, opt.embedding_dir, opt.batch_size, opt.batch_size)\n",
    "    elif opt.dataset == 'celeba':\n",
    "        # build dataset example.\n",
    "        trainset = CelebaEmbeddings(opt.data_dir, 'train', opt.embedding_dir, None)\n",
    "        # build data loader\n",
    "        print(\"Load Data Loader (train, validation, test)\")\n",
    "        train_loader, val_loader, test_loader = load_celeba_embeddings(opt.data_dir, opt.embedding_dir, opt.batch_size, opt.batch_size)\n",
    "    \n",
    "    get_yp_func = partial(get_y_p, n_places=trainset.n_places)\n",
    "    train_group_ratio = trainset.group_ratio\n",
    "\n",
    "    # eval for one epoch\n",
    "    val_acc, val_group_acc = validate_zs(val_loader, get_yp_func, train_group_ratio, target='y', label='Val(y)')\n",
    "    test_acc_y, test_group_acc_y = validate_zs(test_loader, get_yp_func, train_group_ratio, target='y', label='Test(y)', watch=True)\n",
    "    test_acc_spurious, test_group_acc_spurious = validate_zs(test_loader, get_yp_func, train_group_ratio, target='spurious', label='Test(spurious)', watch=True)\n",
    "    \n",
    "    print('===============================Final Results===============================')\n",
    "    print('Zero-shot (worst-)validation accuracy: {} '.format(val_group_acc))\n",
    "    \n",
    "    print('Zero-shot test accuracy (class): {}'.format(test_group_acc_y))\n",
    "    print('Zero-shot test accuracy (spurious): {}'.format(test_group_acc_spurious))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watearbirds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Loader (train, validation, test)\n",
      "Val(y): {'weighted_mean_acc': 0.9450627926530569, 'worst_acc': 0.3233082706766917, 'acc_0_0': 0.9914346895074947, 'acc_0_1': 0.7145922746781116, 'acc_1_0': 0.3233082706766917, 'acc_1_1': 0.8646616541353384, 'mean_acc': 0.7956630525437864}\n",
      " * Acc@1 0.796\n",
      "Test(y): {'weighted_mean_acc': 0.9289761348579215, 'worst_acc': 0.3909657320872274, 'acc_0_0': 0.9804878048780488, 'acc_0_1': 0.7254988913525499, 'acc_1_0': 0.3909657320872274, 'acc_1_1': 0.822429906542056, 'mean_acc': 0.7984121505005177}\n",
      " * Acc@1 0.798\n",
      "===============================Final Results===============================\n",
      "Zero-shot (worst-)validation accuracy: {'weighted_mean_acc': 0.9450627926530569, 'worst_acc': 0.3233082706766917, 'acc_0_0': 0.9914346895074947, 'acc_0_1': 0.7145922746781116, 'acc_1_0': 0.3233082706766917, 'acc_1_1': 0.8646616541353384, 'mean_acc': 0.7956630525437864} \n",
      "Zero-shot test accuracy (class): {'weighted_mean_acc': 0.9289761348579215, 'worst_acc': 0.3909657320872274, 'acc_0_0': 0.9804878048780488, 'acc_0_1': 0.7254988913525499, 'acc_1_0': 0.3909657320872274, 'acc_1_1': 0.822429906542056, 'mean_acc': 0.7984121505005177}\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "opt.dataset = 'waterbird'\n",
    "opt.target = 'class'\n",
    "opt.embedding_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/waterbirds/RN50/embedding_prediction.json\"\n",
    "opt.data_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/waterbirds/waterbird_complete95_forest2water2\"\n",
    "if __name__ == '__main__':    \n",
    "    main_zs(opt)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3909657320872274\n"
     ]
    }
   ],
   "source": [
    "df_zs_embeddings = pd.read_json(\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/waterbirds/RN50/embedding_prediction.json\")\n",
    "from copy import deepcopy\n",
    "w = deepcopy(df_zs_embeddings)\n",
    "w= w.T\n",
    "print(\"Worst acc: \", len(w[(w['split']=='2') & (w['y']=='1') & (w['place']=='0') & (w['y_pred']=='1')]) / len(w[(w['split']=='2') & (w['y']=='1') & (w['place']=='0')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000001.jpg</th>\n",
       "      <th>000002.jpg</th>\n",
       "      <th>000003.jpg</th>\n",
       "      <th>000004.jpg</th>\n",
       "      <th>000005.jpg</th>\n",
       "      <th>000006.jpg</th>\n",
       "      <th>000007.jpg</th>\n",
       "      <th>000008.jpg</th>\n",
       "      <th>000009.jpg</th>\n",
       "      <th>000010.jpg</th>\n",
       "      <th>...</th>\n",
       "      <th>202590.jpg</th>\n",
       "      <th>202591.jpg</th>\n",
       "      <th>202592.jpg</th>\n",
       "      <th>202593.jpg</th>\n",
       "      <th>202594.jpg</th>\n",
       "      <th>202595.jpg</th>\n",
       "      <th>202596.jpg</th>\n",
       "      <th>202597.jpg</th>\n",
       "      <th>202598.jpg</th>\n",
       "      <th>202599.jpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blond</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_embedding</th>\n",
       "      <td>[-0.009254455566406, 0.006446838378906, -0.000...</td>\n",
       "      <td>[-0.014373779296875002, -1.072883605957031e-06...</td>\n",
       "      <td>[-0.020751953125, -0.01275634765625, -0.002752...</td>\n",
       "      <td>[0.008903503417968, 0.005790710449218001, -0.0...</td>\n",
       "      <td>[-0.020309448242187, -0.0140380859375, -0.0012...</td>\n",
       "      <td>[-0.016098022460937, 0.002260208129882, 0.0353...</td>\n",
       "      <td>[0.013648986816406, 0.010597229003906, 0.02252...</td>\n",
       "      <td>[-0.011924743652343, 0.020156860351562, 0.0206...</td>\n",
       "      <td>[0.007244110107421001, 0.008682250976562, -0.0...</td>\n",
       "      <td>[-0.000575065612792, 0.03582763671875, 0.02078...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.005859375, 0.02935791015625, -0.01418304443...</td>\n",
       "      <td>[0.03826904296875, -0.0186767578125, 0.0081253...</td>\n",
       "      <td>[-0.012893676757812, 0.022796630859375003, 0.0...</td>\n",
       "      <td>[0.04962158203125, -0.0041542053222650005, -0....</td>\n",
       "      <td>[-0.036895751953125, -0.00086498260498, 0.0211...</td>\n",
       "      <td>[-0.0157470703125, 0.013694763183593, 0.056549...</td>\n",
       "      <td>[0.004299163818359, 0.0045204162597650005, 0.0...</td>\n",
       "      <td>[0.006679534912109, 0.01129150390625, 0.012878...</td>\n",
       "      <td>[0.037109375, 0.007495880126953001, -0.0129013...</td>\n",
       "      <td>[0.008468627929687, -0.000998497009277, 0.0297...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 202599 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        000001.jpg   \n",
       "blond                                                            0  \\\n",
       "male                                                             0   \n",
       "group                                                            0   \n",
       "split                                                            0   \n",
       "image_embedding  [-0.009254455566406, 0.006446838378906, -0.000...   \n",
       "y_pred                                                           1   \n",
       "\n",
       "                                                        000002.jpg   \n",
       "blond                                                            0  \\\n",
       "male                                                             0   \n",
       "group                                                            0   \n",
       "split                                                            0   \n",
       "image_embedding  [-0.014373779296875002, -1.072883605957031e-06...   \n",
       "y_pred                                                           1   \n",
       "\n",
       "                                                        000003.jpg   \n",
       "blond                                                            0  \\\n",
       "male                                                             1   \n",
       "group                                                            1   \n",
       "split                                                            0   \n",
       "image_embedding  [-0.020751953125, -0.01275634765625, -0.002752...   \n",
       "y_pred                                                           1   \n",
       "\n",
       "                                                        000004.jpg   \n",
       "blond                                                            0  \\\n",
       "male                                                             0   \n",
       "group                                                            0   \n",
       "split                                                            0   \n",
       "image_embedding  [0.008903503417968, 0.005790710449218001, -0.0...   \n",
       "y_pred                                                           1   \n",
       "\n",
       "                                                        000005.jpg   \n",
       "blond                                                            0  \\\n",
       "male                                                             0   \n",
       "group                                                            0   \n",
       "split                                                            0   \n",
       "image_embedding  [-0.020309448242187, -0.0140380859375, -0.0012...   \n",
       "y_pred                                                           0   \n",
       "\n",
       "                                                        000006.jpg   \n",
       "blond                                                            0  \\\n",
       "male                                                             0   \n",
       "group                                                            0   \n",
       "split                                                            0   \n",
       "image_embedding  [-0.016098022460937, 0.002260208129882, 0.0353...   \n",
       "y_pred                                                           1   \n",
       "\n",
       "                                                        000007.jpg   \n",
       "blond                                                            0  \\\n",
       "male                                                             1   \n",
       "group                                                            1   \n",
       "split                                                            0   \n",
       "image_embedding  [0.013648986816406, 0.010597229003906, 0.02252...   \n",
       "y_pred                                                           1   \n",
       "\n",
       "                                                        000008.jpg   \n",
       "blond                                                            0  \\\n",
       "male                                                             1   \n",
       "group                                                            1   \n",
       "split                                                            0   \n",
       "image_embedding  [-0.011924743652343, 0.020156860351562, 0.0206...   \n",
       "y_pred                                                           1   \n",
       "\n",
       "                                                        000009.jpg   \n",
       "blond                                                            0  \\\n",
       "male                                                             0   \n",
       "group                                                            0   \n",
       "split                                                            0   \n",
       "image_embedding  [0.007244110107421001, 0.008682250976562, -0.0...   \n",
       "y_pred                                                           1   \n",
       "\n",
       "                                                        000010.jpg  ...   \n",
       "blond                                                            0  ...  \\\n",
       "male                                                             0  ...   \n",
       "group                                                            0  ...   \n",
       "split                                                            0  ...   \n",
       "image_embedding  [-0.000575065612792, 0.03582763671875, 0.02078...  ...   \n",
       "y_pred                                                           0  ...   \n",
       "\n",
       "                                                        202590.jpg   \n",
       "blond                                                            0  \\\n",
       "male                                                             1   \n",
       "group                                                            1   \n",
       "split                                                            2   \n",
       "image_embedding  [0.005859375, 0.02935791015625, -0.01418304443...   \n",
       "y_pred                                                           1   \n",
       "\n",
       "                                                        202591.jpg   \n",
       "blond                                                            0  \\\n",
       "male                                                             0   \n",
       "group                                                            0   \n",
       "split                                                            2   \n",
       "image_embedding  [0.03826904296875, -0.0186767578125, 0.0081253...   \n",
       "y_pred                                                           1   \n",
       "\n",
       "                                                        202592.jpg   \n",
       "blond                                                            1  \\\n",
       "male                                                             0   \n",
       "group                                                            2   \n",
       "split                                                            2   \n",
       "image_embedding  [-0.012893676757812, 0.022796630859375003, 0.0...   \n",
       "y_pred                                                           1   \n",
       "\n",
       "                                                        202593.jpg   \n",
       "blond                                                            0  \\\n",
       "male                                                             0   \n",
       "group                                                            0   \n",
       "split                                                            2   \n",
       "image_embedding  [0.04962158203125, -0.0041542053222650005, -0....   \n",
       "y_pred                                                           1   \n",
       "\n",
       "                                                        202594.jpg   \n",
       "blond                                                            0  \\\n",
       "male                                                             0   \n",
       "group                                                            0   \n",
       "split                                                            2   \n",
       "image_embedding  [-0.036895751953125, -0.00086498260498, 0.0211...   \n",
       "y_pred                                                           1   \n",
       "\n",
       "                                                        202595.jpg   \n",
       "blond                                                            1  \\\n",
       "male                                                             0   \n",
       "group                                                            2   \n",
       "split                                                            2   \n",
       "image_embedding  [-0.0157470703125, 0.013694763183593, 0.056549...   \n",
       "y_pred                                                           0   \n",
       "\n",
       "                                                        202596.jpg   \n",
       "blond                                                            1  \\\n",
       "male                                                             1   \n",
       "group                                                            3   \n",
       "split                                                            2   \n",
       "image_embedding  [0.004299163818359, 0.0045204162597650005, 0.0...   \n",
       "y_pred                                                           0   \n",
       "\n",
       "                                                        202597.jpg   \n",
       "blond                                                            0  \\\n",
       "male                                                             1   \n",
       "group                                                            1   \n",
       "split                                                            2   \n",
       "image_embedding  [0.006679534912109, 0.01129150390625, 0.012878...   \n",
       "y_pred                                                           1   \n",
       "\n",
       "                                                        202598.jpg   \n",
       "blond                                                            0  \\\n",
       "male                                                             0   \n",
       "group                                                            0   \n",
       "split                                                            2   \n",
       "image_embedding  [0.037109375, 0.007495880126953001, -0.0129013...   \n",
       "y_pred                                                           1   \n",
       "\n",
       "                                                        202599.jpg  \n",
       "blond                                                            1  \n",
       "male                                                             0  \n",
       "group                                                            2  \n",
       "split                                                            2  \n",
       "image_embedding  [0.008468627929687, -0.000998497009277, 0.0297...  \n",
       "y_pred                                                           0  \n",
       "\n",
       "[6 rows x 202599 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zs_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Loader (train, validation, test)\n",
      "Val(y): [0/1]\tTime 0.009 (0.277)\tLoss 0.0000 (0.0000)\tAcc@1 0.137 (0.146)\n",
      "Val(y): [0/1]\tTime 0.003 (0.144)\tLoss 0.0000 (0.0000)\tAcc@1 0.137 (0.148)\n",
      "Val(y): [0/1]\tTime 0.009 (0.099)\tLoss 0.0000 (0.0000)\tAcc@1 0.150 (0.147)\n",
      "Val(y): [0/1]\tTime 0.003 (0.078)\tLoss 0.0000 (0.0000)\tAcc@1 0.119 (0.148)\n",
      "Val(y): [0/1]\tTime 0.002 (0.064)\tLoss 0.0000 (0.0000)\tAcc@1 0.143 (0.147)\n",
      "Val(y): [0/1]\tTime 0.003 (0.056)\tLoss 0.0000 (0.0000)\tAcc@1 0.156 (0.147)\n",
      "Val(y): [0/1]\tTime 0.002 (0.049)\tLoss 0.0000 (0.0000)\tAcc@1 0.152 (0.146)\n",
      "Val(y): [0/1]\tTime 0.003 (0.044)\tLoss 0.0000 (0.0000)\tAcc@1 0.141 (0.147)\n",
      "Val(y): [0/1]\tTime 0.002 (0.041)\tLoss 0.0000 (0.0000)\tAcc@1 0.150 (0.146)\n",
      "Val(y): [0/1]\tTime 0.002 (0.038)\tLoss 0.0000 (0.0000)\tAcc@1 0.139 (0.146)\n",
      "Val(y): [0/1]\tTime 0.002 (0.035)\tLoss 0.0000 (0.0000)\tAcc@1 0.145 (0.147)\n",
      "Val(y): [0/1]\tTime 0.003 (0.033)\tLoss 0.0000 (0.0000)\tAcc@1 0.131 (0.147)\n",
      "Val(y): [0/1]\tTime 0.002 (0.032)\tLoss 0.0000 (0.0000)\tAcc@1 0.168 (0.147)\n",
      "Val(y): [0/1]\tTime 0.003 (0.030)\tLoss 0.0000 (0.0000)\tAcc@1 0.158 (0.147)\n",
      "Val(y): [0/1]\tTime 0.002 (0.029)\tLoss 0.0000 (0.0000)\tAcc@1 0.188 (0.147)\n",
      "Val(y): {'weighted_mean_acc': 0.1469128198791998, 'worst_acc': 0.06282371665107708, 'acc_0_0': 0.06282371665107708, 'acc_0_1': 0.18605138020755452, 'acc_1_0': 0.2932692307692308, 'acc_1_1': 0.18817591925018023, 'mean_acc': 0.146912821773054}\n",
      " * Acc@1 0.147\n",
      "Test(y): [0/1]\tTime 0.003 (0.193)\tLoss 0.0000 (0.0000)\tAcc@1 0.137 (0.146)\n",
      "Test(y): [0/1]\tTime 0.001 (0.101)\tLoss 0.0000 (0.0000)\tAcc@1 0.137 (0.148)\n",
      "Test(y): [0/1]\tTime 0.003 (0.072)\tLoss 0.0000 (0.0000)\tAcc@1 0.150 (0.147)\n",
      "Test(y): [0/1]\tTime 0.002 (0.056)\tLoss 0.0000 (0.0000)\tAcc@1 0.119 (0.148)\n",
      "Test(y): [0/1]\tTime 0.003 (0.048)\tLoss 0.0000 (0.0000)\tAcc@1 0.143 (0.147)\n",
      "Test(y): [0/1]\tTime 0.001 (0.042)\tLoss 0.0000 (0.0000)\tAcc@1 0.156 (0.147)\n",
      "Test(y): [0/1]\tTime 0.003 (0.038)\tLoss 0.0000 (0.0000)\tAcc@1 0.152 (0.146)\n",
      "Test(y): [0/1]\tTime 0.002 (0.034)\tLoss 0.0000 (0.0000)\tAcc@1 0.141 (0.147)\n",
      "Test(y): [0/1]\tTime 0.003 (0.032)\tLoss 0.0000 (0.0000)\tAcc@1 0.150 (0.146)\n",
      "Test(y): [0/1]\tTime 0.002 (0.030)\tLoss 0.0000 (0.0000)\tAcc@1 0.139 (0.146)\n",
      "Test(y): [0/1]\tTime 0.001 (0.028)\tLoss 0.0000 (0.0000)\tAcc@1 0.145 (0.147)\n",
      "Test(y): [0/1]\tTime 0.002 (0.027)\tLoss 0.0000 (0.0000)\tAcc@1 0.131 (0.147)\n",
      "Test(y): [0/1]\tTime 0.001 (0.026)\tLoss 0.0000 (0.0000)\tAcc@1 0.168 (0.147)\n",
      "Test(y): [0/1]\tTime 0.002 (0.025)\tLoss 0.0000 (0.0000)\tAcc@1 0.158 (0.147)\n",
      "Test(y): [0/1]\tTime 0.003 (0.024)\tLoss 0.0000 (0.0000)\tAcc@1 0.188 (0.147)\n",
      "Test(y): {'weighted_mean_acc': 0.1469128198791998, 'worst_acc': 0.06282371665107708, 'acc_0_0': 0.06282371665107708, 'acc_0_1': 0.18605138020755452, 'acc_1_0': 0.2932692307692308, 'acc_1_1': 0.18817591925018023, 'mean_acc': 0.146912821773054}\n",
      " * Acc@1 0.147\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.192)\tLoss 0.0000 (0.0000)\tAcc@1 0.449 (0.467)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.100)\tLoss 0.0000 (0.0000)\tAcc@1 0.457 (0.462)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.071)\tLoss 0.0000 (0.0000)\tAcc@1 0.443 (0.463)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.055)\tLoss 0.0000 (0.0000)\tAcc@1 0.475 (0.461)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.047)\tLoss 0.0000 (0.0000)\tAcc@1 0.473 (0.461)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.041)\tLoss 0.0000 (0.0000)\tAcc@1 0.467 (0.462)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.037)\tLoss 0.0000 (0.0000)\tAcc@1 0.471 (0.462)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.034)\tLoss 0.0000 (0.0000)\tAcc@1 0.430 (0.461)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.031)\tLoss 0.0000 (0.0000)\tAcc@1 0.482 (0.461)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.029)\tLoss 0.0000 (0.0000)\tAcc@1 0.445 (0.462)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.028)\tLoss 0.0000 (0.0000)\tAcc@1 0.469 (0.462)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.026)\tLoss 0.0000 (0.0000)\tAcc@1 0.477 (0.463)\n",
      "Test(spurious): [0/1]\tTime 0.003 (0.025)\tLoss 0.0000 (0.0000)\tAcc@1 0.463 (0.463)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.024)\tLoss 0.0000 (0.0000)\tAcc@1 0.482 (0.463)\n",
      "Test(spurious): [0/1]\tTime 0.003 (0.023)\tLoss 0.0000 (0.0000)\tAcc@1 0.488 (0.463)\n",
      "Test(spurious): {'weighted_mean_acc': 0.4630030035683199, 'worst_acc': 0.06282371665107708, 'acc_0_0': 0.06282371665107708, 'acc_0_1': 0.8139486197924455, 'acc_1_0': 0.7067307692307693, 'acc_1_1': 0.18817591925018023, 'mean_acc': 0.46300301038274866}\n",
      " * Acc@1 0.463\n",
      "===============================Final Results===============================\n",
      "Zero-shot (worst-)validation accuracy: {'weighted_mean_acc': 0.1469128198791998, 'worst_acc': 0.06282371665107708, 'acc_0_0': 0.06282371665107708, 'acc_0_1': 0.18605138020755452, 'acc_1_0': 0.2932692307692308, 'acc_1_1': 0.18817591925018023, 'mean_acc': 0.146912821773054} \n",
      "Zero-shot test accuracy (class): {'weighted_mean_acc': 0.1469128198791998, 'worst_acc': 0.06282371665107708, 'acc_0_0': 0.06282371665107708, 'acc_0_1': 0.18605138020755452, 'acc_1_0': 0.2932692307692308, 'acc_1_1': 0.18817591925018023, 'mean_acc': 0.146912821773054}\n",
      "Zero-shot test accuracy (spurious): {'weighted_mean_acc': 0.4630030035683199, 'worst_acc': 0.06282371665107708, 'acc_0_0': 0.06282371665107708, 'acc_0_1': 0.8139486197924455, 'acc_1_0': 0.7067307692307693, 'acc_1_1': 0.18817591925018023, 'mean_acc': 0.46300301038274866}\n"
     ]
    }
   ],
   "source": [
    "opt.dataset = 'celeba'\n",
    "opt.target = 'class'\n",
    "opt.embedding_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/celeba/RN50/embedding_prediction.json\"\n",
    "opt.data_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/celeba\"\n",
    "if __name__ == '__main__':    \n",
    "    main_zs(opt)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23333333333333334\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "df_zs_embeddings = pd.read_json(\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/celeba/RN50/embedding_prediction.json\")\n",
    "w = deepcopy(df_zs_embeddings)\n",
    "w= w.T\n",
    "print(\"Worst acc:\", len(w[(w['split']=='2') & (w['blond']=='1') & (w['male']=='1') & (w['y_pred']=='1')]) / len(w[(w['split']=='2') & (w['blond']=='1') & (w['male']=='1')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

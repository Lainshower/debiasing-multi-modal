{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "sys.path.append(\"/home/jinsu/workstation/project/debiasing-multi-modal\")\n",
    "\n",
    "\n",
    "df_zs_embeddings = pd.read_json(\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/waterbirds/RN50/embedding_prediction.json\")\n",
    "df_meta = pd.read_csv(\"/home/jinsu/workstation/project/debiasing-multi-modal/data/waterbirds/waterbird_complete95_forest2water2/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from util import AverageMeter\n",
    "from util import adjust_learning_rate, warmup_learning_rate, accuracy, accuracy_zs\n",
    "from util import set_optimizer\n",
    "# from networks.resnet_big import SupConResNet, LinearClassifier\n",
    "\n",
    "try:\n",
    "    import apex\n",
    "    from apex import amp, optimizers\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "from resnet import resnet50\n",
    "from data.waterbirds_embeddings import WaterbirdsEmbeddings, load_waterbirds_embeddings\n",
    "from data.celeba_embeddings import CelebaEmbeddings, load_celeba_embeddings\n",
    "model_dict = {'resnet50': [resnet50, 1024]}\n",
    "new_order_for_print = [\n",
    "    'weighted_mean_acc',\n",
    "    'worst_acc',\n",
    "    'acc_0_0',\n",
    "    'acc_0_1',\n",
    "    'acc_1_0',\n",
    "    'acc_1_1',\n",
    "    'mean_acc'\n",
    "]\n",
    "from functools import partial\n",
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=2):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "\n",
    "    def forward(self, features):\n",
    "        return self.fc(features)\n",
    "\n",
    "\n",
    "\n",
    "class CustomCLIP(nn.Module):\n",
    "    def __init__(self, adapter, text_embedding_dir, temperature=0.01):\n",
    "        super().__init__()\n",
    "        self.text_embedding_dir = text_embedding_dir\n",
    "        self.adapter = adapter\n",
    "        self.temperature = temperature # CA default : 0.01, B2T default : 0.02 (?) NOTE\n",
    "        \n",
    "        with open(self.text_embedding_dir, 'r') as f:\n",
    "            self.text_embeddings = json.load(f)\n",
    "        text_features = []\n",
    "        for class_template, class_embedding in self.text_embeddings.items():\n",
    "            text_features.append(torch.tensor(class_embedding))\n",
    "        self.text_features = torch.stack(text_features, dim=1).cuda() # (B, 2, 1024)\n",
    "        \n",
    "    \n",
    "    def forward(self, features):\n",
    "        image_features =  self.adapter(features) # Un-normalized (B, 1024)\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        text_features = self.text_features # 이미 Normalized(?) NOTE (B, 2, 1024)\n",
    "        \n",
    "        logits = image_features @ text_features / self.temperature # (B, 1024) X (B, 2, 1024) = # (B, 2)\n",
    "        return logits\n",
    "        \n",
    "        \n",
    "class Adapter(nn.Module):\n",
    "    \"\"\"\n",
    "    - Residual connetion : 제외 (original Adapter - 0.2*images + 0.8*adapter)\n",
    "    - Hidden dimension : 128 고정 (original Adatper - input_dim // 4)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "    def forward(self, features):\n",
    "        return self.layers(features)\n",
    "\n",
    "\n",
    "def parse_option():\n",
    "    parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "    parser.add_argument('--print_freq', type=int, default=10,\n",
    "                        help='print frequency')\n",
    "    parser.add_argument('--save_freq', type=int, default=50,\n",
    "                        help='save frequency')\n",
    "    parser.add_argument('--batch_size', type=int, default=128,\n",
    "                        help='batch_size')\n",
    "    parser.add_argument('--num_workers', type=int, default=16,\n",
    "                        help='num of workers to use')\n",
    "    parser.add_argument('--epochs', type=int, default=100,\n",
    "                        help='number of training epochs')\n",
    "\n",
    "    # optimization\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.1,\n",
    "                        help='learning rate')\n",
    "    parser.add_argument('--lr_decay_epochs', type=str, default='60,75,90',\n",
    "                        help='where to decay lr, can be a list')\n",
    "    parser.add_argument('--lr_decay_rate', type=float, default=0.2,\n",
    "                        help='decay rate for learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=0,\n",
    "                        help='weight decay')\n",
    "    parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                        help='momentum')\n",
    "\n",
    "    # model dataset\n",
    "    parser.add_argument('--model', type=str, default='resnet50')\n",
    "    parser.add_argument('--dataset', type=str, default='waterbirds',\n",
    "                        choices=['celeba', 'waterbirds'], help='dataset')\n",
    "\n",
    "    # other setting\n",
    "    parser.add_argument('--cosine', action='store_true',\n",
    "                        help='using cosine annealing')\n",
    "    parser.add_argument('--warm', action='store_true',\n",
    "                        help='warm-up for large batch training')\n",
    "\n",
    "    parser.add_argument('--image_embedding_dir', type=str,\n",
    "                        help='extracted image embedding')\n",
    "    parser.add_argument('--text_embedding_dir', type=str,\n",
    "                        help='extracted text embedding')\n",
    "    parser.add_argument('--train_target', type=str, default=\"class\", choices=[\"class\", \"group\", \"spurious\"]) # label for prediction.\n",
    "    parser.add_argument('--data_dir', type=str,\n",
    "                        help='metadata.csv')\n",
    "    parser.add_argument('--tl_method', type=str, default= \"linear_probing\", choices=[\"linear_probing\", \"adapter\", \"contrastive_adapter\"]\n",
    "                        ,help='transfer learning method')\n",
    "\n",
    "    opt = parser.parse_args(args=[])\n",
    "\n",
    "    # set the path according to the environment\n",
    "\n",
    "    iterations = opt.lr_decay_epochs.split(',')\n",
    "    opt.lr_decay_epochs = list([])\n",
    "    for it in iterations:\n",
    "        opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "    opt.model_name = '{}_{}_lr_{}_decay_{}_bsz_{}'.\\\n",
    "        format(opt.dataset, opt.model, opt.learning_rate, opt.weight_decay,\n",
    "               opt.batch_size)\n",
    "\n",
    "    if opt.cosine:\n",
    "        opt.model_name = '{}_cosine'.format(opt.model_name)\n",
    "\n",
    "    # warm-up for large-batch training,\n",
    "    if opt.warm:\n",
    "        opt.model_name = '{}_warm'.format(opt.model_name)\n",
    "        opt.warmup_from = 0.01\n",
    "        opt.warm_epochs = 10\n",
    "        if opt.cosine:\n",
    "            eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "            opt.warmup_to = eta_min + (opt.learning_rate - eta_min) * (\n",
    "                    1 + math.cos(math.pi * opt.warm_epochs / opt.epochs)) / 2\n",
    "        else:\n",
    "            opt.warmup_to = opt.learning_rate\n",
    "            \n",
    "    if opt.dataset == 'celeba':\n",
    "        opt.n_cls = 2\n",
    "    elif opt.dataset == 'waterbirds':\n",
    "        opt.n_cls = 2\n",
    "    else:\n",
    "        raise ValueError('dataset not supported: {}'.format(opt.dataset))\n",
    "\n",
    "    return opt\n",
    "\n",
    "\n",
    "def set_model(opt):\n",
    "    # model = SupConResNet(name=opt.model)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "    _ , input_dim = model_dict[opt.model] \n",
    "    \n",
    "    if opt.tl_method =='linear_probing':\n",
    "        print(\"Off-the-shelf prediction module : [Linear Classifier]\")\n",
    "        classifier = LinearClassifier(input_dim = input_dim, num_classes = opt.n_cls)\n",
    "    elif opt.tl_method =='adapter':\n",
    "        print(\"Off-the-shelf prediction module : [Adapter + temperatured-image-text-normalized-prediction]\")\n",
    "        adapter = Adapter(input_dim = input_dim, hidden_dim = 128) # Fixed by heuristics\n",
    "        classifier = CustomCLIP(adapter, opt.text_embedding_dir, temperature=0.01)\n",
    "    \n",
    "\n",
    "    # ckpt = torch.load(opt.ckpt, map_location='cpu')\n",
    "    # state_dict = ckpt['model']\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # if torch.cuda.device_count() > 1:\n",
    "        #     model.encoder = torch.nn.DataParallel(model.encoder)\n",
    "        # else:\n",
    "            # new_state_dict = {}\n",
    "            # for k, v in state_dict.items():\n",
    "            #     k = k.replace(\"module.\", \"\")\n",
    "            #     new_state_dict[k] = v\n",
    "            # state_dict = new_state_dict\n",
    "        \n",
    "        # model = model.cuda()\n",
    "        classifier = classifier.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "        # model.load_state_dict(state_dict)\n",
    "\n",
    "    return classifier, criterion # model, \n",
    "\n",
    "def update_dict(acc_groups, y, g, logits):\n",
    "    preds = torch.argmax(logits, axis=1)\n",
    "    correct_batch = (preds == y)\n",
    "    g = g.cpu()\n",
    "    for g_val in np.unique(g):\n",
    "        mask = g == g_val\n",
    "        n = mask.sum().item()\n",
    "        corr = correct_batch[mask].sum().item()\n",
    "        acc_groups[g_val].update(corr / n, n) # AverageMeter Updater. \n",
    "\n",
    "def get_results(acc_groups, get_yp_func, ): # Input 중 acc_groups : AverageMeter()를 담고있는 dict. get_yp_func : 미리 partial을 이용해 n_groups를 저장해놓음. \n",
    "    groups = acc_groups.keys() # 0, 1, 2, 3\n",
    "    results = {\n",
    "            f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\": acc_groups[g].avg\n",
    "            for g in groups\n",
    "    }\n",
    "    all_correct = sum([acc_groups[g].sum for g in groups])\n",
    "    all_total = sum([acc_groups[g].count for g in groups])\n",
    "    results.update({\"mean_acc\" : all_correct / all_total})\n",
    "    results.update({\"worst_acc\" : min(results.values())})\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_y_p(g, n_places):\n",
    "    y = g // n_places\n",
    "    p = g % n_places\n",
    "    return y, p\n",
    "\n",
    "\n",
    "def train(train_loader, classifier, criterion, optimizer, epoch, get_yp_func, target, label='Train'): # model,\n",
    "    \"\"\"one epoch training\"\"\"\n",
    "    # model.eval()\n",
    "    classifier.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(train_loader.dataset.n_groups)}\n",
    "\n",
    "    end = time.time()\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        if opt.dataset == 'waterbirds':\n",
    "            embeddings, all_labels, img_filenames = data\n",
    "            labels = all_labels[target] # (y, group, spurious)\n",
    "            groups = all_labels['group']\n",
    "        else:\n",
    "            embeddings, all_labels, img_filenames = data\n",
    "            labels = all_labels[target] # (y, group, ypurious)\n",
    "            groups = all_labels['group']\n",
    "        \n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        embeddings = embeddings.cuda(non_blocking=True)\n",
    "        labels = labels.cuda(non_blocking=True)\n",
    "        bsz = labels.shape[0]\n",
    "\n",
    "        # warm-up learning rate\n",
    "        warmup_learning_rate(opt, epoch, idx, len(train_loader), optimizer)\n",
    "\n",
    "        # compute loss\n",
    "        # with torch.no_grad():\n",
    "        #     features = model.encoder(embeddings)\n",
    "        output = classifier(embeddings.detach())\n",
    "        \n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # update metric\n",
    "        losses.update(loss.item(), bsz)\n",
    "        acc1 = accuracy(output, labels, bsz)\n",
    "        acc.update(acc1, bsz)\n",
    "\n",
    "        # SGD\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        # Update acc dict\n",
    "        update_dict(acc_groups, labels, groups, output)\n",
    "        \n",
    "        # print info\n",
    "        # if (idx + 1) % opt.print_freq == 0:\n",
    "        #     print(f'{label}: [{0}][{1}/{2}]\\t'\n",
    "        #           'BT {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "        #           'DT {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "        #           'loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n",
    "        #           'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "        #            epoch, idx + 1, len(train_loader), batch_time=batch_time,\n",
    "        #            data_time=data_time, loss=losses, acc=acc))\n",
    "        #     sys.stdout.flush()\n",
    "            \n",
    "    group_acc = get_results(acc_groups, get_yp_func) # NOTE declared in [def main]\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print[1:]}\n",
    "    print(f\"{label}:\", str(group_acc))\n",
    "    \n",
    "    return losses.avg, acc.avg, group_acc\n",
    "\n",
    "\n",
    "def validate(val_loader, classifier, criterion, get_yp_func, train_group_ratio, target, label='Test', watch=True):\n",
    "    \"\"\"validation\"\"\"\n",
    "    \n",
    "    # model.eval()\n",
    "    classifier.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(val_loader.dataset.n_groups)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            if opt.dataset == 'waterbirds':\n",
    "                embeddings, all_labels, _ = data\n",
    "                labels = all_labels[target] # (y, group, spurious)\n",
    "                groups = all_labels['group']\n",
    "            elif opt.dataset == 'celeba':\n",
    "                embeddings, all_labels = data\n",
    "                labels = all_labels[target] # (y, group, spurious)\n",
    "                groups = all_labels['group']\n",
    "            \n",
    "            embeddings = embeddings.float().cuda()\n",
    "            labels = labels.cuda()\n",
    "            bsz = labels.shape[0]\n",
    "\n",
    "            # forward\n",
    "            output = classifier(embeddings)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            # update metric\n",
    "            losses.update(loss.item(), bsz)\n",
    "            acc1 = accuracy(output, labels, bsz)\n",
    "            acc.update(acc1, bsz)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            # Update acc dict\n",
    "            update_dict(acc_groups, labels, groups, output)\n",
    "        \n",
    "            # if (idx+1) % opt.print_freq == 0:\n",
    "            #     if watch:\n",
    "            #         print(f'{label}: [{0}/{1}]\\t'\n",
    "            #             'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "            #             'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "            #             'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "            #             idx, len(val_loader), batch_time=batch_time,\n",
    "            #             loss=losses, acc=acc))\n",
    "                    \n",
    "                    \n",
    "    group_acc = get_results(acc_groups, get_yp_func)\n",
    "    \n",
    "    #NOTE add Weighted mean acc.\n",
    "    groups = range(val_loader.dataset.n_groups) # 0, 1, 2, 3\n",
    "    group_acc_indiv =  [group_acc[f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\"] for g in groups]\n",
    "    weighted_mean_acc = (np.array(group_acc_indiv) * np.array(train_group_ratio)).sum() # Weighted Sum \\\n",
    "    \n",
    "    group_acc[\"weighted_mean_acc\"] = weighted_mean_acc\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print}\n",
    "    \n",
    "    if watch:\n",
    "        print(f\"{label}:\", str(group_acc))\n",
    "        # print(' * Acc@1 {acc.avg:.3f}'.format(acc=acc))\n",
    "    return losses.avg, acc.avg, group_acc\n",
    "\n",
    "\n",
    "def main(opt):\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    # opt = parse_option()\n",
    "    \n",
    "    print(f\"Transfer Learning using [{opt.tl_method}]\")\n",
    "    if opt.dataset == 'waterbirds':\n",
    "        # build dataset example.\n",
    "        trainset = WaterbirdsEmbeddings(opt.data_dir, 'train', opt.image_embedding_dir, None, None)\n",
    "        # build data loader\n",
    "        \n",
    "        if opt.train_target == \"class\":\n",
    "            print(f\"Train Target : {opt.train_target} (Land bird(0) / Water bird(1))\")\n",
    "        elif opt.train_target == \"spurious\":\n",
    "            print(f\"Train Target : {opt.train_target} (Land background(0) / Water background(1)\")\n",
    "            \n",
    "        print(\"Load Data Loader (train, validation, test)\")\n",
    "        train_loader, val_loader, test_loader = load_waterbirds_embeddings(opt.data_dir, opt.image_embedding_dir, opt.batch_size, opt.batch_size)\n",
    "        \n",
    "    elif opt.dataset == 'celeba':\n",
    "        # build dataset example.\n",
    "        trainset = CelebaEmbeddings(opt.data_dir, 'train', opt.image_embedding_dir, None)\n",
    "        \n",
    "        if opt.train_target == \"class\":\n",
    "            print(f\"Target : {opt.train_target} (non-blond hair(0) / blond hair(1)\")\n",
    "        elif opt.train_target == \"spurious\":\n",
    "            print(f\"Target : {opt.train_target} (female(0) / male(1))\")\n",
    "            \n",
    "        # build data loader\n",
    "        print(\"Load Data Loader (train, validation, test)\")\n",
    "        train_loader, val_loader, test_loader = load_celeba_embeddings(opt.data_dir, opt.image_embedding_dir, opt.batch_size, opt.batch_size)\n",
    "    \n",
    "\n",
    "    get_yp_func = partial(get_y_p, n_places=trainset.n_places)\n",
    "    train_group_ratio = trainset.group_ratio\n",
    "    \n",
    "    # build model and criterion\n",
    "    print(f\"Set Classifier : {opt.tl_method}\")\n",
    "    classifier, criterion = set_model(opt) # model, \n",
    "\n",
    "    # build optimizer\n",
    "    print(\"Set Optimizer\")\n",
    "    optimizer = set_optimizer(opt, classifier)\n",
    "\n",
    "    # training routine\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    train_group_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "    val_group_accs = []\n",
    "    val_losses_non_target = []\n",
    "    val_accs_non_target = []\n",
    "    val_group_accs_non_target = []\n",
    "    \n",
    "    test_losses_y = [] # NOTE: Don't peek ! \n",
    "    test_accs_y = [] # NOTE: Don't peek ! \n",
    "    test_group_accs_y = [] # NOTE: Don't peek ! \n",
    "    test_losses_spurious = [] # NOTE: Don't peek ! \n",
    "    test_accs_spurious = [] # NOTE: Don't peek ! \n",
    "    test_group_accs_spurious = [] # NOTE: Don't peek ! \n",
    "    \n",
    "    for epoch in range(1, opt.epochs + 1):\n",
    "        adjust_learning_rate(opt, optimizer, epoch)\n",
    "        print(f'--- Epoch {epoch} ---')\n",
    "        # train for one epoch\n",
    "        loss, acc, group_acc = train(train_loader, classifier, criterion,\n",
    "                          optimizer, epoch, get_yp_func, target=opt.train_target, label=f'Train({opt.train_target})')\n",
    "        \n",
    "        train_losses.append(loss)\n",
    "        train_accs.append(acc)\n",
    "        train_group_accs.append(group_acc)\n",
    "        # eval for one epoch\n",
    "        val_loss, val_acc, val_group_acc = validate(val_loader, classifier, criterion, get_yp_func, train_group_ratio, target=opt.train_target, label=f'Val({opt.train_target})')\n",
    "        \n",
    "        if opt.tl_method in ['linear_probing', 'adapter']:\n",
    "            if val_group_acc['weighted_mean_acc'] > best_acc:\n",
    "                best_acc = val_group_acc['weighted_mean_acc']\n",
    "                best_epoch = epoch\n",
    "        elif opt.tl_method in ['contrastive_adapter']:\n",
    "            if val_group_acc['worst_acc'] > best_acc:\n",
    "                best_acc = val_group_acc['worst_acc']\n",
    "                best_epoch = epoch\n",
    "            \n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        val_group_accs.append(val_group_acc)\n",
    "        \n",
    "        \n",
    "        non_target = [label for label in ['class', 'spurious'] if (label!=opt.train_target)][0]\n",
    "        val_loss_non_target, val_acc_non_target, val_group_acc_non_target = validate(val_loader, classifier, criterion, get_yp_func, train_group_ratio, target=non_target, label=f'Val({non_target})')\n",
    "\n",
    "        val_losses_non_target.append(val_loss_non_target)\n",
    "        val_accs_non_target.append(val_acc_non_target)\n",
    "        val_group_accs_non_target.append(val_group_acc_non_target)\n",
    "        \n",
    "        \n",
    "        test_loss_y, test_acc_y, test_group_acc_y = validate(test_loader, classifier, criterion, get_yp_func, train_group_ratio, target='class', label='Test(class)', watch=True)\n",
    "        test_losses_y.append(test_loss_y)\n",
    "        test_accs_y.append(test_acc_y)\n",
    "        test_group_accs_y.append(test_group_acc_y)\n",
    "        \n",
    "        test_loss_spurious, test_acc_spurious, test_group_acc_spurious= validate(test_loader, classifier, criterion, get_yp_func, train_group_ratio, target='spurious', label='Test(spurious)', watch=True)\n",
    "        test_losses_spurious.append(test_loss_spurious)\n",
    "        test_accs_spurious.append(test_acc_spurious)\n",
    "        test_group_accs_spurious.append(test_group_acc_spurious)\n",
    "    \n",
    "    \n",
    "    print('===============')\n",
    "    print('best epoch : {}'.format(best_epoch))\n",
    "    \n",
    "    val_group_acc = val_group_accs[best_epoch-1]\n",
    "    test_group_acc_y = test_group_accs_y[best_epoch-1]\n",
    "    test_group_acc_spurious = test_group_accs_spurious[best_epoch-1]\n",
    "    print(f'best validation accuracy on {opt.train_target}: {val_group_acc}')\n",
    "    \n",
    "    print(f'best test accuracy (class): {test_group_acc_y}')\n",
    "    print(f'best test accuracy (spurious): {test_group_acc_spurious}')\n",
    "    \n",
    "    \n",
    "    # return val_group_acc, test_group_acc_y, test_group_acc_spurious # 최종 결과만\n",
    "    return val_group_acc, test_group_acc_y, test_group_acc_spurious, train_group_accs, val_group_accs, val_group_accs_non_target # 전체 결과까지."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "parser.add_argument('--print_freq', type=int, default=20,\n",
    "                    help='print frequency')\n",
    "parser.add_argument('--save_freq', type=int, default=50,\n",
    "                    help='save frequency')\n",
    "parser.add_argument('--batch_size', type=int, default=128,\n",
    "                    help='batch_size')\n",
    "parser.add_argument('--num_workers', type=int, default=16,\n",
    "                    help='num of workers to use')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='number of training epochs')\n",
    "\n",
    "# optimization\n",
    "parser.add_argument('--learning_rate', type=float, default=5,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--lr_decay_epochs', type=str, default='60,75,90',\n",
    "                    help='where to decay lr, can be a list')\n",
    "parser.add_argument('--lr_decay_rate', type=float, default=0.2,\n",
    "                    help='decay rate for learning rate')\n",
    "parser.add_argument('--weight_decay', type=float, default=0,\n",
    "                    help='weight decay')\n",
    "parser.add_argument('--momentum', type=float, default=0.9,\n",
    "                    help='momentum')\n",
    "\n",
    "# model dataset\n",
    "parser.add_argument('--model', type=str, default='resnet50')\n",
    "parser.add_argument('--dataset', type=str, default='waterbirds',\n",
    "                    choices=['celeba', 'waterbirds'], help='dataset')\n",
    "\n",
    "# other setting\n",
    "parser.add_argument('--cosine', action='store_true',\n",
    "                    help='using cosine annealing')\n",
    "parser.add_argument('--warm', action='store_true',\n",
    "                    help='warm-up for large batch training')\n",
    "\n",
    "parser.add_argument('--image_embedding_dir', type=str, \n",
    "                    help='extracted image embedding')\n",
    "parser.add_argument('--text_embedding_dir', type=str, \n",
    "                    help='extracted text embedding')\n",
    "parser.add_argument('--train_target', type=str, default=\"class\", choices=[\"class\", \"spurious\", \"group\"]) # Label for training.\n",
    "parser.add_argument('--data_dir', type=str,\n",
    "                    help='folder, in which [metadata.csv] exists')\n",
    "parser.add_argument('--tl_method', type=str, default=\"linear_probing\", choices=[\"linear_probing\", \"adapter\", \"contrastive_adapter\"]\n",
    "                        ,help='transfer learning method')\n",
    "\n",
    "opt = parser.parse_args(args=[])   \n",
    "\n",
    "iterations = opt.lr_decay_epochs.split(',')\n",
    "opt.lr_decay_epochs = list([])\n",
    "for it in iterations:\n",
    "    opt.lr_decay_epochs.append(int(it))\n",
    "\n",
    "opt.model_name = '{}_{}_lr_{}_decay_{}_bsz_{}'.\\\n",
    "    format(opt.dataset, opt.model, opt.learning_rate, opt.weight_decay,\n",
    "            opt.batch_size)\n",
    "\n",
    "if opt.cosine:\n",
    "    opt.model_name = '{}_cosine'.format(opt.model_name)\n",
    "\n",
    "# warm-up for large-batch training,\n",
    "if opt.warm:\n",
    "    opt.model_name = '{}_warm'.format(opt.model_name)\n",
    "    opt.warmup_from = 0.01\n",
    "    opt.warm_epochs = 10\n",
    "    if opt.cosine:\n",
    "        eta_min = opt.learning_rate * (opt.lr_decay_rate ** 3)\n",
    "        opt.warmup_to = eta_min + (opt.learning_rate - eta_min) * (\n",
    "                1 + math.cos(math.pi * opt.warm_epochs / opt.epochs)) / 2\n",
    "    else:\n",
    "        opt.warmup_to = opt.learning_rate\n",
    "        \n",
    "if opt.dataset == 'celeba':\n",
    "    opt.n_cls = 2\n",
    "elif opt.dataset == 'waterbirds':\n",
    "    opt.n_cls = 2\n",
    "else:\n",
    "    raise ValueError('dataset not supported: {}'.format(opt.dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Probing  & Adapter\n",
    "- (Epoch default : 100)\n",
    "- Test 성능 모니터링하면 안 됨."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waterbirds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================= waterbirds_ft_on_class (iter. 1)=================\n",
      "Transfer Learning using [linear_probing]\n",
      "Train Target : class (Land bird(0) / Water bird(1))\n",
      "Load Data Loader (train, validation, test)\n",
      "Set Classifier : linear_probing\n",
      "Off-the-shelf prediction module : [Linear Classifier]\n",
      "Set Optimizer\n",
      "--- Epoch 1 ---\n",
      "Train(class): [0][1/2]\tBT 0.002 (0.040)\tDT 0.001 (0.039)\tloss 0.173 (0.360)\tAcc@1 0.930 (0.838)\n",
      "Train(class): {'worst_acc': 0.30357142857142855, 'acc_0_0': 0.9488279016580904, 'acc_0_1': 0.5543478260869565, 'acc_1_0': 0.30357142857142855, 'acc_1_1': 0.804162724692526, 'mean_acc': 0.8942648592283629}\n",
      "Val(class): {'weighted_mean_acc': 0.9640794620449225, 'worst_acc': 0.37593984962406013, 'acc_0_0': 0.9957173447537473, 'acc_0_1': 0.5944206008583691, 'acc_1_0': 0.37593984962406013, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.7664720600500416}\n",
      "Val(spurious): {'weighted_mean_acc': 0.959730755973583, 'worst_acc': 0.4055793991416309, 'acc_0_0': 0.9957173447537473, 'acc_0_1': 0.4055793991416309, 'acc_1_0': 0.6240601503759399, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.7206005004170142}\n",
      "Test(class): {'weighted_mean_acc': 0.9596334780651717, 'worst_acc': 0.411214953271028, 'acc_0_0': 0.9951219512195122, 'acc_0_1': 0.5689578713968958, 'acc_1_0': 0.411214953271028, 'acc_1_1': 0.9392523364485982, 'mean_acc': 0.7583707283396617}\n",
      "Test(spurious): {'weighted_mean_acc': 0.9564150062383322, 'worst_acc': 0.4310421286031042, 'acc_0_0': 0.9951219512195122, 'acc_0_1': 0.4310421286031042, 'acc_1_0': 0.5887850467289719, 'acc_1_1': 0.9392523364485982, 'mean_acc': 0.7243700379703141}\n",
      "--- Epoch 2 ---\n",
      "Train(class): [0][1/2]\tBT 0.006 (0.037)\tDT 0.005 (0.036)\tloss 0.070 (0.141)\tAcc@1 0.977 (0.957)\n",
      "Train(class): {'worst_acc': 0.42857142857142855, 'acc_0_0': 0.9922813036020584, 'acc_0_1': 0.6304347826086957, 'acc_1_0': 0.42857142857142855, 'acc_1_1': 0.9366130558183539, 'mean_acc': 0.959541188738269}\n",
      "Val(class): {'weighted_mean_acc': 0.9656444555574946, 'worst_acc': 0.22556390977443608, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.8562231759656652, 'acc_1_0': 0.22556390977443608, 'acc_1_1': 0.9172932330827067, 'mean_acc': 0.8482068390325271}\n",
      "Val(spurious): {'weighted_mean_acc': 0.9447157191996631, 'worst_acc': 0.14377682403433475, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.14377682403433475, 'acc_1_0': 0.7744360902255639, 'acc_1_1': 0.9172932330827067, 'mean_acc': 0.6321934945788157}\n",
      "Test(class): {'weighted_mean_acc': 0.9562827995895034, 'worst_acc': 0.2570093457943925, 'acc_0_0': 0.9991130820399113, 'acc_0_1': 0.8643015521064301, 'acc_1_0': 0.2570093457943925, 'acc_1_1': 0.867601246105919, 'mean_acc': 0.8498446668967898}\n",
      "Test(spurious): {'weighted_mean_acc': 0.9339995833190575, 'worst_acc': 0.13569844789356986, 'acc_0_0': 0.9991130820399113, 'acc_0_1': 0.13569844789356986, 'acc_1_0': 0.7429906542056075, 'acc_1_1': 0.867601246105919, 'mean_acc': 0.6201242664825681}\n",
      "===============\n",
      "best epoch : 2\n",
      "best validation accuracy on class: {'weighted_mean_acc': 0.9656444555574946, 'worst_acc': 0.22556390977443608, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.8562231759656652, 'acc_1_0': 0.22556390977443608, 'acc_1_1': 0.9172932330827067, 'mean_acc': 0.8482068390325271}\n",
      "best test accuracy (class): {'weighted_mean_acc': 0.9562827995895034, 'worst_acc': 0.2570093457943925, 'acc_0_0': 0.9991130820399113, 'acc_0_1': 0.8643015521064301, 'acc_1_0': 0.2570093457943925, 'acc_1_1': 0.867601246105919, 'mean_acc': 0.8498446668967898}\n",
      "best test accuracy (spurious): {'weighted_mean_acc': 0.9339995833190575, 'worst_acc': 0.13569844789356986, 'acc_0_0': 0.9991130820399113, 'acc_0_1': 0.13569844789356986, 'acc_1_0': 0.7429906542056075, 'acc_1_1': 0.867601246105919, 'mean_acc': 0.6201242664825681}\n",
      "================= waterbirds_ft_on_class (iter. 2)=================\n",
      "Transfer Learning using [linear_probing]\n",
      "Train Target : class (Land bird(0) / Water bird(1))\n",
      "Load Data Loader (train, validation, test)\n",
      "Set Classifier : linear_probing\n",
      "Off-the-shelf prediction module : [Linear Classifier]\n",
      "Set Optimizer\n",
      "--- Epoch 1 ---\n",
      "Train(class): [0][1/2]\tBT 0.005 (0.039)\tDT 0.004 (0.037)\tloss 0.306 (0.527)\tAcc@1 0.922 (0.799)\n",
      "Train(class): {'worst_acc': 0.23214285714285715, 'acc_0_0': 0.9285305889079474, 'acc_0_1': 0.532608695652174, 'acc_1_0': 0.23214285714285715, 'acc_1_1': 0.7672658467360454, 'mean_acc': 0.8696558915537018}\n",
      "Val(class): {'weighted_mean_acc': 0.9645781482497542, 'worst_acc': 0.18796992481203006, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.7103004291845494, 'acc_1_0': 0.18796992481203006, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.7898248540450375}\n",
      "Val(spurious): {'weighted_mean_acc': 0.9557265960789776, 'worst_acc': 0.28969957081545067, 'acc_0_0': 0.9978586723768736, 'acc_0_1': 0.28969957081545067, 'acc_1_0': 0.8120300751879699, 'acc_1_1': 0.9398496240601504, 'mean_acc': 0.69557964970809}\n",
      "Test(class): {'weighted_mean_acc': 0.9558948207854294, 'worst_acc': 0.23052959501557632, 'acc_0_0': 0.9991130820399113, 'acc_0_1': 0.692239467849224, 'acc_1_0': 0.23052959501557632, 'acc_1_1': 0.897196261682243, 'mean_acc': 0.7832240248532966}\n",
      "Test(spurious): {'weighted_mean_acc': 0.9474352917738933, 'worst_acc': 0.30776053215077603, 'acc_0_0': 0.9991130820399113, 'acc_0_1': 0.30776053215077603, 'acc_1_0': 0.7694704049844237, 'acc_1_1': 0.897196261682243, 'mean_acc': 0.6933034173282706}\n",
      "--- Epoch 2 ---\n",
      "Train(class): [0][1/2]\tBT 0.003 (0.038)\tDT 0.001 (0.036)\tloss 0.169 (0.149)\tAcc@1 0.969 (0.959)\n",
      "Train(class): {'worst_acc': 0.5, 'acc_0_0': 0.9928530588907948, 'acc_0_1': 0.6304347826086957, 'acc_1_0': 0.5, 'acc_1_1': 0.9290444654683065, 'mean_acc': 0.9591240875912409}\n",
      "Val(class): {'weighted_mean_acc': 0.9654960455364847, 'worst_acc': 0.5864661654135338, 'acc_0_0': 0.9892933618843683, 'acc_0_1': 0.6030042918454935, 'acc_1_0': 0.5864661654135338, 'acc_1_1': 0.9699248120300752, 'mean_acc': 0.79232693911593}\n",
      "Val(spurious): {'weighted_mean_acc': 0.9555711674559102, 'worst_acc': 0.3969957081545064, 'acc_0_0': 0.9892933618843683, 'acc_0_1': 0.3969957081545064, 'acc_1_0': 0.41353383458646614, 'acc_1_1': 0.9699248120300752, 'mean_acc': 0.6930775646371977}\n",
      "Test(class): {'weighted_mean_acc': 0.9601832301274924, 'worst_acc': 0.5494456762749446, 'acc_0_0': 0.9902439024390244, 'acc_0_1': 0.5494456762749446, 'acc_1_0': 0.5919003115264797, 'acc_1_1': 0.9517133956386293, 'mean_acc': 0.7702795995857784}\n",
      "Test(spurious): {'weighted_mean_acc': 0.9542418654222831, 'worst_acc': 0.40809968847352024, 'acc_0_0': 0.9902439024390244, 'acc_0_1': 0.45055432372505544, 'acc_1_0': 0.40809968847352024, 'acc_1_1': 0.9517133956386293, 'mean_acc': 0.711425612702796}\n",
      "===============\n",
      "best epoch : 2\n",
      "best validation accuracy on class: {'weighted_mean_acc': 0.9654960455364847, 'worst_acc': 0.5864661654135338, 'acc_0_0': 0.9892933618843683, 'acc_0_1': 0.6030042918454935, 'acc_1_0': 0.5864661654135338, 'acc_1_1': 0.9699248120300752, 'mean_acc': 0.79232693911593}\n",
      "best test accuracy (class): {'weighted_mean_acc': 0.9601832301274924, 'worst_acc': 0.5494456762749446, 'acc_0_0': 0.9902439024390244, 'acc_0_1': 0.5494456762749446, 'acc_1_0': 0.5919003115264797, 'acc_1_1': 0.9517133956386293, 'mean_acc': 0.7702795995857784}\n",
      "best test accuracy (spurious): {'weighted_mean_acc': 0.9542418654222831, 'worst_acc': 0.40809968847352024, 'acc_0_0': 0.9902439024390244, 'acc_0_1': 0.45055432372505544, 'acc_1_0': 0.40809968847352024, 'acc_1_1': 0.9517133956386293, 'mean_acc': 0.711425612702796}\n",
      "================= waterbirds_ft_on_spurious (iter. 1)=================\n",
      "Transfer Learning using [linear_probing]\n",
      "Train Target : spurious (Land background(0) / Water background(1)\n",
      "Load Data Loader (train, validation, test)\n",
      "Set Classifier : linear_probing\n",
      "Off-the-shelf prediction module : [Linear Classifier]\n",
      "Set Optimizer\n",
      "--- Epoch 1 ---\n",
      "Train(spurious): [0][1/2]\tBT 0.002 (0.037)\tDT 0.001 (0.035)\tloss 0.097 (0.363)\tAcc@1 0.969 (0.827)\n",
      "Train(spurious): {'worst_acc': 0.6413043478260869, 'acc_0_0': 0.9293882218410521, 'acc_0_1': 0.6413043478260869, 'acc_1_0': 0.6428571428571429, 'acc_1_1': 0.8278145695364238, 'mean_acc': 0.8925964546402503}\n",
      "Val(spurious): {'weighted_mean_acc': 0.9747775269983613, 'worst_acc': 0.631578947368421, 'acc_0_0': 0.9850107066381156, 'acc_0_1': 0.8261802575107297, 'acc_1_0': 0.631578947368421, 'acc_1_1': 0.9849624060150376, 'mean_acc': 0.8840700583819849}\n",
      "Val(class): {'weighted_mean_acc': 0.9466709203258653, 'worst_acc': 0.17381974248927037, 'acc_0_0': 0.9850107066381156, 'acc_0_1': 0.17381974248927037, 'acc_1_0': 0.3684210526315789, 'acc_1_1': 0.9849624060150376, 'mean_acc': 0.6013344453711427}\n",
      "Test(class): {'weighted_mean_acc': 0.9469572458398365, 'worst_acc': 0.1844789356984479, 'acc_0_0': 0.9862527716186252, 'acc_0_1': 0.1844789356984479, 'acc_1_0': 0.40809968847352024, 'acc_1_1': 0.9781931464174455, 'mean_acc': 0.609250949257853}\n",
      "Test(spurious): {'weighted_mean_acc': 0.9733189953221404, 'worst_acc': 0.5919003115264797, 'acc_0_0': 0.9862527716186252, 'acc_0_1': 0.8155210643015521, 'acc_1_0': 0.5919003115264797, 'acc_1_1': 0.9781931464174455, 'mean_acc': 0.8752157404211253}\n",
      "--- Epoch 2 ---\n",
      "Train(spurious): [0][1/2]\tBT 0.002 (0.037)\tDT 0.001 (0.035)\tloss 0.072 (0.085)\tAcc@1 0.969 (0.975)\n",
      "Train(spurious): {'worst_acc': 0.5892857142857143, 'acc_0_0': 0.9902801600914809, 'acc_0_1': 0.8152173913043478, 'acc_1_0': 0.5892857142857143, 'acc_1_1': 0.9668874172185431, 'mean_acc': 0.9737226277372263}\n",
      "Val(spurious): {'weighted_mean_acc': 0.9804541200866821, 'worst_acc': 0.7443609022556391, 'acc_0_0': 0.9892933618843683, 'acc_0_1': 0.8583690987124464, 'acc_1_0': 0.7443609022556391, 'acc_1_1': 0.9849624060150376, 'mean_acc': 0.9107589658048374}\n",
      "Val(class): {'weighted_mean_acc': 0.9472428059534288, 'worst_acc': 0.14163090128755365, 'acc_0_0': 0.9892933618843683, 'acc_0_1': 0.14163090128755365, 'acc_1_0': 0.2556390977443609, 'acc_1_1': 0.9849624060150376, 'mean_acc': 0.5779816513761468}\n",
      "Test(class): {'weighted_mean_acc': 0.9480127455623971, 'worst_acc': 0.164079822616408, 'acc_0_0': 0.9902439024390244, 'acc_0_1': 0.164079822616408, 'acc_1_0': 0.3161993769470405, 'acc_1_1': 0.9781931464174455, 'mean_acc': 0.5926820849154297}\n",
      "Test(spurious): {'weighted_mean_acc': 0.9780866344117444, 'worst_acc': 0.6838006230529595, 'acc_0_0': 0.9902439024390244, 'acc_0_1': 0.835920177383592, 'acc_1_0': 0.6838006230529595, 'acc_1_1': 0.9781931464174455, 'mean_acc': 0.8948912668277529}\n",
      "===============\n",
      "best epoch : 2\n",
      "best validation accuracy on spurious: {'weighted_mean_acc': 0.9804541200866821, 'worst_acc': 0.7443609022556391, 'acc_0_0': 0.9892933618843683, 'acc_0_1': 0.8583690987124464, 'acc_1_0': 0.7443609022556391, 'acc_1_1': 0.9849624060150376, 'mean_acc': 0.9107589658048374}\n",
      "best test accuracy (class): {'weighted_mean_acc': 0.9480127455623971, 'worst_acc': 0.164079822616408, 'acc_0_0': 0.9902439024390244, 'acc_0_1': 0.164079822616408, 'acc_1_0': 0.3161993769470405, 'acc_1_1': 0.9781931464174455, 'mean_acc': 0.5926820849154297}\n",
      "best test accuracy (spurious): {'weighted_mean_acc': 0.9780866344117444, 'worst_acc': 0.6838006230529595, 'acc_0_0': 0.9902439024390244, 'acc_0_1': 0.835920177383592, 'acc_1_0': 0.6838006230529595, 'acc_1_1': 0.9781931464174455, 'mean_acc': 0.8948912668277529}\n",
      "================= waterbirds_ft_on_spurious (iter. 2)=================\n",
      "Transfer Learning using [linear_probing]\n",
      "Train Target : spurious (Land background(0) / Water background(1)\n",
      "Load Data Loader (train, validation, test)\n",
      "Set Classifier : linear_probing\n",
      "Off-the-shelf prediction module : [Linear Classifier]\n",
      "Set Optimizer\n",
      "--- Epoch 1 ---\n",
      "Train(spurious): [0][1/2]\tBT 0.003 (0.037)\tDT 0.001 (0.035)\tloss 0.099 (0.356)\tAcc@1 0.969 (0.861)\n",
      "Train(spurious): {'worst_acc': 0.6785714285714286, 'acc_0_0': 0.949685534591195, 'acc_0_1': 0.7010869565217391, 'acc_1_0': 0.6785714285714286, 'acc_1_1': 0.8382213812677389, 'mean_acc': 0.9124087591240876}\n",
      "Val(spurious): {'weighted_mean_acc': 0.975761787678706, 'worst_acc': 0.7296137339055794, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.7296137339055794, 'acc_1_0': 0.7819548872180451, 'acc_1_1': 0.9699248120300752, 'mean_acc': 0.8648874061718098}\n",
      "Val(class): {'weighted_mean_acc': 0.9515539040295732, 'worst_acc': 0.21804511278195488, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.2703862660944206, 'acc_1_0': 0.21804511278195488, 'acc_1_1': 0.9699248120300752, 'mean_acc': 0.6238532110091743}\n",
      "Test(class): {'weighted_mean_acc': 0.950185916463681, 'worst_acc': 0.24610591900311526, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.26252771618625276, 'acc_1_0': 0.24610591900311526, 'acc_1_1': 0.9672897196261683, 'mean_acc': 0.622885743872972}\n",
      "Test(spurious): {'weighted_mean_acc': 0.9743414823359435, 'worst_acc': 0.7374722838137472, 'acc_0_0': 0.9924611973392461, 'acc_0_1': 0.7374722838137472, 'acc_1_0': 0.7538940809968847, 'acc_1_1': 0.9672897196261683, 'mean_acc': 0.8639972385226096}\n",
      "--- Epoch 2 ---\n",
      "Train(spurious): [0][1/2]\tBT 0.005 (0.036)\tDT 0.003 (0.034)\tloss 0.094 (0.080)\tAcc@1 0.977 (0.972)\n",
      "Train(spurious): {'worst_acc': 0.7321428571428571, 'acc_0_0': 0.9902801600914809, 'acc_0_1': 0.8097826086956522, 'acc_1_0': 0.7321428571428571, 'acc_1_1': 0.9583727530747398, 'mean_acc': 0.9733055265901981}\n",
      "Val(spurious): {'weighted_mean_acc': 0.9833497480365851, 'worst_acc': 0.7518796992481203, 'acc_0_0': 0.9914346895074947, 'acc_0_1': 0.8476394849785408, 'acc_1_0': 0.7518796992481203, 'acc_1_1': 0.9924812030075187, 'mean_acc': 0.9090909090909091}\n",
      "Val(class): {'weighted_mean_acc': 0.9507862738853261, 'worst_acc': 0.15236051502145923, 'acc_0_0': 0.9914346895074947, 'acc_0_1': 0.15236051502145923, 'acc_1_0': 0.24812030075187969, 'acc_1_1': 0.9924812030075187, 'mean_acc': 0.5829858215179317}\n",
      "Test(class): {'weighted_mean_acc': 0.9472611531779802, 'worst_acc': 0.16585365853658537, 'acc_0_0': 0.991130820399113, 'acc_0_1': 0.16585365853658537, 'acc_1_0': 0.278816199376947, 'acc_1_1': 0.9735202492211839, 'mean_acc': 0.5890576458405247}\n",
      "Test(spurious): {'weighted_mean_acc': 0.978072089803715, 'worst_acc': 0.721183800623053, 'acc_0_0': 0.991130820399113, 'acc_0_1': 0.8341463414634146, 'acc_1_0': 0.721183800623053, 'acc_1_1': 0.9735202492211839, 'mean_acc': 0.8981705212288574}\n",
      "===============\n",
      "best epoch : 2\n",
      "best validation accuracy on spurious: {'weighted_mean_acc': 0.9833497480365851, 'worst_acc': 0.7518796992481203, 'acc_0_0': 0.9914346895074947, 'acc_0_1': 0.8476394849785408, 'acc_1_0': 0.7518796992481203, 'acc_1_1': 0.9924812030075187, 'mean_acc': 0.9090909090909091}\n",
      "best test accuracy (class): {'weighted_mean_acc': 0.9472611531779802, 'worst_acc': 0.16585365853658537, 'acc_0_0': 0.991130820399113, 'acc_0_1': 0.16585365853658537, 'acc_1_0': 0.278816199376947, 'acc_1_1': 0.9735202492211839, 'mean_acc': 0.5890576458405247}\n",
      "best test accuracy (spurious): {'weighted_mean_acc': 0.978072089803715, 'worst_acc': 0.721183800623053, 'acc_0_0': 0.991130820399113, 'acc_0_1': 0.8341463414634146, 'acc_1_0': 0.721183800623053, 'acc_1_1': 0.9735202492211839, 'mean_acc': 0.8981705212288574}\n",
      "================= waterbirds_ft_on_class (iter. 1)=================\n",
      "Transfer Learning using [adapter]\n",
      "Train Target : class (Land bird(0) / Water bird(1))\n",
      "Load Data Loader (train, validation, test)\n",
      "Set Classifier : adapter\n",
      "Off-the-shelf prediction module : [Adapter + temperatured-image-text-normalized-prediction]\n",
      "Set Optimizer\n",
      "--- Epoch 1 ---\n",
      "Train(class): [0][1/2]\tBT 0.004 (0.034)\tDT 0.001 (0.032)\tloss 0.326 (2.183)\tAcc@1 0.961 (0.894)\n",
      "Train(class): {'worst_acc': 0.25, 'acc_0_0': 0.9831332189822756, 'acc_0_1': 0.5760869565217391, 'acc_1_0': 0.25, 'acc_1_1': 0.8145695364238411, 'mean_acc': 0.921793534932221}\n",
      "Val(class): {'weighted_mean_acc': 0.965412043132466, 'worst_acc': 0.48872180451127817, 'acc_0_0': 0.9914346895074947, 'acc_0_1': 0.6330472103004292, 'acc_1_0': 0.48872180451127817, 'acc_1_1': 0.9624060150375939, 'mean_acc': 0.7931609674728941}\n",
      "Val(spurious): {'weighted_mean_acc': 0.9554645526940133, 'worst_acc': 0.3669527896995708, 'acc_0_0': 0.9914346895074947, 'acc_0_1': 0.3669527896995708, 'acc_1_0': 0.5112781954887218, 'acc_1_1': 0.9624060150375939, 'mean_acc': 0.6922435362802335}\n",
      "Test(class): {'weighted_mean_acc': 0.9554264340654347, 'worst_acc': 0.5311526479750779, 'acc_0_0': 0.9875831485587583, 'acc_0_1': 0.5840354767184035, 'acc_1_0': 0.5311526479750779, 'acc_1_1': 0.9361370716510904, 'mean_acc': 0.774249223334484}\n",
      "Test(spurious): {'weighted_mean_acc': 0.9482493428109179, 'worst_acc': 0.41596452328159644, 'acc_0_0': 0.9875831485587583, 'acc_0_1': 0.41596452328159644, 'acc_1_0': 0.4688473520249221, 'acc_1_1': 0.9361370716510904, 'mean_acc': 0.7019330341732827}\n",
      "--- Epoch 2 ---\n",
      "Train(class): [0][1/2]\tBT 0.005 (0.038)\tDT 0.001 (0.034)\tloss 0.381 (0.199)\tAcc@1 0.961 (0.960)\n",
      "Train(class): {'worst_acc': 0.4642857142857143, 'acc_0_0': 0.9882790165809033, 'acc_0_1': 0.6521739130434783, 'acc_1_0': 0.4642857142857143, 'acc_1_1': 0.9394512771996215, 'mean_acc': 0.9584984358706986}\n",
      "Val(class): {'weighted_mean_acc': 0.9669636575706935, 'worst_acc': 0.48872180451127817, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.6759656652360515, 'acc_1_0': 0.48872180451127817, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.8098415346121768}\n",
      "Val(spurious): {'weighted_mean_acc': 0.9537223210898698, 'worst_acc': 0.3240343347639485, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.3240343347639485, 'acc_1_0': 0.5112781954887218, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.6755629691409508}\n",
      "Test(class): {'weighted_mean_acc': 0.9584761665791477, 'worst_acc': 0.5280373831775701, 'acc_0_0': 0.9902439024390244, 'acc_0_1': 0.6496674057649667, 'acc_1_0': 0.5280373831775701, 'acc_1_1': 0.9299065420560748, 'mean_acc': 0.7997928891957197}\n",
      "Test(spurious): {'weighted_mean_acc': 0.9463348123858559, 'worst_acc': 0.35033259423503327, 'acc_0_0': 0.9902439024390244, 'acc_0_1': 0.35033259423503327, 'acc_1_0': 0.4719626168224299, 'acc_1_1': 0.9299065420560748, 'mean_acc': 0.6770797376596479}\n",
      "===============\n",
      "best epoch : 2\n",
      "best validation accuracy on class: {'weighted_mean_acc': 0.9669636575706935, 'worst_acc': 0.48872180451127817, 'acc_0_0': 0.9935760171306209, 'acc_0_1': 0.6759656652360515, 'acc_1_0': 0.48872180451127817, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.8098415346121768}\n",
      "best test accuracy (class): {'weighted_mean_acc': 0.9584761665791477, 'worst_acc': 0.5280373831775701, 'acc_0_0': 0.9902439024390244, 'acc_0_1': 0.6496674057649667, 'acc_1_0': 0.5280373831775701, 'acc_1_1': 0.9299065420560748, 'mean_acc': 0.7997928891957197}\n",
      "best test accuracy (spurious): {'weighted_mean_acc': 0.9463348123858559, 'worst_acc': 0.35033259423503327, 'acc_0_0': 0.9902439024390244, 'acc_0_1': 0.35033259423503327, 'acc_1_0': 0.4719626168224299, 'acc_1_1': 0.9299065420560748, 'mean_acc': 0.6770797376596479}\n",
      "================= waterbirds_ft_on_class (iter. 2)=================\n",
      "Transfer Learning using [adapter]\n",
      "Train Target : class (Land bird(0) / Water bird(1))\n",
      "Load Data Loader (train, validation, test)\n",
      "Set Classifier : adapter\n",
      "Off-the-shelf prediction module : [Adapter + temperatured-image-text-normalized-prediction]\n",
      "Set Optimizer\n",
      "--- Epoch 1 ---\n",
      "Train(class): [0][1/2]\tBT 0.004 (0.038)\tDT 0.001 (0.035)\tloss 7.296 (8.444)\tAcc@1 0.789 (0.743)\n",
      "Train(class): {'worst_acc': 0.02459791863765374, 'acc_0_0': 0.9711263579188107, 'acc_0_1': 0.9619565217391305, 'acc_1_0': 0.05357142857142857, 'acc_1_1': 0.02459791863765374, 'mean_acc': 0.7514077163712201}\n",
      "Val(class): {'weighted_mean_acc': 0.7678831964731216, 'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 1.0, 'acc_1_0': 0.0, 'acc_1_1': 0.0, 'mean_acc': 0.7781484570475397}\n",
      "Val(spurious): {'weighted_mean_acc': 0.7411887217313051, 'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 0.0, 'acc_1_0': 1.0, 'acc_1_1': 0.0, 'mean_acc': 0.5004170141784821}\n",
      "Test(class): {'weighted_mean_acc': 0.7678831964731216, 'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 1.0, 'acc_1_0': 0.0, 'acc_1_1': 0.0, 'mean_acc': 0.7783914394200897}\n",
      "Test(spurious): {'weighted_mean_acc': 0.7411887217313051, 'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 0.0, 'acc_1_0': 1.0, 'acc_1_1': 0.0, 'mean_acc': 0.5}\n",
      "--- Epoch 2 ---\n",
      "Train(class): [0][1/2]\tBT 0.004 (0.041)\tDT 0.001 (0.038)\tloss 4.331 (6.256)\tAcc@1 0.820 (0.776)\n",
      "Train(class): {'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 1.0, 'acc_1_0': 0.0, 'acc_1_1': 0.0, 'mean_acc': 0.7678832116788321}\n",
      "Val(class): {'weighted_mean_acc': 0.7678831964731216, 'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 1.0, 'acc_1_0': 0.0, 'acc_1_1': 0.0, 'mean_acc': 0.7781484570475397}\n",
      "Val(spurious): {'weighted_mean_acc': 0.7411887217313051, 'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 0.0, 'acc_1_0': 1.0, 'acc_1_1': 0.0, 'mean_acc': 0.5004170141784821}\n",
      "Test(class): {'weighted_mean_acc': 0.7678831964731216, 'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 1.0, 'acc_1_0': 0.0, 'acc_1_1': 0.0, 'mean_acc': 0.7783914394200897}\n",
      "Test(spurious): {'weighted_mean_acc': 0.7411887217313051, 'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 0.0, 'acc_1_0': 1.0, 'acc_1_1': 0.0, 'mean_acc': 0.5}\n",
      "===============\n",
      "best epoch : 1\n",
      "best validation accuracy on class: {'weighted_mean_acc': 0.7678831964731216, 'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 1.0, 'acc_1_0': 0.0, 'acc_1_1': 0.0, 'mean_acc': 0.7781484570475397}\n",
      "best test accuracy (class): {'weighted_mean_acc': 0.7678831964731216, 'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 1.0, 'acc_1_0': 0.0, 'acc_1_1': 0.0, 'mean_acc': 0.7783914394200897}\n",
      "best test accuracy (spurious): {'weighted_mean_acc': 0.7411887217313051, 'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 0.0, 'acc_1_0': 1.0, 'acc_1_1': 0.0, 'mean_acc': 0.5}\n",
      "================= waterbirds_ft_on_spurious (iter. 1)=================\n",
      "Transfer Learning using [adapter]\n",
      "Train Target : spurious (Land background(0) / Water background(1)\n",
      "Load Data Loader (train, validation, test)\n",
      "Set Classifier : adapter\n",
      "Off-the-shelf prediction module : [Adapter + temperatured-image-text-normalized-prediction]\n",
      "Set Optimizer\n",
      "--- Epoch 1 ---\n",
      "Train(spurious): [0][1/2]\tBT 0.041 (0.039)\tDT 0.037 (0.035)\tloss 0.500 (1.988)\tAcc@1 0.961 (0.908)\n",
      "Train(spurious): {'worst_acc': 0.6607142857142857, 'acc_0_0': 0.9545454545454546, 'acc_0_1': 0.8315217391304348, 'acc_1_0': 0.6607142857142857, 'acc_1_1': 0.9148533585619678, 'mean_acc': 0.9376433785192909}\n",
      "Val(spurious): {'weighted_mean_acc': 0.9735308175362539, 'worst_acc': 0.7939914163090128, 'acc_0_0': 0.9914346895074947, 'acc_0_1': 0.7939914163090128, 'acc_1_0': 0.7969924812030075, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.8890742285237698}\n",
      "Val(class): {'weighted_mean_acc': 0.9440309217663673, 'worst_acc': 0.20300751879699247, 'acc_0_0': 0.9914346895074947, 'acc_0_1': 0.20600858369098712, 'acc_1_0': 0.20300751879699247, 'acc_1_1': 0.9548872180451128, 'mean_acc': 0.5946622185154296}\n",
      "Test(class): {'weighted_mean_acc': 0.9466071825634452, 'worst_acc': 0.2057649667405765, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.2057649667405765, 'acc_1_0': 0.22118380062305296, 'acc_1_1': 0.956386292834891, 'mean_acc': 0.5975146703486365}\n",
      "Test(spurious): {'weighted_mean_acc': 0.9757012196380888, 'worst_acc': 0.778816199376947, 'acc_0_0': 0.9942350332594235, 'acc_0_1': 0.7942350332594235, 'acc_1_0': 0.778816199376947, 'acc_1_1': 0.956386292834891, 'mean_acc': 0.8883327580255437}\n",
      "--- Epoch 2 ---\n",
      "Train(spurious): [0][1/2]\tBT 0.004 (0.040)\tDT 0.001 (0.037)\tloss 0.229 (0.176)\tAcc@1 0.977 (0.977)\n",
      "Train(spurious): {'worst_acc': 0.7678571428571429, 'acc_0_0': 0.9911377930245855, 'acc_0_1': 0.8804347826086957, 'acc_1_0': 0.7678571428571429, 'acc_1_1': 0.9668874172185431, 'mean_acc': 0.9789363920750782}\n",
      "Val(spurious): {'weighted_mean_acc': 0.9804541200866821, 'worst_acc': 0.7443609022556391, 'acc_0_0': 0.9892933618843683, 'acc_0_1': 0.8583690987124464, 'acc_1_0': 0.7443609022556391, 'acc_1_1': 0.9849624060150376, 'mean_acc': 0.9107589658048374}\n",
      "Val(class): {'weighted_mean_acc': 0.9472428059534288, 'worst_acc': 0.14163090128755365, 'acc_0_0': 0.9892933618843683, 'acc_0_1': 0.14163090128755365, 'acc_1_0': 0.2556390977443609, 'acc_1_1': 0.9849624060150376, 'mean_acc': 0.5779816513761468}\n",
      "Test(class): {'weighted_mean_acc': 0.9465729559070196, 'worst_acc': 0.15432372505543238, 'acc_0_0': 0.9893569844789357, 'acc_0_1': 0.15432372505543238, 'acc_1_0': 0.2803738317757009, 'acc_1_1': 0.9781931464174455, 'mean_acc': 0.5845702450811184}\n",
      "Test(spurious): {'weighted_mean_acc': 0.9782323932199742, 'worst_acc': 0.719626168224299, 'acc_0_0': 0.9893569844789357, 'acc_0_1': 0.8456762749445677, 'acc_1_0': 0.719626168224299, 'acc_1_1': 0.9781931464174455, 'mean_acc': 0.9023127373144633}\n",
      "===============\n",
      "best epoch : 2\n",
      "best validation accuracy on spurious: {'weighted_mean_acc': 0.9804541200866821, 'worst_acc': 0.7443609022556391, 'acc_0_0': 0.9892933618843683, 'acc_0_1': 0.8583690987124464, 'acc_1_0': 0.7443609022556391, 'acc_1_1': 0.9849624060150376, 'mean_acc': 0.9107589658048374}\n",
      "best test accuracy (class): {'weighted_mean_acc': 0.9465729559070196, 'worst_acc': 0.15432372505543238, 'acc_0_0': 0.9893569844789357, 'acc_0_1': 0.15432372505543238, 'acc_1_0': 0.2803738317757009, 'acc_1_1': 0.9781931464174455, 'mean_acc': 0.5845702450811184}\n",
      "best test accuracy (spurious): {'weighted_mean_acc': 0.9782323932199742, 'worst_acc': 0.719626168224299, 'acc_0_0': 0.9893569844789357, 'acc_0_1': 0.8456762749445677, 'acc_1_0': 0.719626168224299, 'acc_1_1': 0.9781931464174455, 'mean_acc': 0.9023127373144633}\n",
      "================= waterbirds_ft_on_spurious (iter. 2)=================\n",
      "Transfer Learning using [adapter]\n",
      "Train Target : spurious (Land background(0) / Water background(1)\n",
      "Load Data Loader (train, validation, test)\n",
      "Set Classifier : adapter\n",
      "Off-the-shelf prediction module : [Adapter + temperatured-image-text-normalized-prediction]\n",
      "Set Optimizer\n",
      "--- Epoch 1 ---\n",
      "Train(spurious): [0][1/2]\tBT 0.004 (0.047)\tDT 0.001 (0.043)\tloss 13.737 (10.488)\tAcc@1 0.672 (0.716)\n",
      "Train(spurious): {'worst_acc': 0.010869565217391304, 'acc_0_0': 0.9779874213836478, 'acc_0_1': 0.010869565217391304, 'acc_1_0': 0.9642857142857143, 'acc_1_1': 0.015137180700094607, 'mean_acc': 0.7284671532846715}\n",
      "Val(spurious): {'weighted_mean_acc': 0.7411887217313051, 'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 0.0, 'acc_1_0': 1.0, 'acc_1_1': 0.0, 'mean_acc': 0.5004170141784821}\n",
      "Val(class): {'weighted_mean_acc': 0.7678831964731216, 'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 1.0, 'acc_1_0': 0.0, 'acc_1_1': 0.0, 'mean_acc': 0.7781484570475397}\n",
      "Test(class): {'weighted_mean_acc': 0.7678831964731216, 'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 1.0, 'acc_1_0': 0.0, 'acc_1_1': 0.0, 'mean_acc': 0.7783914394200897}\n",
      "Test(spurious): {'weighted_mean_acc': 0.7411887217313051, 'worst_acc': 0.0, 'acc_0_0': 1.0, 'acc_0_1': 0.0, 'acc_1_0': 1.0, 'acc_1_1': 0.0, 'mean_acc': 0.5}\n",
      "--- Epoch 2 ---\n",
      "Train(spurious): [0][1/2]\tBT 0.004 (0.039)\tDT 0.001 (0.035)\tloss 7.056 (10.391)\tAcc@1 0.711 (0.733)\n",
      "Train(spurious): {'worst_acc': 0.3623462630085147, 'acc_0_0': 0.9857061177815895, 'acc_0_1': 0.3804347826086957, 'acc_1_0': 0.8571428571428571, 'acc_1_1': 0.3623462630085147, 'mean_acc': 0.8235662148070907}\n",
      "Val(spurious): {'weighted_mean_acc': 0.9360916687233494, 'worst_acc': 0.8045112781954887, 'acc_0_0': 0.9271948608137045, 'acc_0_1': 0.907725321888412, 'acc_1_0': 0.8045112781954887, 'acc_1_1': 0.9774436090225563, 'mean_acc': 0.9115929941618015}\n",
      "Val(class): {'weighted_mean_acc': 0.8976874594125805, 'worst_acc': 0.09227467811158799, 'acc_0_0': 0.9271948608137045, 'acc_0_1': 0.09227467811158799, 'acc_1_0': 0.19548872180451127, 'acc_1_1': 0.9774436090225563, 'mean_acc': 0.5271059216013344}\n",
      "Test(class): {'weighted_mean_acc': 0.893833176641686, 'worst_acc': 0.08337028824833703, 'acc_0_0': 0.9250554323725055, 'acc_0_1': 0.08337028824833703, 'acc_1_0': 0.278816199376947, 'acc_1_1': 0.9641744548286605, 'mean_acc': 0.5302036589575423}\n",
      "Test(spurious): {'weighted_mean_acc': 0.93097443254832, 'worst_acc': 0.721183800623053, 'acc_0_0': 0.9250554323725055, 'acc_0_1': 0.916629711751663, 'acc_1_0': 0.721183800623053, 'acc_1_1': 0.9641744548286605, 'mean_acc': 0.903520883672765}\n",
      "===============\n",
      "best epoch : 2\n",
      "best validation accuracy on spurious: {'weighted_mean_acc': 0.9360916687233494, 'worst_acc': 0.8045112781954887, 'acc_0_0': 0.9271948608137045, 'acc_0_1': 0.907725321888412, 'acc_1_0': 0.8045112781954887, 'acc_1_1': 0.9774436090225563, 'mean_acc': 0.9115929941618015}\n",
      "best test accuracy (class): {'weighted_mean_acc': 0.893833176641686, 'worst_acc': 0.08337028824833703, 'acc_0_0': 0.9250554323725055, 'acc_0_1': 0.08337028824833703, 'acc_1_0': 0.278816199376947, 'acc_1_1': 0.9641744548286605, 'mean_acc': 0.5302036589575423}\n",
      "best test accuracy (spurious): {'weighted_mean_acc': 0.93097443254832, 'worst_acc': 0.721183800623053, 'acc_0_0': 0.9250554323725055, 'acc_0_1': 0.916629711751663, 'acc_1_0': 0.721183800623053, 'acc_1_1': 0.9641744548286605, 'mean_acc': 0.903520883672765}\n"
     ]
    }
   ],
   "source": [
    "final_acc_dict = {} # for mean+-std (final) accuracy (over 3 times run) \n",
    "\n",
    "full_acc_dict = {} # for full accuracy (on only single run) (for simple reasoning)\n",
    "\n",
    "opt.epochs = 2\n",
    "opt.dataset = 'waterbirds'\n",
    "\n",
    "opt.text_embedding_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/text_embedding.json\"\n",
    "opt.image_embedding_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings_unnormalized/waterbirds/RN50/embedding_prediction.json\"\n",
    "opt.data_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/waterbirds/waterbird_complete95_forest2water2\"\n",
    "\n",
    "# opt.tl_method = \"linear_probing\"\n",
    "opt.tl_method = \"adapter\"\n",
    "if __name__ == '__main__':    \n",
    "    for tl_method in [\"linear_probing\", \"adapter\"]:\n",
    "        opt.tl_method = tl_method\n",
    "        final_acc_dict[tl_method] = {}\n",
    "        full_acc_dict[tl_method] = {}\n",
    "        for train_target in ['class', 'spurious']:\n",
    "            opt.train_target = train_target\n",
    "            for iter in range(1, 3):\n",
    "                print(f\"================= {opt.dataset}_ft_on_{opt.train_target} (iter. {iter})=================\")\n",
    "                \n",
    "                v_acc_t, t_acc_y, t_acc_s, tr_accs_t, v_accs_t, v_accs_non_t = main(opt)\n",
    "                final_acc_dict[tl_method][f\"{opt.dataset}_ft_on_{opt.train_target}({iter})\"] = {f'val_{opt.train_target}': v_acc_t, 'test_class': t_acc_y, 'test_spurious': t_acc_s}\n",
    "                \n",
    "                if iter==1:\n",
    "                    full_acc_dict[tl_method][f\"{opt.dataset}_ft_on_{opt.train_target}\"] = {f\"train_{opt.train_target}\" : tr_accs_t, f\"val_{opt.train_target}\" : v_accs_t, f\"val_non_target\" : v_accs_non_t}                \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean+-std (averaged over 3 times run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_final_report = {} # For reporting final performance.\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Best [avg]-validation group accuracy on [class]-trained [linear_probing] ==============\n",
      "\n",
      "      weighted_mean_acc  worst_acc   acc_0_0   acc_0_1   acc_1_0   acc_1_1  mean_acc\n",
      "iter                                                                                \n",
      "1              0.965644   0.225564  0.997859  0.856223  0.225564  0.917293  0.848207\n",
      "2              0.965496   0.586466  0.989293  0.603004  0.586466  0.969925  0.792327\n",
      "mean           0.965570   0.406015  0.993576  0.729614  0.406015  0.943609  0.820267\n",
      "std            0.000074   0.180451  0.004283  0.126609  0.180451  0.026316  0.027940\n",
      "Lin. Prov. on class {}\n",
      "===== Corresponding [test_class] group accuracy on [class]-trained [linear_probing] =====\n",
      "\n",
      "      weighted_mean_acc  worst_acc   acc_0_0   acc_0_1   acc_1_0   acc_1_1  mean_acc\n",
      "iter                                                                                \n",
      "1              0.956283   0.257009  0.999113  0.864302  0.257009  0.867601  0.849845\n",
      "2              0.960183   0.549446  0.990244  0.549446  0.591900  0.951713  0.770280\n",
      "mean           0.958233   0.403228  0.994678  0.706874  0.424455  0.909657  0.810062\n",
      "std            0.001950   0.146218  0.004435  0.157428  0.167445  0.042056  0.039783\n",
      "Lin. Prov. on class {'Avg. acc (on class)': 0.9582330148584979, 'Worst. acc (on class)': 0.40322751103466853}\n",
      "===== Corresponding [test_spurious] group accuracy on [class]-trained [linear_probing] =====\n",
      "\n",
      "      weighted_mean_acc  worst_acc   acc_0_0   acc_0_1   acc_1_0   acc_1_1  mean_acc\n",
      "iter                                                                                \n",
      "1              0.934000   0.135698  0.999113  0.135698  0.742991  0.867601  0.620124\n",
      "2              0.954242   0.408100  0.990244  0.450554  0.408100  0.951713  0.711426\n",
      "mean           0.944121   0.271899  0.994678  0.293126  0.575545  0.909657  0.665775\n",
      "std            0.010121   0.136201  0.004435  0.157428  0.167445  0.042056  0.045651\n",
      "Lin. Prov. on class {'Avg. acc (on class)': 0.9582330148584979, 'Worst. acc (on class)': 0.40322751103466853, 'Avg. acc (on spurious)': 0.9441207243706703, 'Worst. acc (on spurious)': 0.27189906818354503}\n",
      "============== Best [avg]-validation group accuracy on [spurious]-trained [linear_probing] ==============\n",
      "\n",
      "      weighted_mean_acc  worst_acc   acc_0_0   acc_0_1   acc_1_0   acc_1_1  mean_acc\n",
      "iter                                                                                \n",
      "1              0.980454   0.744361  0.989293  0.858369  0.744361  0.984962  0.910759\n",
      "2              0.983350   0.751880  0.991435  0.847639  0.751880  0.992481  0.909091\n",
      "mean           0.981902   0.748120  0.990364  0.853004  0.748120  0.988722  0.909925\n",
      "std            0.001448   0.003759  0.001071  0.005365  0.003759  0.003759  0.000834\n",
      "Lin. Prov. on class {'Avg. acc (on class)': 0.9582330148584979, 'Worst. acc (on class)': 0.40322751103466853, 'Avg. acc (on spurious)': 0.9441207243706703, 'Worst. acc (on spurious)': 0.27189906818354503}\n",
      "Lin. Prov. on spurious {}\n",
      "===== Corresponding [test_class] group accuracy on [spurious]-trained [linear_probing] =====\n",
      "\n",
      "      weighted_mean_acc  worst_acc   acc_0_0   acc_0_1   acc_1_0   acc_1_1  mean_acc\n",
      "iter                                                                                \n",
      "1              0.948013   0.164080  0.990244  0.164080  0.316199  0.978193  0.592682\n",
      "2              0.947261   0.165854  0.991131  0.165854  0.278816  0.973520  0.589058\n",
      "mean           0.947637   0.164967  0.990687  0.164967  0.297508  0.975857  0.590870\n",
      "std            0.000376   0.000887  0.000443  0.000887  0.018692  0.002336  0.001812\n",
      "Lin. Prov. on class {'Avg. acc (on class)': 0.9582330148584979, 'Worst. acc (on class)': 0.40322751103466853, 'Avg. acc (on spurious)': 0.9441207243706703, 'Worst. acc (on spurious)': 0.27189906818354503}\n",
      "Lin. Prov. on spurious {'Avg. acc (on class)': 0.9476369493701886, 'Worst. acc (on class)': 0.16496674057649668}\n",
      "===== Corresponding [test_spurious] group accuracy on [spurious]-trained [linear_probing] =====\n",
      "\n",
      "      weighted_mean_acc  worst_acc   acc_0_0   acc_0_1   acc_1_0   acc_1_1  mean_acc\n",
      "iter                                                                                \n",
      "1              0.978087   0.683801  0.990244  0.835920  0.683801  0.978193  0.894891\n",
      "2              0.978072   0.721184  0.991131  0.834146  0.721184  0.973520  0.898171\n",
      "mean           0.978079   0.702492  0.990687  0.835033  0.702492  0.975857  0.896531\n",
      "std            0.000007   0.018692  0.000443  0.000887  0.018692  0.002336  0.001640\n",
      "Lin. Prov. on class {'Avg. acc (on class)': 0.9582330148584979, 'Worst. acc (on class)': 0.40322751103466853, 'Avg. acc (on spurious)': 0.9441207243706703, 'Worst. acc (on spurious)': 0.27189906818354503}\n",
      "Lin. Prov. on spurious {'Avg. acc (on class)': 0.9476369493701886, 'Worst. acc (on class)': 0.16496674057649668, 'Avg. acc (on spurious)': 0.9780793621077297, 'Worst. acc (on spurious)': 0.7024922118380063}\n",
      "============== Best [avg]-validation group accuracy on [class]-trained [adapter] ==============\n",
      "\n",
      "      weighted_mean_acc  worst_acc   acc_0_0   acc_0_1   acc_1_0   acc_1_1  mean_acc\n",
      "iter                                                                                \n",
      "1              0.966964   0.488722  0.993576  0.675966  0.488722  0.954887  0.809842\n",
      "2              0.767883   0.000000  1.000000  1.000000  0.000000  0.000000  0.778148\n",
      "mean           0.867423   0.244361  0.996788  0.837983  0.244361  0.477444  0.793995\n",
      "std            0.099540   0.244361  0.003212  0.162017  0.244361  0.477444  0.015847\n",
      "Lin. Prov. on class {'Avg. acc (on class)': 0.9582330148584979, 'Worst. acc (on class)': 0.40322751103466853, 'Avg. acc (on spurious)': 0.9441207243706703, 'Worst. acc (on spurious)': 0.27189906818354503}\n",
      "Lin. Prov. on spurious {'Avg. acc (on class)': 0.9476369493701886, 'Worst. acc (on class)': 0.16496674057649668, 'Avg. acc (on spurious)': 0.9780793621077297, 'Worst. acc (on spurious)': 0.7024922118380063}\n",
      "Adapter on class {}\n",
      "===== Corresponding [test_class] group accuracy on [class]-trained [adapter] =====\n",
      "\n",
      "      weighted_mean_acc  worst_acc   acc_0_0   acc_0_1   acc_1_0   acc_1_1  mean_acc\n",
      "iter                                                                                \n",
      "1              0.958476   0.528037  0.990244  0.649667  0.528037  0.929907  0.799793\n",
      "2              0.767883   0.000000  1.000000  1.000000  0.000000  0.000000  0.778391\n",
      "mean           0.863180   0.264019  0.995122  0.824834  0.264019  0.464953  0.789092\n",
      "std            0.095296   0.264019  0.004878  0.175166  0.264019  0.464953  0.010701\n",
      "Lin. Prov. on class {'Avg. acc (on class)': 0.9582330148584979, 'Worst. acc (on class)': 0.40322751103466853, 'Avg. acc (on spurious)': 0.9441207243706703, 'Worst. acc (on spurious)': 0.27189906818354503}\n",
      "Lin. Prov. on spurious {'Avg. acc (on class)': 0.9476369493701886, 'Worst. acc (on class)': 0.16496674057649668, 'Avg. acc (on spurious)': 0.9780793621077297, 'Worst. acc (on spurious)': 0.7024922118380063}\n",
      "Adapter on class {'Avg. acc (on class)': 0.8631796815261347, 'Worst. acc (on class)': 0.26401869158878505}\n",
      "===== Corresponding [test_spurious] group accuracy on [class]-trained [adapter] =====\n",
      "\n",
      "      weighted_mean_acc  worst_acc   acc_0_0   acc_0_1   acc_1_0   acc_1_1  mean_acc\n",
      "iter                                                                                \n",
      "1              0.946335   0.350333  0.990244  0.350333  0.471963  0.929907   0.67708\n",
      "2              0.741189   0.000000  1.000000  0.000000  1.000000  0.000000   0.50000\n",
      "mean           0.843762   0.175166  0.995122  0.175166  0.735981  0.464953   0.58854\n",
      "std            0.102573   0.175166  0.004878  0.175166  0.264019  0.464953   0.08854\n",
      "Lin. Prov. on class {'Avg. acc (on class)': 0.9582330148584979, 'Worst. acc (on class)': 0.40322751103466853, 'Avg. acc (on spurious)': 0.9441207243706703, 'Worst. acc (on spurious)': 0.27189906818354503}\n",
      "Lin. Prov. on spurious {'Avg. acc (on class)': 0.9476369493701886, 'Worst. acc (on class)': 0.16496674057649668, 'Avg. acc (on spurious)': 0.9780793621077297, 'Worst. acc (on spurious)': 0.7024922118380063}\n",
      "Adapter on class {'Avg. acc (on class)': 0.8631796815261347, 'Worst. acc (on class)': 0.26401869158878505, 'Avg. acc (on spurious)': 0.8437617670585805, 'Worst. acc (on spurious)': 0.17516629711751663}\n",
      "============== Best [avg]-validation group accuracy on [spurious]-trained [adapter] ==============\n",
      "\n",
      "      weighted_mean_acc  worst_acc   acc_0_0   acc_0_1   acc_1_0   acc_1_1  mean_acc\n",
      "iter                                                                                \n",
      "1              0.980454   0.744361  0.989293  0.858369  0.744361  0.984962  0.910759\n",
      "2              0.936092   0.804511  0.927195  0.907725  0.804511  0.977444  0.911593\n",
      "mean           0.958273   0.774436  0.958244  0.883047  0.774436  0.981203  0.911176\n",
      "std            0.022181   0.030075  0.031049  0.024678  0.030075  0.003759  0.000417\n",
      "Lin. Prov. on class {'Avg. acc (on class)': 0.9582330148584979, 'Worst. acc (on class)': 0.40322751103466853, 'Avg. acc (on spurious)': 0.9441207243706703, 'Worst. acc (on spurious)': 0.27189906818354503}\n",
      "Lin. Prov. on spurious {'Avg. acc (on class)': 0.9476369493701886, 'Worst. acc (on class)': 0.16496674057649668, 'Avg. acc (on spurious)': 0.9780793621077297, 'Worst. acc (on spurious)': 0.7024922118380063}\n",
      "Adapter on class {'Avg. acc (on class)': 0.8631796815261347, 'Worst. acc (on class)': 0.26401869158878505, 'Avg. acc (on spurious)': 0.8437617670585805, 'Worst. acc (on spurious)': 0.17516629711751663}\n",
      "Adapter on spurious {}\n",
      "===== Corresponding [test_class] group accuracy on [spurious]-trained [adapter] =====\n",
      "\n",
      "      weighted_mean_acc  worst_acc   acc_0_0   acc_0_1   acc_1_0   acc_1_1  mean_acc\n",
      "iter                                                                                \n",
      "1              0.946573   0.154324  0.989357  0.154324  0.280374  0.978193  0.584570\n",
      "2              0.893833   0.083370  0.925055  0.083370  0.278816  0.964174  0.530204\n",
      "mean           0.920203   0.118847  0.957206  0.118847  0.279595  0.971184  0.557387\n",
      "std            0.026370   0.035477  0.032151  0.035477  0.000779  0.007009  0.027183\n",
      "Lin. Prov. on class {'Avg. acc (on class)': 0.9582330148584979, 'Worst. acc (on class)': 0.40322751103466853, 'Avg. acc (on spurious)': 0.9441207243706703, 'Worst. acc (on spurious)': 0.27189906818354503}\n",
      "Lin. Prov. on spurious {'Avg. acc (on class)': 0.9476369493701886, 'Worst. acc (on class)': 0.16496674057649668, 'Avg. acc (on spurious)': 0.9780793621077297, 'Worst. acc (on spurious)': 0.7024922118380063}\n",
      "Adapter on class {'Avg. acc (on class)': 0.8631796815261347, 'Worst. acc (on class)': 0.26401869158878505, 'Avg. acc (on spurious)': 0.8437617670585805, 'Worst. acc (on spurious)': 0.17516629711751663}\n",
      "Adapter on spurious {'Avg. acc (on class)': 0.9202030662743528, 'Worst. acc (on class)': 0.1188470066518847}\n",
      "===== Corresponding [test_spurious] group accuracy on [spurious]-trained [adapter] =====\n",
      "\n",
      "      weighted_mean_acc  worst_acc   acc_0_0   acc_0_1   acc_1_0   acc_1_1  mean_acc\n",
      "iter                                                                                \n",
      "1              0.978232   0.719626  0.989357  0.845676  0.719626  0.978193  0.902313\n",
      "2              0.930974   0.721184  0.925055  0.916630  0.721184  0.964174  0.903521\n",
      "mean           0.954603   0.720405  0.957206  0.881153  0.720405  0.971184  0.902917\n",
      "std            0.023629   0.000779  0.032151  0.035477  0.000779  0.007009  0.000604\n",
      "Lin. Prov. on class {'Avg. acc (on class)': 0.9582330148584979, 'Worst. acc (on class)': 0.40322751103466853, 'Avg. acc (on spurious)': 0.9441207243706703, 'Worst. acc (on spurious)': 0.27189906818354503}\n",
      "Lin. Prov. on spurious {'Avg. acc (on class)': 0.9476369493701886, 'Worst. acc (on class)': 0.16496674057649668, 'Avg. acc (on spurious)': 0.9780793621077297, 'Worst. acc (on spurious)': 0.7024922118380063}\n",
      "Adapter on class {'Avg. acc (on class)': 0.8631796815261347, 'Worst. acc (on class)': 0.26401869158878505, 'Avg. acc (on spurious)': 0.8437617670585805, 'Worst. acc (on spurious)': 0.17516629711751663}\n",
      "Adapter on spurious {'Avg. acc (on class)': 0.9202030662743528, 'Worst. acc (on class)': 0.1188470066518847, 'Avg. acc (on spurious)': 0.9546034128841472, 'Worst. acc (on spurious)': 0.720404984423676}\n"
     ]
    }
   ],
   "source": [
    "# val_target\n",
    "for tl_method in [\"linear_probing\", \"adapter\"]:\n",
    "    if tl_method == \"linear_probing\":\n",
    "        report_label = 'Lin. Prov.'\n",
    "        val_on = 'avg'\n",
    "    elif tl_method =='adapter':\n",
    "        report_label = 'Adapter'\n",
    "        val_on = 'avg'\n",
    "    elif tl_method =='contrastive_adapter':\n",
    "        report_label = 'Contra. Adapter'\n",
    "        val_on = 'worst'\n",
    "        \n",
    "        \n",
    "    for train_target in [\"class\", \"spurious\"]:\n",
    "        df_for_final_report[f\"{report_label} on {train_target}\"]  = {}\n",
    "    \n",
    "        for eval in [f\"val_{train_target}\", \"test_class\", \"test_spurious\"]:\n",
    "            if \"val\" in eval:\n",
    "                print(f\"============== Best [{val_on}]-validation group accuracy on [{train_target}]-trained [{tl_method}] ==============\\n\")\n",
    "            elif \"test\" in eval:\n",
    "                print(f\"===== Corresponding [{eval}] group accuracy on [{train_target}]-trained [{tl_method}] =====\\n\")\n",
    "                \n",
    "            multiple_run = []\n",
    "            for iter in range(1,3): \n",
    "                # val_target \n",
    "                single_run = final_acc_dict[tl_method][f\"{opt.dataset}_ft_on_{train_target}({iter})\"][eval]\n",
    "                multiple_run.append(single_run)\n",
    "                    \n",
    "            df_multiple = pd.DataFrame(multiple_run, index=range(1, 3))\n",
    "            df_multiple.index.name = 'iter'\n",
    "            \n",
    "            df_multiple.loc[\"mean\"] = df_multiple.mean()\n",
    "            df_multiple.loc[\"std\"] = df_multiple.std()\n",
    "            print(df_multiple)\n",
    "            \n",
    "            # 3-times-averaged performance(Avg. & Worst acc.)\n",
    "            if \"test\" in eval:\n",
    "                df_for_final_report[f\"{report_label} on {train_target}\"][f\"Avg. acc (on {eval.split('_')[-1]})\"] = df_multiple.loc[\"mean\"][\"weighted_mean_acc\"]\n",
    "                df_for_final_report[f\"{report_label} on {train_target}\"][f\"Worst. acc (on {eval.split('_')[-1]})\"] = df_multiple.loc[\"mean\"][\"worst_acc\"]\n",
    "\n",
    "            for k, v in df_for_final_report.items():\n",
    "                print(k, v)\n",
    "            \n",
    "        \n",
    "\n",
    "# for k, v in final_acc_dict[tl_method].items():\n",
    "#     print(k, v)\n",
    "#     print(v.keys())\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full acc plot for understanding learning mechanism (일단 생략)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear probing on semantic \"class\" (foreground in Waterbirds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear probing on \"spurious attributes\" (backgorund in Waterbirds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_zs_embeddings = pd.read_json(\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/celeba/RN50/embedding_prediction.json\")        \n",
    "full_dict_celeba = {}\n",
    "opt.dataset = 'celeba'\n",
    "opt.image_embedding_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/celeba/RN50/embedding_prediction.json\"\n",
    "opt.data_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/celeba\"\n",
    "\n",
    "if __name__ == '__main__':    \n",
    "    for target in ['class', 'spurious']:\n",
    "        opt.train_target = target\n",
    "        for iter in range(1, 4):\n",
    "            print(f\"======= {opt.dataset}_ft_on_{opt.train_target} (No. {iter} )=======\")\n",
    "            t_acc_y, t_acc_s = main(opt)\n",
    "            full_dict_celeba[f\"{opt.dataset}_ft_on_{opt.train_target}({iter})\"] = {'class': t_acc_y, 'spurious': t_acc_s}\n",
    "        \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dict_zs(acc_groups, y, g, preds):\n",
    "    # preds = torch.argmax(logits, axis=1)\n",
    "    correct_batch = (preds == y)\n",
    "    g = g.cpu()\n",
    "    for g_val in np.unique(g):\n",
    "        mask = g == g_val\n",
    "        n = mask.sum().item()\n",
    "        corr = correct_batch[mask].sum().item()\n",
    "        acc_groups[g_val].update(corr / n, n) # AverageMeter Updater. \n",
    "\n",
    "def validate_zs(val_loader, get_yp_func, train_group_ratio, target, label='Test', watch=True):\n",
    "    \"\"\"validation\"\"\"\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc = AverageMeter()\n",
    "    acc_groups = {g_idx : AverageMeter() for g_idx in range(val_loader.dataset.n_groups)}\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            if opt.dataset == 'waterbirds':\n",
    "                _, all_labels, _ = data\n",
    "                labels = all_labels[target] # (y, y_group, y_spurious)\n",
    "                groups = all_labels['group']\n",
    "                preds = all_labels['ebd_y_pred']\n",
    "            else:\n",
    "                _,  all_labels, _ = data\n",
    "                labels = all_labels[target] # (y, y_group, y_spurious)\n",
    "                groups = all_labels['group']\n",
    "                preds = all_labels['ebd_y_pred']\n",
    "              \n",
    "              \n",
    "            preds = preds.float().cuda()  \n",
    "            labels = labels.cuda()\n",
    "            bsz = labels.shape[0]\n",
    "            \n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            \n",
    "            # update metric    \n",
    "            acc1 = accuracy_zs(preds, labels, bsz)\n",
    "            acc.update(acc1, bsz)\n",
    "            \n",
    "            # Update acc dict\n",
    "            update_dict_zs(acc_groups, labels, groups, preds)\n",
    "            \n",
    "            # if (idx+1) % opt.print_freq == 0:\n",
    "            #     print(f'{label}: [{0}/{1}]\\t'\n",
    "            #         'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "            #         'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "            #         'Acc@1 {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "            #         idx, len(val_loader), batch_time=batch_time,\n",
    "            #         loss=losses, acc=acc))\n",
    "                    \n",
    "                    \n",
    "    group_acc = get_results(acc_groups, get_yp_func)\n",
    "    \n",
    "    #NOTE add Weighted mean acc.\n",
    "    groups = range(val_loader.dataset.n_groups) # 0, 1, 2, 3\n",
    "    group_acc_indiv =  [group_acc[f\"acc_{get_yp_func(g)[0]}_{get_yp_func(g)[1]}\"] for g in groups]\n",
    "    weighted_mean_acc = (np.array(group_acc_indiv) * np.array(train_group_ratio)).sum() # Weighted Sum \\\n",
    "    \n",
    "    group_acc[\"weighted_mean_acc\"] = weighted_mean_acc\n",
    "    group_acc = {key: group_acc[key] for key in new_order_for_print}\n",
    "    \n",
    "    if watch:\n",
    "        print(f\"{label}:\", str(group_acc))\n",
    "        print(' * Acc@1 {acc.avg:.3f}'.format(acc=acc))\n",
    "        \n",
    "    return  acc.avg, group_acc\n",
    "\n",
    "\n",
    "def main_zs(opt):\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    # opt = parse_option()\n",
    "    \n",
    "    # build dataset example.\n",
    "    if opt.dataset == 'waterbirds':\n",
    "        # build dataset example.\n",
    "        trainset = WaterbirdsEmbeddings(opt.data_dir, 'train', opt.image_embedding_dir, None, None)\n",
    "        # build data loader\n",
    "        print(\"Load Data Loader (Waterbirds) (test)\")\n",
    "        train_loader, val_loader, test_loader = load_waterbirds_embeddings(opt.data_dir, opt.image_embedding_dir, opt.batch_size, opt.batch_size)\n",
    "    elif opt.dataset == 'celeba':\n",
    "        # build dataset example.\n",
    "        trainset = CelebaEmbeddings(opt.data_dir, 'train', opt.image_embedding_dir, None)\n",
    "        # build data loader\n",
    "        print(\"Load Data Loader (CelebA) (test)\")\n",
    "        train_loader, val_loader, test_loader = load_celeba_embeddings(opt.data_dir, opt.image_embedding_dir, opt.batch_size, opt.batch_size)\n",
    "    \n",
    "    get_yp_func = partial(get_y_p, n_places=trainset.n_places)\n",
    "    train_group_ratio = trainset.group_ratio\n",
    "\n",
    "    # eval for one epoch\n",
    "    # val_acc, val_group_acc = validate_zs(val_loader, get_yp_func, train_group_ratio, target='y', label='Val(y)')\n",
    "\n",
    "    test_acc_y, test_group_acc_y = validate_zs(test_loader, get_yp_func, train_group_ratio, target='class', label='Test(class)', watch=True)\n",
    "    test_acc_spurious, test_group_acc_spurious = validate_zs(test_loader, get_yp_func, train_group_ratio, target='spurious', label='Test(spurious)', watch=True)\n",
    "    print('===============================Final Results===============================')\n",
    "    # print('Zero-shot validation accuracy: {} '.format(val_group_acc))\n",
    "    \n",
    "    print('Zero-shot test accuracy (class): {}'.format(test_group_acc_y))\n",
    "    print('Zero-shot test accuracy (spurious): {}'.format(test_group_acc_spurious))\n",
    "    \n",
    "    return test_group_acc_y, test_group_acc_spurious"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waterbirds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Loader (Waterbirds) (validation / test)\n",
      "Val(y): {'weighted_mean_acc': 0.9450627926530569, 'worst_acc': 0.3233082706766917, 'acc_0_0': 0.9914346895074947, 'acc_0_1': 0.7145922746781116, 'acc_1_0': 0.3233082706766917, 'acc_1_1': 0.8646616541353384, 'mean_acc': 0.7956630525437864}\n",
      " * Acc@1 0.796\n",
      "Test(y): {'weighted_mean_acc': 0.9289761348579215, 'worst_acc': 0.3909657320872274, 'acc_0_0': 0.9804878048780488, 'acc_0_1': 0.7254988913525499, 'acc_1_0': 0.3909657320872274, 'acc_1_1': 0.822429906542056, 'mean_acc': 0.7984121505005177}\n",
      " * Acc@1 0.798\n",
      "Test(spurious): {'weighted_mean_acc': 0.9142166444777964, 'worst_acc': 0.2745011086474501, 'acc_0_0': 0.9804878048780488, 'acc_0_1': 0.2745011086474501, 'acc_1_0': 0.6090342679127726, 'acc_1_1': 0.822429906542056, 'mean_acc': 0.6470486710390059}\n",
      " * Acc@1 0.647\n",
      "===============================Final Results===============================\n",
      "Zero-shot (worst-)validation accuracy: {'weighted_mean_acc': 0.9450627926530569, 'worst_acc': 0.3233082706766917, 'acc_0_0': 0.9914346895074947, 'acc_0_1': 0.7145922746781116, 'acc_1_0': 0.3233082706766917, 'acc_1_1': 0.8646616541353384, 'mean_acc': 0.7956630525437864} \n",
      "Zero-shot test accuracy (class): {'weighted_mean_acc': 0.9289761348579215, 'worst_acc': 0.3909657320872274, 'acc_0_0': 0.9804878048780488, 'acc_0_1': 0.7254988913525499, 'acc_1_0': 0.3909657320872274, 'acc_1_1': 0.822429906542056, 'mean_acc': 0.7984121505005177}\n",
      "Zero-shot test accuracy (spurious): {'weighted_mean_acc': 0.9142166444777964, 'worst_acc': 0.2745011086474501, 'acc_0_0': 0.9804878048780488, 'acc_0_1': 0.2745011086474501, 'acc_1_0': 0.6090342679127726, 'acc_1_1': 0.822429906542056, 'mean_acc': 0.6470486710390059}\n"
     ]
    }
   ],
   "source": [
    "full_dict_wb_zs = {}\n",
    "\n",
    "opt.dataset = 'waterbirds'\n",
    "# opt.train_target = 'class'\n",
    "\n",
    "opt.image_embedding_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/waterbirds/RN50/embedding_prediction.json\"\n",
    "opt.data_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/waterbirds/waterbird_complete95_forest2water2\"\n",
    "if __name__ == '__main__':    \n",
    "    opt.train_target = target\n",
    "    t_acc_y, t_acc_s = main_zs(opt)\n",
    "    full_dict_wb_zs[f\"{opt_dataset}_zs\"] = {'class': t_acc_y, 'spurious': t_acc_s}\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst acc:  0.3909657320872274\n"
     ]
    }
   ],
   "source": [
    "df_zs_embeddings = pd.read_json(\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/waterbirds/RN50/embedding_prediction.json\")\n",
    "from copy import deepcopy\n",
    "w = deepcopy(df_zs_embeddings)\n",
    "w= w.T\n",
    "print(\"Worst acc: \", len(w[(w['split']=='2') & (w['y']=='1') & (w['place']=='0') & (w['y_pred']=='1')]) / len(w[(w['split']=='2') & (w['y']=='1') & (w['place']=='0')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data Loader (train, validation, test)\n",
      "Val(y): [0/1]\tTime 0.009 (0.277)\tLoss 0.0000 (0.0000)\tAcc@1 0.137 (0.146)\n",
      "Val(y): [0/1]\tTime 0.003 (0.144)\tLoss 0.0000 (0.0000)\tAcc@1 0.137 (0.148)\n",
      "Val(y): [0/1]\tTime 0.009 (0.099)\tLoss 0.0000 (0.0000)\tAcc@1 0.150 (0.147)\n",
      "Val(y): [0/1]\tTime 0.003 (0.078)\tLoss 0.0000 (0.0000)\tAcc@1 0.119 (0.148)\n",
      "Val(y): [0/1]\tTime 0.002 (0.064)\tLoss 0.0000 (0.0000)\tAcc@1 0.143 (0.147)\n",
      "Val(y): [0/1]\tTime 0.003 (0.056)\tLoss 0.0000 (0.0000)\tAcc@1 0.156 (0.147)\n",
      "Val(y): [0/1]\tTime 0.002 (0.049)\tLoss 0.0000 (0.0000)\tAcc@1 0.152 (0.146)\n",
      "Val(y): [0/1]\tTime 0.003 (0.044)\tLoss 0.0000 (0.0000)\tAcc@1 0.141 (0.147)\n",
      "Val(y): [0/1]\tTime 0.002 (0.041)\tLoss 0.0000 (0.0000)\tAcc@1 0.150 (0.146)\n",
      "Val(y): [0/1]\tTime 0.002 (0.038)\tLoss 0.0000 (0.0000)\tAcc@1 0.139 (0.146)\n",
      "Val(y): [0/1]\tTime 0.002 (0.035)\tLoss 0.0000 (0.0000)\tAcc@1 0.145 (0.147)\n",
      "Val(y): [0/1]\tTime 0.003 (0.033)\tLoss 0.0000 (0.0000)\tAcc@1 0.131 (0.147)\n",
      "Val(y): [0/1]\tTime 0.002 (0.032)\tLoss 0.0000 (0.0000)\tAcc@1 0.168 (0.147)\n",
      "Val(y): [0/1]\tTime 0.003 (0.030)\tLoss 0.0000 (0.0000)\tAcc@1 0.158 (0.147)\n",
      "Val(y): [0/1]\tTime 0.002 (0.029)\tLoss 0.0000 (0.0000)\tAcc@1 0.188 (0.147)\n",
      "Val(y): {'weighted_mean_acc': 0.1469128198791998, 'worst_acc': 0.06282371665107708, 'acc_0_0': 0.06282371665107708, 'acc_0_1': 0.18605138020755452, 'acc_1_0': 0.2932692307692308, 'acc_1_1': 0.18817591925018023, 'mean_acc': 0.146912821773054}\n",
      " * Acc@1 0.147\n",
      "Test(y): [0/1]\tTime 0.003 (0.193)\tLoss 0.0000 (0.0000)\tAcc@1 0.137 (0.146)\n",
      "Test(y): [0/1]\tTime 0.001 (0.101)\tLoss 0.0000 (0.0000)\tAcc@1 0.137 (0.148)\n",
      "Test(y): [0/1]\tTime 0.003 (0.072)\tLoss 0.0000 (0.0000)\tAcc@1 0.150 (0.147)\n",
      "Test(y): [0/1]\tTime 0.002 (0.056)\tLoss 0.0000 (0.0000)\tAcc@1 0.119 (0.148)\n",
      "Test(y): [0/1]\tTime 0.003 (0.048)\tLoss 0.0000 (0.0000)\tAcc@1 0.143 (0.147)\n",
      "Test(y): [0/1]\tTime 0.001 (0.042)\tLoss 0.0000 (0.0000)\tAcc@1 0.156 (0.147)\n",
      "Test(y): [0/1]\tTime 0.003 (0.038)\tLoss 0.0000 (0.0000)\tAcc@1 0.152 (0.146)\n",
      "Test(y): [0/1]\tTime 0.002 (0.034)\tLoss 0.0000 (0.0000)\tAcc@1 0.141 (0.147)\n",
      "Test(y): [0/1]\tTime 0.003 (0.032)\tLoss 0.0000 (0.0000)\tAcc@1 0.150 (0.146)\n",
      "Test(y): [0/1]\tTime 0.002 (0.030)\tLoss 0.0000 (0.0000)\tAcc@1 0.139 (0.146)\n",
      "Test(y): [0/1]\tTime 0.001 (0.028)\tLoss 0.0000 (0.0000)\tAcc@1 0.145 (0.147)\n",
      "Test(y): [0/1]\tTime 0.002 (0.027)\tLoss 0.0000 (0.0000)\tAcc@1 0.131 (0.147)\n",
      "Test(y): [0/1]\tTime 0.001 (0.026)\tLoss 0.0000 (0.0000)\tAcc@1 0.168 (0.147)\n",
      "Test(y): [0/1]\tTime 0.002 (0.025)\tLoss 0.0000 (0.0000)\tAcc@1 0.158 (0.147)\n",
      "Test(y): [0/1]\tTime 0.003 (0.024)\tLoss 0.0000 (0.0000)\tAcc@1 0.188 (0.147)\n",
      "Test(y): {'weighted_mean_acc': 0.1469128198791998, 'worst_acc': 0.06282371665107708, 'acc_0_0': 0.06282371665107708, 'acc_0_1': 0.18605138020755452, 'acc_1_0': 0.2932692307692308, 'acc_1_1': 0.18817591925018023, 'mean_acc': 0.146912821773054}\n",
      " * Acc@1 0.147\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.192)\tLoss 0.0000 (0.0000)\tAcc@1 0.449 (0.467)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.100)\tLoss 0.0000 (0.0000)\tAcc@1 0.457 (0.462)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.071)\tLoss 0.0000 (0.0000)\tAcc@1 0.443 (0.463)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.055)\tLoss 0.0000 (0.0000)\tAcc@1 0.475 (0.461)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.047)\tLoss 0.0000 (0.0000)\tAcc@1 0.473 (0.461)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.041)\tLoss 0.0000 (0.0000)\tAcc@1 0.467 (0.462)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.037)\tLoss 0.0000 (0.0000)\tAcc@1 0.471 (0.462)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.034)\tLoss 0.0000 (0.0000)\tAcc@1 0.430 (0.461)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.031)\tLoss 0.0000 (0.0000)\tAcc@1 0.482 (0.461)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.029)\tLoss 0.0000 (0.0000)\tAcc@1 0.445 (0.462)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.028)\tLoss 0.0000 (0.0000)\tAcc@1 0.469 (0.462)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.026)\tLoss 0.0000 (0.0000)\tAcc@1 0.477 (0.463)\n",
      "Test(spurious): [0/1]\tTime 0.003 (0.025)\tLoss 0.0000 (0.0000)\tAcc@1 0.463 (0.463)\n",
      "Test(spurious): [0/1]\tTime 0.002 (0.024)\tLoss 0.0000 (0.0000)\tAcc@1 0.482 (0.463)\n",
      "Test(spurious): [0/1]\tTime 0.003 (0.023)\tLoss 0.0000 (0.0000)\tAcc@1 0.488 (0.463)\n",
      "Test(spurious): {'weighted_mean_acc': 0.4630030035683199, 'worst_acc': 0.06282371665107708, 'acc_0_0': 0.06282371665107708, 'acc_0_1': 0.8139486197924455, 'acc_1_0': 0.7067307692307693, 'acc_1_1': 0.18817591925018023, 'mean_acc': 0.46300301038274866}\n",
      " * Acc@1 0.463\n",
      "===============================Final Results===============================\n",
      "Zero-shot (worst-)validation accuracy: {'weighted_mean_acc': 0.1469128198791998, 'worst_acc': 0.06282371665107708, 'acc_0_0': 0.06282371665107708, 'acc_0_1': 0.18605138020755452, 'acc_1_0': 0.2932692307692308, 'acc_1_1': 0.18817591925018023, 'mean_acc': 0.146912821773054} \n",
      "Zero-shot test accuracy (class): {'weighted_mean_acc': 0.1469128198791998, 'worst_acc': 0.06282371665107708, 'acc_0_0': 0.06282371665107708, 'acc_0_1': 0.18605138020755452, 'acc_1_0': 0.2932692307692308, 'acc_1_1': 0.18817591925018023, 'mean_acc': 0.146912821773054}\n",
      "Zero-shot test accuracy (spurious): {'weighted_mean_acc': 0.4630030035683199, 'worst_acc': 0.06282371665107708, 'acc_0_0': 0.06282371665107708, 'acc_0_1': 0.8139486197924455, 'acc_1_0': 0.7067307692307693, 'acc_1_1': 0.18817591925018023, 'mean_acc': 0.46300301038274866}\n"
     ]
    }
   ],
   "source": [
    "opt.dataset = 'celeba'\n",
    "opt.train_target = 'class'\n",
    "opt.image_embedding_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/celeba/RN50/embedding_prediction.json\"\n",
    "opt.data_dir = \"/home/jinsu/workstation/project/debiasing-multi-modal/data/celeba\"\n",
    "if __name__ == '__main__':    \n",
    "    main_zs(opt)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst acc: 0.23333333333333334\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "df_zs_embeddings = pd.read_json(\"/home/jinsu/workstation/project/debiasing-multi-modal/data/embeddings/celeba/RN50/embedding_prediction.json\")\n",
    "w = deepcopy(df_zs_embeddings)\n",
    "w= w.T\n",
    "print(\"Worst acc:\", len(w[(w['split']=='2') & (w['blond']=='1') & (w['male']=='1') & (w['y_pred']=='1')]) / len(w[(w['split']=='2') & (w['blond']=='1') & (w['male']=='1')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
